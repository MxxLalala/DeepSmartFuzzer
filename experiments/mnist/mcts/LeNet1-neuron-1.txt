Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f862282bf28>, tc2=<function tc2 at 0x7f862283a048>, tc3=<function tc3 at 0x7f862283a158>, tfc_threshold=33000000, time_period=3600, verbose=True)
initial coverage: 41.6667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b867f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b867f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86762b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86766a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86433c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86433c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8676908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07647f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07115f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07115f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07115f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07115f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0711240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07112e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07117f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07117f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 9
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07117f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06790f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5a90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07117f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86594a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01510f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85f0bb8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b870b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 600
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b867f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86f7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0643860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06432b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 2
Completed Iteration #2
Best Reward: 0
coverage_call_count 800
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06799b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b518> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b870b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86eddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07645f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07898d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07898d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07113c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06592e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b870b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07114e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07117b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1000
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07117b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3940> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e39e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550aac0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a97fd0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a649e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aace10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aaca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a580b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a375f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a375f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a375f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a37588> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58898> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aaccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aaccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f07f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01515c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01515c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a641d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 1400
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a370f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a370f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a370f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479052b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479052b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479052b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478582e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478ca780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b50b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783d208> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b198> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8547858dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441efcc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0755710> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07715f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a01a97f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06794e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06794e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07115c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478dac50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 2
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b872dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caac8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a079b160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b872da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85f0bb8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b870b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 19
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01517b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01517b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46160> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a586d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a586d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478581d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64320> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a586a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64588> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06431d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06431d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85479056d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a97198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06432b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06432b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854786b550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a849e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a849e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854780fda0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a844a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a844a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a844a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853ded8668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01c67f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de550f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de550f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dec53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c56d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dacf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1daf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853df30e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1433c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb7f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c10ce48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0baa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0baf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0baf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 2900
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 14
Completed Iteration #21
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479057b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479054e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854792bf60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0764ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0711198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478dadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858898> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8659438> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07716a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07716a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0789c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07edfd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f863c954ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3300
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441effd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441effd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478caac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478da1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0babe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0babe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 3400
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478daf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae9e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0e72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed940> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c1da4a8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0679d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 3500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a079bf98> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06431d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06431d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786b748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441efc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854786bc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df309b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1280f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c52b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 24
Completed Iteration #24
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86435c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c15be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df692b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0f0> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df315c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df315c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df31a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 3900
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 4
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defc470> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de799e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de799e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6dda0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8544190cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0bb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df315c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e31d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e31d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7faba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7faba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 4200
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7befd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7bea58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa048> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7197f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7197f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1588> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d730f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7306d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1288d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1288d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7309b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0659e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb1160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8550a97320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0789b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0643f60> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f863c954ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547905dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de557f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0643b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803ee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 16
Completed Iteration #21
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478276a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aaceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550aac208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de55748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8544190828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85479054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b870b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07115c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85eeace6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b870b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8676b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0659c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8676240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee86d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853dee8b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c08eba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7e278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478ca940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c08e240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85e865b3c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de9f128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de236a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de236a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de23fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0755978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86768d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de8ea20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d76dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a84198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aacac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547858438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76def0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a58400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3550> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a46ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853de41668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 9
Completed Iteration #14
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de796d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de796d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df319b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547827438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de23c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478cac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2b00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d7be278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850decfba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 5300
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7addd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853deb1780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7beac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df908> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c11d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c11d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9739b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9739b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9738d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c91d358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973470> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 17
Completed Iteration #24
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94f0f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c84d6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 5700
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c84d0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c832ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8259b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8259b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3808d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c24e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3800f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3922b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3922b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 16
Completed Iteration #15
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3800f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3800f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8251d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8251d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8251d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c897da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c312400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c3010b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db390> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2d81d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 6100
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c323630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2425f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2564e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2564e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2425f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2564e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2564e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c242160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854780fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a069b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854780fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8320f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a069be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8320f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b40b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6200
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0679a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8329b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c128e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a37240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3019b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8326a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3dbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8326a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8326a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c84d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c8329e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8807f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d898> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c94ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c880668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8806a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c880f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8325c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c8327f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850decf860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01e7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c15b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7be320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8547858fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7bef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8547858080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3db630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850dec5320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c94f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c242cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f2b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854783db70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854783d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de79908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df31e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c91dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6df28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c301208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c880b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c91d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850decf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c242c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de6d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7fadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c301978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c880cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bd908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de0b4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de79c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df69a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441909e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1f2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df694a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df694a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c832e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de232e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de6d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de232e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df694a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06bdba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de23518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850defc7b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a647b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dee8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0711a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a647b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a64a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c09e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8550a64438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f859803e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854791bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854417cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c08e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853deb1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dee8668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f854791b630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850dec5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06bde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550aac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a019b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0151630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df696d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85eeb064e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df319b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df319b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85eeace748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417c9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b867f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b8643f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85eeace6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85479053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06caf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2e9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86ed9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a0755358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86c5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c832e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854783d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85e865b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8659c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441eff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c99aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8544190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c92d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854417cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c07b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de8e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854786bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0764d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a97160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1da898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae7b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1a12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85a06b59b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a079b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854792b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a06cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854786b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0bad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850deb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a079b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b52e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c15b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a97160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a019b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c99a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a0659a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01c68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a0151128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c92def0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c1ae1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c07b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01a9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85e865b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850de233c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850defc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7195c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a013aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7a1e80> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d730588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c09e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c143ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850df7ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854792bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de8e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f854784a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853dec5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a01d0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850defce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85b8643c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdb00> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3922b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8979b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d7e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c973a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c10c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d7d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd048> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c84db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a01d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de23470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853de55d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f853c10c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f854784a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853ded8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3926a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85a06b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850de9fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d758d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d719eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d76d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dea3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478b5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1400> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8547905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 7200
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba908> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f859803e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df7edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85478b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9dfbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c9df278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d758978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c8c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c973518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3126a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3126a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850d6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 7300
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85478f02e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2562b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2565c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2565c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2566d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2567f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c256e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c2560b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de9ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850df69ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c85b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c1aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850deb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2fd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c380048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85a07ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d6c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034483c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85441ef7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c825be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c392940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3125c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448a58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85034484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850de0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853dec5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034489e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c36db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3bada0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c08e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c9df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c86e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c380da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c897b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c86e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c323da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85034259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85034255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85034256a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fcadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7500
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85034259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fde4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fde4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fde898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fde0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fde4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fcaba8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8550a2a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f850343bf98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d730128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fde828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850346ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fde6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f946d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c323da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c8f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345bbe0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c392eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c97f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85b86e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850d76d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85034486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c312080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c85b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f850345b198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503425668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c3239e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850343bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c380748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85034258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e7f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f285f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853c0ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f281d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85034252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c2d85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f7ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f284a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f284a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850343b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c2d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 14
Completed Iteration #24
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448550> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f94c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850c825710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850346bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdef98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c36d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503425a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b748> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fb2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e452b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850345b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 7900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503448160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 307
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850347ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f0b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e455c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e455c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c86e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c312908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e45198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 308
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c256630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502efa198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c897a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5320> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 309
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502f28ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 310
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029c6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029c6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029c6160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 311
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e33828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fde908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502efac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e213c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 312
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e21a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 313
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029901d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 314
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 8100
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85029b1630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 315
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502fdeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502fdee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c3238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb10f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 316
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ee5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029905f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e33ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029905f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 317
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029785f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c9df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e45da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85029781d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 318
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e72208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8503425320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e72fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e21588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ee53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 8200
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502990ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850347e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502e8f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502e5fc18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 319
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f8502969518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 320
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502969940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2278> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 321
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029696d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029d7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028f0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502ed6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85028d9dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 322
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850c825390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 8300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f28198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502990e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502f94198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502eb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850299cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502978518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028c2fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 323
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028c2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850299cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f853df30898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f850290be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502969e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f850290bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85029d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f8502978fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f8502e5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85029b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f85028f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f85028c2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f85028d9e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 324
found coverage increase 0
Current Total Coverage 41.66666666666667
initial coverage: 41.6667
time passed (minutes): 60.159
iterations: 325
number of new inputs: 0
final coverage: 41.6667
total coverage increase: 0
