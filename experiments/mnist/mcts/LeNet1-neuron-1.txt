Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f63ec251f28>, tc2=<function tc2 at 0x7f63ec262048>, tc3=<function tc3 at 0x7f63ec262158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 41.6667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00237f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00237f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0086390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00237f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f63787bd208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00238d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bd390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00772e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00772e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787570b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787570b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787572b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00eecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787573c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787036a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787036a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787036a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6378757320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378716080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 300
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378703e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a008f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a008f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a000b668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867df60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637872c1d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786523c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786523c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af98710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af989e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a01127f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0135be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a01127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af989e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af989e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af981d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 600
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b85065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0135b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0135b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f50b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbf860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63787cca20> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df5f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8424630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787165f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787165c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787165f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787165c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b160> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 800
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637868ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cc4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637867de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787033c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787033c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a0077eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f58d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786692e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786694e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786694e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0135b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786520b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786525f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6080> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afada20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afada20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580d5860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803ce10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580bb860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 1300
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4db278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4845c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbd30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 1400
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4456a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4456a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4456a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4458d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4458d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4524a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf403c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786699e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0086240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00777b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00777b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a0077400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f64043aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f64043ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00232e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0086240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 7
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787039b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8452160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad160> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbfba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b8419668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f635afbf2e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b85473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0086dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635afadeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4846a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b85473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787df518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580e9470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580484a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c433748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786521d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4522e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786525c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfeddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fd048518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bef0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0593c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0593c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0480f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0198d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0198d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0197f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0197f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0292b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0193c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0193c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd029128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c978> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc984208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9947b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 2600
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9947b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9842e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9842e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9644e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9762e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9762e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9077b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9aff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9aff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9648d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d14a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9946a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a8d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0194e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd019f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f630c452f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6338046278> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452cf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4e53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cf60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf400f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3100
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580c6e80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787576d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380464a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787576d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a01127f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3200
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6378757ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580488d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b84193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580488d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580488d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4843c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4843c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4843c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787cccf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a008f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a008f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f635afd0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd0eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f635af98518> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a90f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787037f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787037f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afd02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bfa58> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787df0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf651d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf651d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9074a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7be10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9072b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9079e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9079e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9079e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580486d8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2170f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 3600
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd005da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cce48> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637867d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eeb8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2175f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b198> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 3900
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f53c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 41.66666666666667
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0559b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0559b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0664a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0664a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0559b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0558d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afadbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a470> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 4100
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208f28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9762e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f05c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f05c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f64043aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4400
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f64043aecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00eeb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd059588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0077a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f63786bf198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63b84194a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af98588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfe10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378703da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd0482b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378703128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0482b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0482b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0482b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0482b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0077d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00fe160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af8b470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63786e2400> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0112898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0112898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd019908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf834e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc984ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1101d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc110978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc994ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
coverage_call_count 5000
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e5f8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc013f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0035c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0035c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc066668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1defd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63786a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd005e48> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0023ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc908> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0908d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 5200
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5458d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1100b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1100b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee367f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd005588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab128> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7622e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7158d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7234a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7237b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7237b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7230b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7235f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7237b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de749dd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6faef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa9e8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb00> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7624a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a79b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7624a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a79b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64d748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6752e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675a20> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de63b438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4358> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63bdd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b03c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b06d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5900
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1107b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1104a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1106d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de179518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1343c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de134390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1797f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de11eb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1104e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1107f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 6000
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfda0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de11e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df518> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5572e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5572e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df557630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0059e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ecc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd005630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1dee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 6100
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ded30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dee0fd68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1100b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1109b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc110cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9d52b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2177f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc984eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9942b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9942b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0668d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc217198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df557898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9942b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc09eeb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc994438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdf4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 6300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df557f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de110a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc090a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee36c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a000b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd048c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a000bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4cf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdfedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0484e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fd048cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378669c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63786a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afad0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc04a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378757630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dee0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df545ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc110c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc1adb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc11b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0907f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dee36978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc090128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c484278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63380469e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787ccb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afd0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0594e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00ee828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63b8419668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0112898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0594e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f64043ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0594e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a0135be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0594e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63380465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637867d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9affd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635af98c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0594e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635af983c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf83fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9af208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c484278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd019d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd059438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c452940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868edd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdfdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6378716ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc09ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 6500
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd029e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635808ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633805d630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc003550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637873b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc91a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6358048cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637873b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5ed908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd03ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc013080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0134a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc2084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc14e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5edd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df545320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc090128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc19ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378669ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1beac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635afad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637879bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc2081d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc208ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633805dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c452940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc1ad8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd059438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0552e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd029278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd03cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637872c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4459e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fd0050f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c433208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1524e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc217588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1524e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378716cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1524e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de179eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6facc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6facc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee1d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c4dbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc055c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7238d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de11e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de110cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc208be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc907d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6eec50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6756a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7157b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de675f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637868e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de179240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de762320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1526a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f635808e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de64dc50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de665198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6959b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de152a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f633803cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63787dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 7000
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6052e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fd0599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de675908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7150f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7150f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de64df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcda0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1e4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de715588> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3097b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3097b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3099b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3099b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3090b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd317160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd317160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de64dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3092b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3092b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3178d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3179e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3178d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3178d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c4db940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd309908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5dce10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de152b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc907eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7625c0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de63b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7300
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bae10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de715e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba278> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd317128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de134da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d898> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6358048320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2afcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24edd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd867b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd867b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6338046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfabe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd25db38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd709b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 7600
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd097f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd097f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 7
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de134710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd606a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd606a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccaca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc427b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dccaccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 7800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc427b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc427b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc427b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 304
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 305
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcccd6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 306
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 7900
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc345c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 307
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfae10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 308
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccacc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdb1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccacc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc24fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 309
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 310
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcdc2828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 8000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccacf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccacf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a20b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 311
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcccda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcce4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd86c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcdfa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc5c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dccac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de749198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc42f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7c7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd70160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcca1b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dcc249b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 312
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dccfa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7816d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc781240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 313
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc779048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc78e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc10470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcc34e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc779128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc779438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc779748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 314
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6378652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 6
Completed Iteration #11
Best Reward: 0
coverage_call_count 8100
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f635afbf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7689e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637879b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7689e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a22e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 315
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f637868e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63580480f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 316
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 317
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd21cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ccc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc9071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 318
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6358048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 8200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd965f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc781ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 319
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd093c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd093c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 320
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc7811d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 321
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7f17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcf98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 322
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd3098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 8300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc978> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 323
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a0023438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd21c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dc768588> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 324
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c445cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dc781080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 325
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00e47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de762828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7623c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de762dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7623c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f630c433f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5dcc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 326
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f630c445cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 8400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd96358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de715e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc976208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de695e10> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 327
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd309cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd099b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc768630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3094a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de63b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de723240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cccf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 328
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd20cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de63b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63a00f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6eecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6facc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2cce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de723400> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 329
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f637872c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f63580d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dcd09630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc12ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6ee0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62df5b64e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 330
found coverage increase 0
Current Total Coverage 41.66666666666667
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd309278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 8500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3098d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dc7a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2ccd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd24e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dcd961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62df5a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5a77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f63a00e4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62df5dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1d0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc8f0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd22d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd3098d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de1b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd2f1470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de1b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62de7bcb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 331
found coverage increase 0
Current Total Coverage 41.66666666666667
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd25d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de605a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62dd2e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de605400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf65470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc055438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62de7ab400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62de7cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc9646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc0c7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fc964978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fc964080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62fdf7ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f62dd20c400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 332
found coverage increase 0
Current Total Coverage 41.66666666666667
initial coverage: 41.6667
time passed (minutes): 60.3797
iterations: 333
number of new inputs: 0
final coverage: 41.6667
total coverage increase: 0
