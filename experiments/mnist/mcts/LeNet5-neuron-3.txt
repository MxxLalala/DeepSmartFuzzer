Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fdf1c6b8f28>, tc2=<function tc2 at 0x7fdf1c6c9048>, tc3=<function tc3 at 0x7fdf1c6c9158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 66.7939
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 66.79389312977099
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01013c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 66.79389312977099
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0178390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aafd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aafd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aacc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 66.79389312977099
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 66.79389312977099
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 8
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 9
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 10
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 11
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 12
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 13
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 14
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 15
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 16
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 17
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.3816793893129784 18
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded001e7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.7633587786259568 19
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded002abe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 1.1450381679389352 20
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 1.1450381679389352 21
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003a470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 1.5267175572519136 22
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003abe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002abe0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 1.908396946564892 23
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded002a470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ab70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e7f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e320> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 2.2900763358778704 24
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded004c978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 2.671755725190849 25
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 2.671755725190849 26
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded006fdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 3.053435114503827 27
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded006f668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebfd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002abe0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 3.4351145038168056 28
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded001e940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ab70> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e7f0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e320> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 3.816793893129784 29
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded006f940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 4.198473282442762 30
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded00eb400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 4.580152671755741 31
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded00056d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 4.961832061068719 32
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e320> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 5.343511450381698 33
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded002a8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 5.725190839694676 34
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 6.106870229007654 35
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 6.488549618320633 36
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 6.870229007633611 37
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003acc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ae48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00056d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 7.25190839694659 38
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ae10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a2e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 7.633587786259568 39
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 8.015267175572546 40
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a048> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 8.015267175572546 41
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003afd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 8.396946564885525 42
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f0b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 8.778625954198503 43
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->5->17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded002aba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 9.160305343511482 44
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded00eb518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 9.54198473282446 30
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 9.54198473282446 45
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003a1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004cd30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002aba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 9.923664122137438 31
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 9.923664122137438 46
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded001e240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 10.305343511450417 47
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0099278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 10.687022900763395 48
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e50b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00056d8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 11.068702290076374 49
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb518> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 11.450381679389352 35
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 11.450381679389352 50
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2e8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 11.83206106870233 36
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 11.83206106870233 51
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 12.213740458015309 52
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 12.595419847328287 38
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 12.595419847328287 53
Completed Iteration #23
Best Reward: 0.3816793893129784
coverage_call_count 200
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 12.977099236641266 39
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 12.977099236641266 54
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->5->17->3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f54e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 11.450381679389352 32
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 13.358778625954244 40
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 13.358778625954244 55
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded001ef60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc18> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 11.83206106870233 33
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 13.740458015267222 41
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 13.740458015267222 56
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003af98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2e8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 12.213740458015309 34
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 14.1221374045802 42
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 14.1221374045802 57
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e59b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002aa20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 12.595419847328287 35
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 14.50381679389318 43
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 14.50381679389318 58
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e58d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c72b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e240> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 12.977099236641266 36
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 14.885496183206158 44
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 14.885496183206158 59
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c72b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e240> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 13.358778625954244 37
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 15.267175572519136 45
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 15.267175572519136 60
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded002aa20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 13.740458015267222 38
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 15.648854961832114 61
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f57b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e240> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 14.1221374045802 39
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 16.030534351145093 62
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2e8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 14.1221374045802 40
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 16.030534351145093 48
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 16.030534351145093 63
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->5->17->3->16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec6d8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c72b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e240> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 16.030534351145093 49
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 16.030534351145093 64
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 16.41221374045807 50
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 16.41221374045807 65
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 10.305343511450417 30
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 16.79389312977105 51
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 16.79389312977105 66
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0005f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 15.267175572519136 44
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 17.175572519084028 52
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 17.175572519084028 67
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 15.648854961832114 45
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 17.557251908397006 53
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 17.557251908397006 68
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec860> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 16.030534351145093 46
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 17.938931297709985 54
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 17.938931297709985 69
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 17.938931297709985 55
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 17.938931297709985 70
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f59e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 16.41221374045807 48
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 18.320610687022963 56
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 18.320610687022963 71
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87930f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b70> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 18.70229007633594 57
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 18.70229007633594 72
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 16.79389312977105 50
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 18.70229007633594 58
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 18.70229007633594 73
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->5->17->3->16->0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 12.595419847328287 38
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 17.175572519084028 51
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 19.08396946564892 59
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 19.08396946564892 74
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f59e8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 8.396946564885525 28
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 12.595419847328287 39
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 17.175572519084028 52
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 19.08396946564892 60
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 19.08396946564892 75
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 12.977099236641266 40
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 17.557251908397006 53
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 19.4656488549619 61
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 19.4656488549619 76
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 9.160305343511482 30
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 13.358778625954244 41
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 17.938931297709985 54
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 19.847328244274877 62
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 19.847328244274877 77
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1710> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 9.54198473282446 31
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 13.740458015267222 42
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 18.320610687022963 55
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 20.229007633587855 63
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 20.229007633587855 78
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 9.923664122137438 32
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 14.1221374045802 43
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 18.70229007633594 56
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 20.610687022900834 64
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 20.610687022900834 79
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 10.305343511450417 33
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 14.50381679389318 44
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 19.08396946564892 57
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 20.992366412213812 65
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 20.992366412213812 80
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 10.687022900763395 34
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 14.885496183206158 45
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 19.4656488549619 58
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 21.37404580152679 66
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 21.37404580152679 81
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f59e8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 6.870229007633611 24
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 10.687022900763395 35
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 14.885496183206158 46
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 19.4656488549619 59
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 21.37404580152679 67
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 21.37404580152679 82
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8747438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 7.25190839694659 25
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 11.068702290076374 36
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 15.267175572519136 47
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 19.847328244274877 60
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 21.75572519083977 68
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 21.75572519083977 83
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->5->17->3->16->0->0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 7.633587786259568 26
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 11.450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 15.648854961832114 48
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 20.229007633587855 61
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 22.137404580152747 69
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 22.137404580152747 84
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c77b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 8.015267175572546 27
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 11.83206106870233 38
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 16.030534351145093 49
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 20.610687022900834 62
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 22.519083969465726 70
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 22.519083969465726 85
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 8.396946564885525 28
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 12.213740458015309 39
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 16.41221374045807 50
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 20.992366412213812 63
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 22.900763358778704 71
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 22.900763358778704 86
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 12.595419847328287 40
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 16.79389312977105 51
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 21.37404580152679 64
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 23.282442748091682 72
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 23.282442748091682 87
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5a20> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 8.778625954198503 30
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 12.595419847328287 41
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 16.79389312977105 52
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 21.37404580152679 65
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 23.282442748091682 73
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 23.282442748091682 88
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8747160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 9.160305343511482 31
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 12.977099236641266 42
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 17.175572519084028 53
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 21.75572519083977 66
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 23.66412213740466 74
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 23.66412213740466 89
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8747dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 9.54198473282446 32
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 13.358778625954244 43
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 17.557251908397006 54
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 22.137404580152747 67
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 24.04580152671764 75
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 24.04580152671764 90
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 9.923664122137438 33
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 13.740458015267222 44
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 17.938931297709985 55
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 22.519083969465726 68
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 24.427480916030618 76
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 24.427480916030618 91
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8764a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87645c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 10.305343511450417 34
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 14.1221374045802 45
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 18.320610687022963 56
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 22.900763358778704 69
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 24.809160305343596 77
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 24.809160305343596 92
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 10.687022900763395 35
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 14.50381679389318 46
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 18.70229007633594 57
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 23.282442748091682 70
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 25.190839694656574 78
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 25.190839694656574 93
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->5->17->3->16->0->0->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87937b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764a20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87645c0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 11.068702290076374 36
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 14.885496183206158 47
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 19.08396946564892 58
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 23.66412213740466 71
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 25.572519083969553 79
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 25.572519083969553 94
Completed Iteration #1
Best Reward: 0.3816793893129784
coverage_call_count 300
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87645c0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 11.450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 15.267175572519136 48
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 19.4656488549619 59
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 24.04580152671764 72
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 25.95419847328253 80
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 25.95419847328253 95
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b12b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 11.83206106870233 38
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 15.648854961832114 49
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 19.847328244274877 60
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 24.427480916030618 73
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 26.33587786259551 81
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 26.33587786259551 96
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87645c0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 12.213740458015309 39
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 16.030534351145093 50
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 20.229007633587855 61
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 24.809160305343596 74
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 26.717557251908488 82
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 26.717557251908488 97
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 12.595419847328287 40
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 16.41221374045807 51
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 20.610687022900834 62
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 25.190839694656574 75
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 27.099236641221466 83
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 27.099236641221466 98
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8769f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 12.977099236641266 41
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 16.79389312977105 52
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 20.992366412213812 63
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 25.572519083969553 76
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 27.480916030534445 84
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 27.480916030534445 99
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870c4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1748> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 13.358778625954244 42
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 17.175572519084028 53
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 21.37404580152679 64
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 25.95419847328253 77
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 27.862595419847423 85
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 27.862595419847423 100
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1c50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 13.740458015267222 43
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 17.557251908397006 54
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 21.75572519083977 65
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 26.33587786259551 78
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 28.2442748091604 86
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 28.2442748091604 101
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 14.1221374045802 44
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 17.938931297709985 55
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 22.137404580152747 66
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 26.717557251908488 79
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 28.62595419847338 87
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 28.62595419847338 102
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 14.50381679389318 45
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 18.320610687022963 56
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 22.519083969465726 67
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 27.099236641221466 80
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 29.00763358778636 88
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 29.00763358778636 103
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87699b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 14.885496183206158 46
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 18.70229007633594 57
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 22.900763358778704 68
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 27.480916030534445 81
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 29.389312977099337 89
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 29.389312977099337 104
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8769860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 15.267175572519136 47
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 19.08396946564892 58
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 23.282442748091682 69
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 27.862595419847423 82
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 29.770992366412315 90
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 29.770992366412315 105
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870c828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87937b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8764a20> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87645c0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e10> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec160> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7fded0178da0> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7fded001e048> 15.648854961832114 48
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 19.4656488549619 59
backprop <src.mcts.MCTS_Node object at 0x7fded0005f60> 23.66412213740466 70
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 28.2442748091604 83
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 30.152671755725294 91
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 30.152671755725294 106
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->5->17->3->16->0->0->6->10
Best Reward: 0.3816793893129784
iteration: 4
found coverage increase 0.3816793893129784
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce80> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87691d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87691d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87691d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86beb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87201d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 15
Completed Iteration #23
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87695c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867da20> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.3816793893129784 13
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.3816793893129784 14
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.3816793893129784 15
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.3816793893129784 16
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86be6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 17
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 18
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 19
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 20
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 8
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 21
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 9
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 22
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 23
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 11
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 24
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 12
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 25
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 13
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 26
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 14
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 27
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 0.7633587786259568 15
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.7633587786259568 28
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 1.1450381679389352 16
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 1.1450381679389352 29
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec865a940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 1.5267175572519136 17
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 1.5267175572519136 30
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 1.5267175572519136 18
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 1.5267175572519136 31
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 1.908396946564892 19
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 1.908396946564892 32
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 1.908396946564892 20
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 1.908396946564892 33
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 1.908396946564892 21
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 1.908396946564892 34
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 22
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 35
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 23
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 36
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 24
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 37
Completed Iteration #19
Best Reward: 0.3816793893129784
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 25
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 38
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 26
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 39
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 27
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 40
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 28
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 41
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.2900763358778704 29
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.2900763358778704 42
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec864b4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 2.671755725190849 30
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 2.671755725190849 43
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870c668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.053435114503827 31
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.053435114503827 44
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdee88494e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.4351145038168056 32
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.4351145038168056 45
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8857668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.4351145038168056 33
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.4351145038168056 46
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee88494e0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.4351145038168056 34
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.4351145038168056 47
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee88494e0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.4351145038168056 35
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.4351145038168056 48
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.4351145038168056 36
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.4351145038168056 49
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.816793893129784 37
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.816793893129784 50
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0185748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 3.816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 3.816793893129784 38
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 3.816793893129784 51
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->0->19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec864be10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.198473282442762 18
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.198473282442762 39
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.198473282442762 52
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.198473282442762 40
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.198473282442762 53
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a940> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.198473282442762 41
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.198473282442762 54
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.198473282442762 42
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.198473282442762 55
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8690748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.580152671755741 43
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.580152671755741 56
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8690400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87208d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be6a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.961832061068719 23
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.961832061068719 44
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.961832061068719 57
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 4.961832061068719 45
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 4.961832061068719 58
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 5.343511450381698 46
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 5.343511450381698 59
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870cb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87208d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be6a0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 5.725190839694676 26
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 5.725190839694676 47
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 5.725190839694676 60
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be6a0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 5.725190839694676 48
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 5.725190839694676 61
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8747898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 28
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 49
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 62
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b4a8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8665400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 29
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 50
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 63
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->0->19->7
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864be10> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 30
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 51
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 64
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 52
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 65
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc50> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.908396946564892 11
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 25
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 32
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 53
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 66
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc50> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.908396946564892 12
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 33
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 54
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 67
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 1.908396946564892 13
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.106870229007654 55
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.106870229007654 68
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.2900763358778704 14
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.488549618320633 56
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.488549618320633 69
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc50> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.2900763358778704 15
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.961832061068719 29
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.488549618320633 57
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.488549618320633 70
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.2900763358778704 16
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.961832061068719 30
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.488549618320633 37
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.488549618320633 58
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.488549618320633 71
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.2900763358778704 17
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 4.961832061068719 31
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.488549618320633 38
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.488549618320633 59
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.488549618320633 72
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8764be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.671755725190849 18
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 5.343511450381698 32
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.870229007633611 39
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.870229007633611 60
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.870229007633611 73
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b358> 0.7633587786259568 8
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.671755725190849 19
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 5.343511450381698 33
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.870229007633611 40
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.870229007633611 61
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.870229007633611 74
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->0->19->7->12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ac8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747c50> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747898> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 2.671755725190849 20
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 5.343511450381698 34
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 6.870229007633611 41
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 6.870229007633611 62
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 6.870229007633611 75
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec864beb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 3.053435114503827 21
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 5.725190839694676 35
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 7.25190839694659 42
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 7.25190839694659 63
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 7.25190839694659 76
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 3.4351145038168056 22
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 6.106870229007654 36
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 7.633587786259568 43
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 7.633587786259568 64
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 7.633587786259568 77
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8764828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747898> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 3.816793893129784 23
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 6.488549618320633 37
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 8.015267175572546 65
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 8.015267175572546 78
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 4.198473282442762 24
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 8.396946564885525 66
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 8.396946564885525 79
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8769400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 4.580152671755741 25
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 8.778625954198503 67
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 8.778625954198503 80
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 7.633587786259568 40
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 9.160305343511482 68
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 9.160305343511482 81
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 8.015267175572546 41
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 9.54198473282446 48
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 9.54198473282446 69
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 9.54198473282446 82
Completed Iteration #19
Best Reward: 0.3816793893129784
coverage_call_count 600
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec864b550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 8.396946564885525 42
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 9.923664122137438 49
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 9.923664122137438 70
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 9.923664122137438 83
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 6.106870229007654 29
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 8.778625954198503 43
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 10.305343511450417 50
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 10.305343511450417 71
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 10.305343511450417 84
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->0->19->7->12->2
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01557f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 6.488549618320633 30
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 9.160305343511482 44
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 10.687022900763395 51
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 10.687022900763395 72
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 10.687022900763395 85
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded01557f0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 6.488549618320633 31
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 9.160305343511482 45
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 10.687022900763395 52
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 10.687022900763395 73
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 10.687022900763395 86
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdee8849710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 6.870229007633611 32
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 9.54198473282446 46
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 11.068702290076374 53
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 11.068702290076374 74
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 11.068702290076374 87
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01557f0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 7.25190839694659 33
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 9.923664122137438 47
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 11.450381679389352 54
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 11.450381679389352 75
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 11.450381679389352 88
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee8849710> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 7.25190839694659 34
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 9.923664122137438 48
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 11.450381679389352 55
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 11.450381679389352 76
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 11.450381679389352 89
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8764e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a15c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793780> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 7.633587786259568 35
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 10.305343511450417 49
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 11.83206106870233 56
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 11.83206106870233 77
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 11.83206106870233 90
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793780> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 7.633587786259568 36
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 10.305343511450417 50
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 11.83206106870233 57
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 11.83206106870233 78
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 11.83206106870233 91
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee8849710> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 7.633587786259568 37
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 10.305343511450417 51
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 11.83206106870233 58
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 11.83206106870233 79
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 11.83206106870233 92
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 8.015267175572546 38
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 10.687022900763395 52
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 12.213740458015309 59
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 12.213740458015309 80
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 12.213740458015309 93
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 6.870229007633611 24
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 8.396946564885525 39
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 11.068702290076374 53
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 12.595419847328287 60
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 12.595419847328287 81
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 12.595419847328287 94
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 8.396946564885525 40
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 11.068702290076374 54
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 12.595419847328287 61
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 12.595419847328287 82
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 12.595419847328287 95
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87643c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded01557f0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 7.25190839694659 26
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 8.778625954198503 41
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 11.450381679389352 55
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 12.977099236641266 62
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 12.977099236641266 83
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 12.977099236641266 96
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 7.633587786259568 27
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 9.160305343511482 42
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 11.83206106870233 56
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 13.358778625954244 63
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 13.358778625954244 84
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 13.358778625954244 97
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->0->19->7->12->2->29
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 8.015267175572546 28
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 9.54198473282446 43
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 12.213740458015309 57
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 13.740458015267222 64
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 13.740458015267222 85
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 13.740458015267222 98
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8764710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 4.580152671755741 18
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 8.396946564885525 29
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 9.923664122137438 44
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 12.595419847328287 58
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 14.1221374045802 65
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 14.1221374045802 86
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 14.1221374045802 99
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e59b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 8.778625954198503 30
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 10.305343511450417 45
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 12.977099236641266 59
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 14.50381679389318 66
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 14.50381679389318 87
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 14.50381679389318 100
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 9.160305343511482 31
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 10.687022900763395 46
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 13.358778625954244 60
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 14.885496183206158 67
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 14.885496183206158 88
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 14.885496183206158 101
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003ac18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 9.54198473282446 32
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 11.068702290076374 47
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 13.740458015267222 61
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 15.267175572519136 68
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 15.267175572519136 89
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 15.267175572519136 102
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->0->19->7->12->2->29->2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87e59e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 9.923664122137438 33
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 11.450381679389352 48
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 14.1221374045802 62
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 15.648854961832114 69
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 15.648854961832114 90
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 15.648854961832114 103
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 6.106870229007654 23
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 9.923664122137438 34
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 11.450381679389352 49
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 14.1221374045802 63
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 15.648854961832114 70
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 15.648854961832114 91
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 15.648854961832114 104
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003af28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19b0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 6.488549618320633 24
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 10.305343511450417 35
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 11.83206106870233 50
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 14.50381679389318 64
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 16.030534351145093 71
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 16.030534351145093 92
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 16.030534351145093 105
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec870c630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 10.687022900763395 36
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 12.213740458015309 51
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 14.885496183206158 65
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 16.41221374045807 72
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 16.41221374045807 93
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 16.41221374045807 106
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded003ae10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 7.25190839694659 26
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 11.068702290076374 37
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 12.595419847328287 52
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 15.267175572519136 66
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 16.79389312977105 73
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 16.79389312977105 94
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 16.79389312977105 107
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c78d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19b0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 7.633587786259568 27
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 11.450381679389352 38
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 12.977099236641266 53
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 15.648854961832114 67
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 17.175572519084028 74
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 17.175572519084028 95
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 17.175572519084028 108
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ae10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 8.015267175572546 28
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 11.83206106870233 39
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 13.358778625954244 54
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 16.030534351145093 68
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 17.557251908397006 75
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 17.557251908397006 96
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 17.557251908397006 109
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 8.015267175572546 29
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 11.83206106870233 40
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 13.358778625954244 55
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 16.030534351145093 69
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 17.557251908397006 76
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 17.557251908397006 97
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 17.557251908397006 110
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 8.015267175572546 30
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 11.83206106870233 41
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 13.358778625954244 56
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 16.030534351145093 70
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 17.557251908397006 77
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 17.557251908397006 98
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 17.557251908397006 111
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 8.396946564885525 31
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 12.213740458015309 42
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 13.740458015267222 57
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 16.41221374045807 71
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 17.938931297709985 78
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 17.938931297709985 99
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 17.938931297709985 112
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fdec870c160> 8.778625954198503 32
backprop <src.mcts.MCTS_Node object at 0x7fdec8747f60> 12.595419847328287 43
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 14.1221374045802 58
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a90> 16.79389312977105 72
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6978> 18.320610687022963 79
backprop <src.mcts.MCTS_Node object at 0x7fdec8690080> 18.320610687022963 100
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 18.320610687022963 113
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->0->19->7->12->2->29->2->12
Best Reward: 0.3816793893129784
iteration: 10
found coverage increase 0.3816793893129784
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded002a438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e51d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0178358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01667b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fded00aa518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0178358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 800
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aac18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeeac41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.3816793893129784 10
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded006feb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.7633587786259568 11
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00051d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.7633587786259568 12
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 0.7633587786259568 13
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec867deb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 1.1450381679389352 14
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 1.5267175572519136 15
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 1.5267175572519136 16
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded004c7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 1.908396946564892 17
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 2.2900763358778704 18
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006feb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 2.2900763358778704 19
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded01bafd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 2.671755725190849 20
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867deb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 3.053435114503827 21
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 3.4351145038168056 22
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 3.816793893129784 23
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86d26d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 4.198473282442762 24
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86d24a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d6d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 4.580152671755741 25
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d24a8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867d6d8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 4.580152671755741 26
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec867df28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 4.961832061068719 27
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 5.343511450381698 28
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806da518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86653c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d26d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 5.725190839694676 29
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 5.725190839694676 30
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 5.725190839694676 31
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806e99e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bafd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 6.106870229007654 32
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bafd0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 6.106870229007654 23
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 6.106870229007654 33
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 6.488549618320633 24
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 6.488549618320633 34
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0166128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 6.870229007633611 35
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 7.25190839694659 26
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 7.25190839694659 36
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0005b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00055c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 7.633587786259568 27
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 7.633587786259568 37
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec867db38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 8.015267175572546 28
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 8.015267175572546 38
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005b70> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded00055c0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5f8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c400> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 8.015267175572546 29
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 8.015267175572546 39
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0099d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 8.396946564885525 30
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 8.396946564885525 40
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->4->14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 8.778625954198503 31
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 8.778625954198503 41
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166128> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 9.160305343511482 32
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 9.160305343511482 42
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806dafd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 9.54198473282446 33
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 9.54198473282446 43
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 9.923664122137438 34
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 9.923664122137438 44
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806e9b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86659b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dafd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 10.305343511450417 35
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 10.305343511450417 45
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806814e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 10.687022900763395 36
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 10.687022900763395 46
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0099dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.068702290076374 37
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.068702290076374 47
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2390> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 6.870229007633611 24
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.068702290076374 38
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.068702290076374 48
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0005eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dafd0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 7.25190839694659 25
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.450381679389352 39
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.450381679389352 49
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa4a8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde806dafd0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 7.25190839694659 26
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.450381679389352 40
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.450381679389352 50
Completed Iteration #17
Best Reward: 0.3816793893129784
coverage_call_count 900
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 7.25190839694659 27
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.450381679389352 41
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.450381679389352 51
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa4a8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fde806dafd0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 7.25190839694659 28
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.450381679389352 42
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.450381679389352 52
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 7.25190839694659 29
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.450381679389352 43
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.450381679389352 53
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8665470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9dd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.580152671755741 18
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 7.633587786259568 30
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 11.83206106870233 44
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 11.83206106870233 54
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->4->14->6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806815f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 12.213740458015309 45
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 12.213740458015309 55
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806815f8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.961832061068719 20
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 8.015267175572546 32
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 12.213740458015309 46
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 12.213740458015309 56
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 4.961832061068719 21
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 8.015267175572546 33
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 12.213740458015309 47
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 12.213740458015309 57
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 5.343511450381698 22
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 8.396946564885525 34
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 12.595419847328287 48
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 12.595419847328287 58
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fded0166a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 5.725190839694676 23
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 8.778625954198503 35
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 12.977099236641266 49
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 12.977099236641266 59
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 5.725190839694676 24
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 8.778625954198503 36
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 12.977099236641266 50
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 12.977099236641266 60
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 6.106870229007654 25
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 9.160305343511482 37
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 13.358778625954244 51
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 13.358778625954244 61
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 6.488549618320633 26
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 9.54198473282446 38
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 13.740458015267222 52
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 13.740458015267222 62
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80697be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 6.870229007633611 27
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 9.923664122137438 39
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 14.1221374045802 53
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 14.1221374045802 63
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80697c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 7.25190839694659 28
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 10.305343511450417 40
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 14.50381679389318 54
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 14.50381679389318 64
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->4->14->6->1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 10.687022900763395 41
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 14.885496183206158 55
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 14.885496183206158 65
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806815f8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 7.633587786259568 30
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 10.687022900763395 42
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 14.885496183206158 56
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 14.885496183206158 66
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806b2748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697be0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 11.068702290076374 43
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 15.267175572519136 57
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 15.267175572519136 67
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8063e630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 8.396946564885525 32
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 11.450381679389352 44
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 15.648854961832114 58
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 15.648854961832114 68
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8063ed30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099dd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 8.778625954198503 33
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 11.83206106870233 45
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 16.030534351145093 59
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 16.030534351145093 69
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec8665588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 9.160305343511482 34
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 12.213740458015309 46
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 16.41221374045807 60
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 16.41221374045807 70
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806817f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806977f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 9.54198473282446 35
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 12.595419847328287 47
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 16.79389312977105 61
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 16.79389312977105 71
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806b2320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b20b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697be0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 9.923664122137438 36
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 12.977099236641266 48
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 17.175572519084028 62
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 17.175572519084028 72
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8063e4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099dd8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 10.305343511450417 37
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 13.358778625954244 49
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 17.557251908397006 63
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 17.557251908397006 73
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80697f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b22b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2748> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2ef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde80697be0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 10.687022900763395 38
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 13.740458015267222 50
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 17.938931297709985 64
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 17.938931297709985 74
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8063eda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 7.633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 11.068702290076374 39
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 14.1221374045802 51
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 18.320610687022963 65
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 18.320610687022963 75
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80658f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c6a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 11.450381679389352 40
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 14.50381679389318 52
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 18.70229007633594 66
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 18.70229007633594 76
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->4->14->6->1->0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806580f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 11.83206106870233 41
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 14.885496183206158 53
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 19.08396946564892 67
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 19.08396946564892 77
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697c88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde80697518> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 12.213740458015309 42
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 15.267175572519136 54
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 19.4656488549619 68
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 19.4656488549619 78
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80658a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 12.595419847328287 43
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 15.648854961832114 55
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 19.847328244274877 69
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 19.847328244274877 79
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806b2160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9be0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 9.54198473282446 30
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 12.977099236641266 44
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 16.030534351145093 56
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 20.229007633587855 70
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 20.229007633587855 80
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80681eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806976d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 9.923664122137438 31
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 13.358778625954244 45
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 16.41221374045807 57
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 20.610687022900834 71
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 20.610687022900834 81
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 13.740458015267222 46
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 16.79389312977105 58
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 20.992366412213812 72
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 20.992366412213812 82
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8066c748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 14.1221374045802 47
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 17.175572519084028 59
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 21.37404580152679 73
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 21.37404580152679 83
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c748> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 10.687022900763395 34
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 14.1221374045802 48
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 17.175572519084028 60
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 21.37404580152679 74
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 21.37404580152679 84
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8066cfd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 11.068702290076374 35
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 14.50381679389318 49
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 17.557251908397006 61
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 21.75572519083977 75
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 21.75572519083977 85
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->4->14->6->1->0->0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806775f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 11.450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 14.885496183206158 50
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 17.938931297709985 62
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 22.137404580152747 76
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 22.137404580152747 86
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 11.068702290076374 35
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 11.450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 14.885496183206158 51
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 17.938931297709985 63
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 22.137404580152747 77
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 22.137404580152747 87
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80681cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 11.450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 11.83206106870233 38
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 15.267175572519136 52
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 18.320610687022963 64
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 22.519083969465726 78
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 22.519083969465726 88
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806971d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806582b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cfd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 11.83206106870233 37
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 12.213740458015309 39
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 15.648854961832114 53
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 18.70229007633594 65
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 22.900763358778704 79
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 22.900763358778704 89
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80658080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 12.213740458015309 38
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 12.595419847328287 40
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 16.030534351145093 54
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 19.08396946564892 66
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 23.282442748091682 80
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 23.282442748091682 90
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 12.213740458015309 39
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 12.595419847328287 41
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 16.030534351145093 55
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 19.08396946564892 67
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 23.282442748091682 81
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 23.282442748091682 91
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80677b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 12.595419847328287 40
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 12.977099236641266 42
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 16.41221374045807 56
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 19.4656488549619 68
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 23.66412213740466 82
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 23.66412213740466 92
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806772b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 12.977099236641266 41
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 13.358778625954244 43
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 16.79389312977105 57
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 19.847328244274877 69
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 24.04580152671764 83
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 24.04580152671764 93
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658080> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 13.358778625954244 42
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 13.740458015267222 44
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 17.175572519084028 58
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 20.229007633587855 70
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 24.427480916030618 84
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 24.427480916030618 94
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
coverage_call_count 1000
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 7.633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 13.358778625954244 43
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 13.740458015267222 45
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 17.175572519084028 59
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 20.229007633587855 71
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 24.427480916030618 85
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 24.427480916030618 95
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->4->14->6->1->0->0->7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806973c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 13.740458015267222 44
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 14.1221374045802 46
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 17.557251908397006 60
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 20.610687022900834 72
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 24.809160305343596 86
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 24.809160305343596 96
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80658e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 14.1221374045802 45
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 14.50381679389318 47
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 17.938931297709985 61
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 20.992366412213812 73
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 25.190839694656574 87
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 25.190839694656574 97
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80658048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681cf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 14.50381679389318 46
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 14.885496183206158 48
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 18.320610687022963 62
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 21.37404580152679 74
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 25.572519083969553 88
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 25.572519083969553 98
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80677908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde806582b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066cfd0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 14.885496183206158 47
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 15.267175572519136 49
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 18.70229007633594 63
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 21.75572519083977 75
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 25.95419847328253 89
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 25.95419847328253 99
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80677da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 9.54198473282446 30
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 15.267175572519136 48
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 15.648854961832114 50
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 19.08396946564892 64
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 22.137404580152747 76
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 26.33587786259551 90
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 26.33587786259551 100
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde6afdba58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 9.923664122137438 31
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 15.648854961832114 49
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 16.030534351145093 51
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 19.4656488549619 65
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 22.519083969465726 77
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 26.717557251908488 91
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 26.717557251908488 101
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde8066c320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afceeb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681cf8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 16.030534351145093 50
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 16.41221374045807 52
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 19.847328244274877 66
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 22.900763358778704 78
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 27.099236641221466 92
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 27.099236641221466 102
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681cf8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 16.41221374045807 51
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 16.79389312977105 53
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 20.229007633587855 67
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 23.282442748091682 79
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 27.480916030534445 93
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 27.480916030534445 103
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde80658e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec88> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 16.79389312977105 52
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 17.175572519084028 54
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 20.610687022900834 68
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 23.66412213740466 80
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 27.862595419847423 94
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 27.862595419847423 104
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde806771d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 11.450381679389352 35
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 17.175572519084028 53
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 17.557251908397006 55
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 20.992366412213812 69
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 24.04580152671764 81
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 28.2442748091604 95
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 28.2442748091604 105
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 11.83206106870233 36
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 17.557251908397006 54
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 17.938931297709985 56
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 21.37404580152679 70
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 24.427480916030618 82
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 28.62595419847338 96
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 28.62595419847338 106
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbcf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd68> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7fdec867d978> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7fde80697940> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 17.938931297709985 55
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 18.320610687022963 57
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 21.75572519083977 71
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 24.809160305343596 83
backprop <src.mcts.MCTS_Node object at 0x7fded00e0fd0> 29.00763358778636 97
backprop <src.mcts.MCTS_Node object at 0x7fded006f9b0> 29.00763358778636 107
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->4->14->6->1->0->0->7->3
Best Reward: 0.3816793893129784
iteration: 16
found coverage increase 0.3816793893129784
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbe80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 11
Completed Iteration #16
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f28> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af502e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af502e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af502e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af28> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed45c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af50588> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dda0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7e48> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae532b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681622b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681625f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681506a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681622b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681508d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681506a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681506a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68162320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681629e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681629e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af506d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af506d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681788d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68130470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0178240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68120438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806972b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806daf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806daf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806e9d68> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0101588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 67.93893129770993
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806979e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 11
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dada0> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee894dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00993c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00eb550> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6813e940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc18> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e99e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0185748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e99e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8857668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87a18d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf347883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ece10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c7b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01552b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c908> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01554e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01554e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01556a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01554e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003ab70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87eccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870ccf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681307b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf34788160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ef0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86eccf8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681780b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681207b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681785c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681785c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681785c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806810f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2240> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681306d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde68120898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aefff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aefff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf34788160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce5f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6470> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681629b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681629b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aefff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6aeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aefff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806776a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806776a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 2500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80658d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01662e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01662e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68162588> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8451d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8451d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8451d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e8450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e8459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf34788160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681509b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c105278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86bee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86beeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8935358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86bee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec865ada0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee88494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee88495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee894dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8857668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee88492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ae48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0170d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ffef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded003a9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8935358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87692b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87692b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5828> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee88494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee88492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf347883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf34788160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde8063e898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 11
Completed Iteration #20
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150978> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87697b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87697b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681789b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee8935048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806817f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ca20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8935358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde806b2358> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e8459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3278> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806daf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8923fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806daf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8690c50> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e8459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e8453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806da748> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80658c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde680ddcc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 5
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 6
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 7
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 8
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86900f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 9
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6813e2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.3816793893129642 13
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6af50be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ec18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e2b0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.7633587786259284 14
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.7633587786259284 15
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e2b0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.7633587786259284 16
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 0.7633587786259284 6
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 0.7633587786259284 17
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 1.1450381679388926 7
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 1.1450381679388926 18
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 1.5267175572518568 8
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 1.5267175572518568 19
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6af50780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 1.908396946564821 9
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 1.908396946564821 20
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde68130c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 2.290076335877785 10
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 2.290076335877785 21
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6aee72e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e2b0> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 2.6717557251907493 11
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 2.6717557251907493 22
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb57b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 3.0534351145037135 23
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 3.4351145038166777 24
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde681309e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 3.816793893129642 25
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde806771d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e2b0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 4.198473282442606 26
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
coverage_call_count 3400
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 4.198473282442606 27
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681309e8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2c88> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 4.198473282442606 17
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 4.198473282442606 28
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 4.198473282442606 18
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 4.198473282442606 29
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 4.58015267175557 19
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 4.58015267175557 30
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6af0db70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 4.9618320610685345 20
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 4.9618320610685345 31
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 5.343511450381499 21
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 5.343511450381499 32
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 5.725190839694463 22
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 5.725190839694463 33
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 6.106870229007427 23
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 6.106870229007427 34
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 6.488549618320391 24
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 6.488549618320391 35
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6813ea58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7470> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 6.870229007633355 36
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 6.870229007633355 26
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 6.870229007633355 37
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde80677c88> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 7.25190839694632 27
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 7.25190839694632 38
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde68130358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7470> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 7.633587786259284 28
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 7.633587786259284 39
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->8->6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 8.015267175572248 29
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 8.015267175572248 40
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 8.396946564885212 41
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 8.778625954198176 42
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde80677208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 9.16030534351114 43
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->8->6->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde3c637b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 9.541984732824105 44
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde3c6529e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 9.923664122137069 45
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 9.923664122137069 35
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 9.923664122137069 46
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 9.923664122137069 36
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 9.923664122137069 47
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->8->6->0->2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 10.305343511450033 37
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 10.305343511450033 48
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 10.687022900762997 38
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 10.687022900762997 49
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde3c646470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6529e8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 11.068702290075962 39
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 11.068702290075962 50
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 2.6717557251907493 11
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 11.068702290075962 40
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 11.068702290075962 51
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247db550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 11.450381679388926 41
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 11.450381679388926 52
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646f98> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fde80677208> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 2.6717557251907493 11
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 3.0534351145037135 13
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 8.015267175572248 27
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 11.450381679388926 42
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 11.450381679388926 53
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
coverage_call_count 3500
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->8->6->0->2->8
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 3.4351145038166777 14
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 8.396946564885212 28
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 11.83206106870189 43
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 11.83206106870189 54
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde4c1154a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 3.816793893129642 15
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 8.778625954198176 29
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 12.213740458014854 44
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 12.213740458014854 55
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247db1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 9.16030534351114 30
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 12.595419847327818 45
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 12.595419847327818 56
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247dbf28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 4.58015267175557 17
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 6.870229007633355 23
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 9.541984732824105 31
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 12.977099236640782 46
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 12.977099236640782 57
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->8->6->0->2->8->8
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24791550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 4.9618320610685345 18
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 9.923664122137069 32
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 13.358778625953747 47
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 13.358778625953747 58
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24791a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 10.305343511450033 33
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 13.74045801526671 59
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24798550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 10.687022900762997 34
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 14.122137404579675 49
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 14.122137404579675 60
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247989b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 8.396946564885212 27
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 11.068702290075962 35
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 14.50381679389264 50
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 14.50381679389264 61
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24798fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 8.778625954198176 28
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 11.450381679388926 36
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 14.885496183205603 51
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 14.885496183205603 62
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->8->6->0->2->8->8->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24791f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652b70> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 6.870229007633355 23
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 9.16030534351114 29
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 11.83206106870189 37
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 15.267175572518568 52
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 15.267175572518568 63
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24798518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652b70> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 9.541984732824105 30
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 12.213740458014854 38
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 15.648854961831532 53
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 15.648854961831532 64
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde24798c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 9.923664122137069 31
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 12.595419847327818 39
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 16.030534351144496 54
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 16.030534351144496 65
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247a9eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652b70> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 10.305343511450033 32
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 12.977099236640782 40
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 16.41221374045746 55
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 16.41221374045746 66
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652b70> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fde4c1155f8> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7fde6af0da58> 8.396946564885212 27
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb52e8> 10.687022900762997 33
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 13.358778625953747 41
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 16.793893129770424 56
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8eb8> 16.793893129770424 67
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->8->6->0->2->8->8->0->9
Best Reward: 0.3816793893129642
iteration: 108
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247455c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247455c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247457f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247457f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247454e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247457f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247985f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24759c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247077f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 3700
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24759eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247454e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247454e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a940> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2468be80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 4000
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bf60> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0379ba90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037189e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2465c588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646550> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681203c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80677208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0166278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6374a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c637160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c6371d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af50a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aefff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6afce160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.32061068702289
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806dac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb03c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87642e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681628d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0155048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806580b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6375c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 15
Completed Iteration #21
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde80681550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247dbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeeac41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f630> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee8849630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afcee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8769710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee8849630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdee8849630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aea67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded002a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec870cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee894dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00eb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793a90> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdec8793978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded003a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aac50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68150320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8459b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86be160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 4700
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e8456a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ecdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1683c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037450b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae535f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f80b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037455c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037458d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0005438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03745470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247072e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8747438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aea67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 4900
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247916d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247916d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247916d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247599b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d19e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a88d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c10b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2471a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037458d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa20> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00fff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 3
Completed Iteration #5
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24745cc0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00fff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b9e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379bd68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba20> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b20b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
coverage_call_count 5600
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017480b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01748b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0171a4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017000f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017006d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017486a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5800
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c646f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017486a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016853c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01685438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0173f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c646b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afdb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 5900
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bcc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016852e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01685400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde016f8dd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247988d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247988d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246a8710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246c14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24798dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded003af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037b4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde037b4a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 6000
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247a9358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24707438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8747588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2468b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24707ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d1400> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016856d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016856d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c8ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde246d13c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 6100
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2471a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681503c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806e9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681503c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1684e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1684e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86be978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dc358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c1051d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246a8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2471ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681502e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247e8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247459b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01748b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68150908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ec278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde24791470> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec865a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded00ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded004ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec865a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec867dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded004c438> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee89921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde680ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c1681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2472eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037ecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c105710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded004c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cb95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c105978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8063e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8063e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0379b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87b1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f89e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeeac41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6300
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae8df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded001ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded00aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8923fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68178b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde4c13c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aeffa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afbd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68178c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86ecc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d780> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aefffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cb95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded002ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24791f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aefffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01748828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c13ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0173f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded07af7b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2469e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec867d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4e845d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde680ddda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0099d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde681627f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 68.32061068702289
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8764198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec870c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af50400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c1159e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80658128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c9bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded0170da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8665898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4e845080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0155748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aec4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6af6a048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af8b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde68130c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68130e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2468b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8769b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec864bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24745be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded0166278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde806772e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdeea9d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dba20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde247db208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afb09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0379b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aff3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6afb00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde24759b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813eda0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8935358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde016f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2469e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c168be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2472ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded01553c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68162278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde8066cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 19
Completed Iteration #19
Best Reward: 0
coverage_call_count 6600
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde03718828> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a77b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6ae53b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8690ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c6d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80658438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8690f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68162208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde037c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03745860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded01662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c115cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68130e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c637c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde037c1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0377d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247dbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fded006fef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec86d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded001e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813ef98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017a7390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2465c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bda0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80681dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde8066c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 6700
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80681a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aed4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0173f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde247db908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aeb5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6afce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde80677240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde806b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde2466abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03745860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde4c0f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c652128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0372ae48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec864b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fded006f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde4c115cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde017c8320> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0377d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde806b2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0171a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde681205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0372a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde03718588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdee8849630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017edda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017007b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6af0d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde80697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c7b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6813e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017dceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cf6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde68120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0172c828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2465cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 6900
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c652128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde681300b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde247db908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0372aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01cc1400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb00> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03770f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde24759e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde806b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d7b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec8793470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0175be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00887550> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7000
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde3c637e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0171ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0172c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0172ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0377d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0171a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde00887358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde6aee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdec87209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bda90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bdf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde3c6372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c34898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0084cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde008bd080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008310b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008226a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0175bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde00822f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde2466a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c340f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008311d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00831b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0085ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01700128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008311d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008311d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008f3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0169c5c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde008bda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003c4da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0169ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00831198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde017000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038eef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0085e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde03718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0084cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c0fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0084cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde01c0f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fde0038e710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 7300
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0080e940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003051d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00305438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00305470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00305cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003059e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00305b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde008bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0036cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003058d0> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0039da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01d2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00887940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01c34400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00822f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0080e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00305128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0085ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0080e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00305dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00305470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0038e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0035b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde246d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0039de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde01cd2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00822550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde003b5908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0035bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00316208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00316518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde0036c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00316a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde003165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003f97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00316f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003b5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00316eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde00316668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde002c54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde002c54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde00316a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002c5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde003c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fde002d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fde0038e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fde0038e4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 68.32061068702289
initial coverage: 66.7939
time passed (minutes): 60.2106
iterations: 258
number of new inputs: 256
final coverage: 68.3206
total coverage increase: 1.52672
