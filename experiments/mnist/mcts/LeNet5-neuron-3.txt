Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f7b3ec2ef28>, tc2=<function tc2 at 0x7f7b3ec3d048>, tc3=<function tc3 at 0x7f7b3ec3d158>, tfc_threshold=3300000, time_period=3600, verbose=True)
initial coverage: 67.1756
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc72afd0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65be80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc732c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.3816793893129784 6
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.3816793893129784 7
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 0.7633587786259568 8
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 1.1450381679389352 9
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 1.1450381679389352 10
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 1.5267175572519136 11
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 1.908396946564892 12
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 2.2900763358778704 13
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 2.671755725190849 14
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 3.053435114503827 15
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 3.053435114503827 16
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47894e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 3.4351145038168056 17
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a14e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 3.816793893129784 18
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 3.816793893129784 19
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f57b8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.198473282442762 20
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.580152671755741 21
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.580152671755741 22
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.580152671755741 23
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.580152671755741 24
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.580152671755741 25
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aad30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.580152671755741 18
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 4.961832061068719 26
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 5.343511450381698 27
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 5.725190839694676 28
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789cc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 6.106870229007654 29
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ea90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a90> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 6.488549618320633 30
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc69f9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a90> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 6.870229007633611 31
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1e48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 6.870229007633611 24
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 7.25190839694659 32
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaf98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 7.25190839694659 25
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 7.633587786259568 33
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a14e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 7.633587786259568 26
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 8.015267175572546 34
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 8.015267175572546 27
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 8.396946564885525 35
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1be0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 8.396946564885525 28
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 8.778625954198503 36
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 9.160305343511482 37
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bf98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 9.160305343511482 30
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 9.54198473282446 38
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc7366a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1be0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1898> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 9.54198473282446 31
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 9.923664122137438 39
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b40b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a14e0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 9.923664122137438 32
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 10.305343511450417 40
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 10.305343511450417 33
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 10.687022900763395 41
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 10.687022900763395 34
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 11.068702290076374 42
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->5->18
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 11.068702290076374 35
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 11.450381679389352 43
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 11.450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 11.83206106870233 44
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 11.83206106870233 37
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 12.213740458015309 45
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc645fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccf8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 12.213740458015309 38
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 12.595419847328287 46
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789710> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 12.595419847328287 39
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 12.977099236641266 47
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ced30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b41d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789438> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 12.977099236641266 40
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 13.358778625954244 48
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789710> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 13.358778625954244 41
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 13.740458015267222 49
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ca90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 13.740458015267222 42
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 14.1221374045802 50
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cc18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c0b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 14.1221374045802 43
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 14.50381679389318 51
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
coverage_call_count 200
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ced30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b41d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789438> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 14.50381679389318 44
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 14.885496183206158 52
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce8d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789710> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 14.885496183206158 45
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 15.267175572519136 53
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->5->18->0
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 2.671755725190849 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 8.778625954198503 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 11.83206106870233 31
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 16.030534351145093 54
Completed Iteration #3
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47009e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789cc0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 3.053435114503827 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 9.160305343511482 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 12.213740458015309 32
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 16.41221374045807 55
Completed Iteration #4
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 1.5267175572519136 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 3.4351145038168056 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 9.54198473282446 25
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 12.595419847328287 33
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 16.41221374045807 48
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 16.79389312977105 56
Completed Iteration #5
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 3.816793893129784 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 9.923664122137438 26
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 12.977099236641266 34
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 17.175572519084028 57
Completed Iteration #6
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752c18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 1.908396946564892 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 4.198473282442762 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 10.305343511450417 27
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 13.358778625954244 35
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 17.175572519084028 50
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 17.557251908397006 58
Completed Iteration #7
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 4.580152671755741 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 10.687022900763395 28
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 13.740458015267222 36
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 17.557251908397006 51
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 17.938931297709985 59
Completed Iteration #8
Best Reward: 0.7633587786259568
Completed Iteration #9
Best Reward: 0.7633587786259568
Completed Iteration #10
Best Reward: 0.7633587786259568
Completed Iteration #11
Best Reward: 0.7633587786259568
Completed Iteration #12
Best Reward: 0.7633587786259568
Completed Iteration #13
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789cc0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 4.961832061068719 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 11.068702290076374 29
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 14.1221374045802 37
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 17.938931297709985 52
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 18.320610687022963 60
Completed Iteration #14
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 5.343511450381698 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 11.450381679389352 30
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 14.50381679389318 38
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 18.320610687022963 53
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 18.70229007633594 61
Completed Iteration #15
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc50> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 5.725190839694676 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 11.83206106870233 31
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 14.885496183206158 39
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 18.70229007633594 54
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 19.08396946564892 62
Completed Iteration #16
Best Reward: 0.7633587786259568
Completed Iteration #17
Best Reward: 0.7633587786259568
Completed Iteration #18
Best Reward: 0.7633587786259568
Completed Iteration #19
Best Reward: 0.7633587786259568
Completed Iteration #20
Best Reward: 0.7633587786259568
Completed Iteration #21
Best Reward: 0.7633587786259568
Completed Iteration #22
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 2.2900763358778704 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 6.106870229007654 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 12.213740458015309 32
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 15.267175572519136 40
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 19.08396946564892 55
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 19.4656488549619 63
Completed Iteration #23
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dbe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789cc0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 6.488549618320633 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 12.595419847328287 33
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 15.648854961832114 41
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 19.4656488549619 56
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 19.847328244274877 64
Completed Iteration #24
Best Reward: 0.7633587786259568
Completed Iteration #25
Best Reward: 0.7633587786259568
Completed MCTS Level/Depth: #4
root->5->18->0->3
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac471de80> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4898> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752c18> 1.5267175572519136 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 3.053435114503827 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 7.25190839694659 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 13.358778625954244 34
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 16.41221374045807 42
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 20.229007633587855 57
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 20.610687022900834 65
Completed Iteration #0
Best Reward: 0.7633587786259568
Completed Iteration #1
Best Reward: 0.7633587786259568
Completed Iteration #2
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47276d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 1.5267175572519136 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 3.4351145038168056 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 7.633587786259568 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 13.740458015267222 35
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 16.79389312977105 43
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 20.610687022900834 58
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 20.992366412213812 66
Completed Iteration #3
Best Reward: 0.7633587786259568
Completed Iteration #4
Best Reward: 0.7633587786259568
Completed Iteration #5
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752c18> 1.908396946564892 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 3.816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 8.015267175572546 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 14.1221374045802 36
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 17.175572519084028 44
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 20.992366412213812 59
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 21.37404580152679 67
Completed Iteration #6
Best Reward: 0.7633587786259568
Completed Iteration #7
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c860> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 2.2900763358778704 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 4.580152671755741 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 8.778625954198503 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 14.885496183206158 37
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 17.938931297709985 45
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 21.75572519083977 60
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 22.137404580152747 68
Completed Iteration #8
Best Reward: 0.7633587786259568
Completed Iteration #9
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cc88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 4.961832061068719 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 9.160305343511482 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 15.267175572519136 38
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 18.320610687022963 46
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 22.137404580152747 61
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 22.519083969465726 69
Completed Iteration #10
Best Reward: 0.7633587786259568
Completed Iteration #11
Best Reward: 0.7633587786259568
Completed Iteration #12
Best Reward: 0.7633587786259568
Completed Iteration #13
Best Reward: 0.7633587786259568
Completed Iteration #14
Best Reward: 0.7633587786259568
Completed Iteration #15
Best Reward: 0.7633587786259568
Completed Iteration #16
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 5.343511450381698 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 9.54198473282446 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 15.648854961832114 39
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 18.70229007633594 47
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 22.519083969465726 62
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 22.900763358778704 70
Completed Iteration #17
Best Reward: 0.7633587786259568
Completed Iteration #18
Best Reward: 0.7633587786259568
Completed Iteration #19
Best Reward: 0.7633587786259568
Completed Iteration #20
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47272b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cc88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 5.725190839694676 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 9.923664122137438 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 16.030534351145093 40
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 19.08396946564892 48
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 22.900763358778704 63
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 23.282442748091682 71
Completed Iteration #21
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700dd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 6.106870229007654 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 10.305343511450417 25
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 16.41221374045807 41
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 19.4656488549619 49
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 23.282442748091682 64
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 23.66412213740466 72
Completed Iteration #22
Best Reward: 0.7633587786259568
Completed Iteration #23
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727080> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700dd8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 6.488549618320633 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 10.687022900763395 26
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 16.79389312977105 42
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 19.847328244274877 50
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 23.66412213740466 65
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 24.04580152671764 73
Completed Iteration #24
Best Reward: 0.7633587786259568
Completed Iteration #25
Best Reward: 0.7633587786259568
Completed MCTS Level/Depth: #5
root->5->18->0->3->6
Best Reward: 0.7633587786259568
Completed Iteration #0
Best Reward: 0.7633587786259568
Completed Iteration #1
Best Reward: 0.7633587786259568
Completed Iteration #2
Best Reward: 0.7633587786259568
Completed Iteration #3
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bee10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c860> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 2.671755725190849 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 6.870229007633611 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 11.068702290076374 27
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 17.175572519084028 43
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 20.229007633587855 51
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 24.04580152671764 66
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 24.427480916030618 74
Completed Iteration #4
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46beef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 1.5267175572519136 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 3.053435114503827 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 7.25190839694659 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 11.450381679389352 28
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 17.557251908397006 44
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 20.610687022900834 52
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 24.427480916030618 67
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 24.809160305343596 75
Completed Iteration #5
Best Reward: 0.7633587786259568
Completed Iteration #6
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 1.908396946564892 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 3.4351145038168056 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 7.633587786259568 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 11.83206106870233 29
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 17.938931297709985 45
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 20.992366412213812 53
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 24.809160305343596 68
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 25.190839694656574 76
Completed Iteration #7
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d780> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 3.816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 8.015267175572546 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 12.213740458015309 30
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 18.320610687022963 46
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 21.37404580152679 54
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 25.190839694656574 69
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 25.572519083969553 77
Completed Iteration #8
Best Reward: 0.7633587786259568
Completed Iteration #9
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 2.2900763358778704 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 4.198473282442762 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 8.396946564885525 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 12.595419847328287 31
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 18.70229007633594 47
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 21.75572519083977 55
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 25.572519083969553 70
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 25.95419847328253 78
Completed Iteration #10
Best Reward: 0.7633587786259568
Completed Iteration #11
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 3.053435114503827 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 4.961832061068719 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 9.160305343511482 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 13.358778625954244 32
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 19.4656488549619 48
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 22.519083969465726 56
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 26.33587786259551 71
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 26.717557251908488 79
Completed Iteration #12
Best Reward: 0.7633587786259568
Completed Iteration #13
Best Reward: 0.7633587786259568
Completed Iteration #14
Best Reward: 0.7633587786259568
Completed Iteration #15
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 5.343511450381698 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 9.54198473282446 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 13.740458015267222 33
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 19.847328244274877 49
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 22.900763358778704 57
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 26.717557251908488 72
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 27.099236641221466 80
Completed Iteration #16
Best Reward: 0.7633587786259568
Completed Iteration #17
Best Reward: 0.7633587786259568
Completed Iteration #18
Best Reward: 0.7633587786259568
Completed Iteration #19
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c47b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 5.725190839694676 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 9.923664122137438 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 14.1221374045802 34
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 20.229007633587855 50
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 23.282442748091682 58
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 27.099236641221466 73
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 27.480916030534445 81
Completed Iteration #20
Best Reward: 0.7633587786259568
Completed Iteration #21
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac471da20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c49e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 6.106870229007654 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 10.305343511450417 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 14.50381679389318 35
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 20.610687022900834 51
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 23.66412213740466 59
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 27.480916030534445 74
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 27.862595419847423 82
Completed Iteration #22
Best Reward: 0.7633587786259568
Completed Iteration #23
Best Reward: 0.7633587786259568
Completed Iteration #24
Best Reward: 0.7633587786259568
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700eb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 3.053435114503827 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 6.106870229007654 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 10.305343511450417 25
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 14.50381679389318 36
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 20.610687022900834 52
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 23.66412213740466 60
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 27.480916030534445 75
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 27.862595419847423 83
Completed Iteration #25
Best Reward: 0.7633587786259568
Completed MCTS Level/Depth: #6
root->5->18->0->3->6->17
Best Reward: 0.7633587786259568
Completed Iteration #0
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 3.4351145038168056 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 6.488549618320633 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 10.687022900763395 26
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 14.885496183206158 37
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 20.992366412213812 53
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 24.04580152671764 61
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 27.862595419847423 76
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 28.2442748091604 84
Completed Iteration #1
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46beef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 3.816793893129784 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 6.870229007633611 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 11.068702290076374 27
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 15.267175572519136 38
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 21.37404580152679 54
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 24.427480916030618 62
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 28.2442748091604 77
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 28.62595419847338 85
Completed Iteration #2
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c860> 1.5267175572519136 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 4.198473282442762 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 7.25190839694659 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 11.450381679389352 28
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 15.648854961832114 39
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 21.75572519083977 55
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 24.809160305343596 63
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 28.62595419847338 78
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 29.00763358778636 86
Completed Iteration #3
Best Reward: 0.7633587786259568
Completed Iteration #4
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bee10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c860> 1.908396946564892 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 4.580152671755741 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 7.633587786259568 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 11.83206106870233 29
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 16.030534351145093 40
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 22.137404580152747 56
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 25.190839694656574 64
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 29.00763358778636 79
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 29.389312977099337 87
Completed Iteration #5
Best Reward: 0.7633587786259568
Completed Iteration #6
Best Reward: 0.7633587786259568
Completed Iteration #7
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 4.961832061068719 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 8.015267175572546 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 12.213740458015309 30
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 16.41221374045807 41
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 22.519083969465726 57
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 25.572519083969553 65
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 29.389312977099337 80
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 29.770992366412315 88
Completed Iteration #8
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc080> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 5.725190839694676 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 8.778625954198503 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 12.977099236641266 31
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 17.175572519084028 42
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 23.282442748091682 58
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 26.33587786259551 66
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 30.152671755725294 81
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 30.534351145038272 89
Completed Iteration #9
Best Reward: 0.7633587786259568
Completed Iteration #10
Best Reward: 0.7633587786259568
Completed Iteration #11
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752e48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c860> 2.2900763358778704 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 6.106870229007654 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 9.160305343511482 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 13.358778625954244 32
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 17.557251908397006 43
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 23.66412213740466 59
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 26.717557251908488 67
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 30.534351145038272 82
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 30.91603053435125 90
Completed Iteration #12
Best Reward: 0.7633587786259568
Completed Iteration #13
Best Reward: 0.7633587786259568
Completed Iteration #14
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6a0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 6.488549618320633 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 9.54198473282446 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 13.740458015267222 33
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 17.938931297709985 44
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 24.04580152671764 60
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 27.099236641221466 68
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 30.91603053435125 83
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 31.29770992366423 91
Completed Iteration #15
Best Reward: 0.7633587786259568
Completed Iteration #16
Best Reward: 0.7633587786259568
Completed Iteration #17
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700eb8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 6.870229007633611 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 9.923664122137438 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 14.1221374045802 34
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 18.320610687022963 45
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 24.427480916030618 61
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 27.480916030534445 69
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 31.29770992366423 84
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 31.679389312977207 92
Completed Iteration #18
Best Reward: 0.7633587786259568
coverage_call_count 300
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f53c8> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 7.633587786259568 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 10.687022900763395 25
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 14.885496183206158 35
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 19.08396946564892 46
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 25.190839694656574 62
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 28.2442748091604 70
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 32.061068702290186 85
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 32.442748091603164 93
Completed Iteration #19
Best Reward: 0.7633587786259568
Completed Iteration #20
Best Reward: 0.7633587786259568
Completed Iteration #21
Best Reward: 0.7633587786259568
Completed Iteration #22
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 8.396946564885525 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 11.450381679389352 26
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 15.648854961832114 36
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 19.847328244274877 47
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 25.95419847328253 63
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 29.00763358778636 71
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 32.82442748091614 86
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 33.20610687022912 94
Completed Iteration #23
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 8.778625954198503 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 11.83206106870233 27
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 16.030534351145093 37
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 20.229007633587855 48
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 26.33587786259551 64
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 29.389312977099337 72
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 33.20610687022912 87
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 33.5877862595421 95
Completed Iteration #24
Best Reward: 0.7633587786259568
Completed Iteration #25
Best Reward: 0.7633587786259568
Completed MCTS Level/Depth: #7
root->5->18->0->3->6->17->2
Best Reward: 0.7633587786259568
Completed Iteration #0
Best Reward: 0.7633587786259568
Completed Iteration #1
Best Reward: 0.7633587786259568
Completed Iteration #2
Best Reward: 0.7633587786259568
Completed Iteration #3
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f50b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 9.160305343511482 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 12.213740458015309 28
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 16.41221374045807 38
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 20.610687022900834 49
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 26.717557251908488 65
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 29.770992366412315 73
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 33.5877862595421 88
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 33.96946564885508 96
Completed Iteration #4
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c438> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752f60> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 1.908396946564892 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 9.923664122137438 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 12.977099236641266 29
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 17.175572519084028 39
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 21.37404580152679 50
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 27.480916030534445 66
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 30.534351145038272 74
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 34.351145038168056 89
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 34.732824427481034 97
Completed Iteration #5
Best Reward: 0.7633587786259568
Completed Iteration #6
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 2.2900763358778704 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 10.305343511450417 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 13.358778625954244 30
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 17.557251908397006 40
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 21.75572519083977 51
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 27.862595419847423 67
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 30.91603053435125 75
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 34.732824427481034 90
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 35.11450381679401 98
Completed Iteration #7
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 2.671755725190849 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 10.687022900763395 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 13.740458015267222 31
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 17.938931297709985 41
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 22.137404580152747 52
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 28.2442748091604 68
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 31.29770992366423 76
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 35.11450381679401 91
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 35.49618320610699 99
Completed Iteration #8
Best Reward: 0.7633587786259568
Completed Iteration #9
Best Reward: 0.7633587786259568
Completed Iteration #10
Best Reward: 0.7633587786259568
Reward: 0.7633587786259568
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.7633587786259568 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700588> 1.1450381679389352 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 3.4351145038168056 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 11.450381679389352 25
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 14.50381679389318 32
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 18.70229007633594 42
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 22.900763358778704 53
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 29.00763358778636 69
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 32.061068702290186 77
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 35.87786259541997 92
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 36.25954198473295 100
Completed Iteration #11
Best Reward: 0.7633587786259568
Completed Iteration #12
Best Reward: 0.7633587786259568
Completed Iteration #13
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac469add8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5f28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700588> 1.5267175572519136 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 3.816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 11.83206106870233 26
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 14.885496183206158 33
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 19.08396946564892 43
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 23.282442748091682 54
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 29.389312977099337 70
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 32.442748091603164 78
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 36.25954198473295 93
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 36.64122137404593 101
Completed Iteration #14
Best Reward: 0.7633587786259568
Completed Iteration #15
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc1d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f50b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 4.198473282442762 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 12.213740458015309 27
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 15.267175572519136 34
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 19.4656488549619 44
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 23.66412213740466 55
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 29.770992366412315 71
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 32.82442748091614 79
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 36.64122137404593 94
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 37.022900763358905 102
Completed Iteration #16
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f50b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 4.580152671755741 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 12.595419847328287 28
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 15.648854961832114 35
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 19.847328244274877 45
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 24.04580152671764 56
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 30.152671755725294 72
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 33.20610687022912 80
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 37.022900763358905 95
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 37.40458015267188 103
Completed Iteration #17
Best Reward: 0.7633587786259568
Completed Iteration #18
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700588> 1.908396946564892 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 4.961832061068719 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 12.977099236641266 29
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 16.030534351145093 36
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 20.229007633587855 46
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 24.427480916030618 57
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 30.534351145038272 73
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 33.5877862595421 81
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 37.40458015267188 96
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 37.78625954198486 104
Completed Iteration #19
Best Reward: 0.7633587786259568
Completed Iteration #20
Best Reward: 0.7633587786259568
Completed Iteration #21
Best Reward: 0.7633587786259568
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc208> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be6a0> 5.343511450381698 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1080> 13.358778625954244 30
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c390> 16.41221374045807 37
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4ac8> 20.610687022900834 47
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789588> 24.809160305343596 58
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f55f8> 30.91603053435125 74
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 33.96946564885508 82
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 37.78625954198486 97
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b240> 38.16793893129784 105
Completed Iteration #22
Best Reward: 0.7633587786259568
Completed Iteration #23
Best Reward: 0.7633587786259568
Completed Iteration #24
Best Reward: 0.7633587786259568
Completed Iteration #25
Best Reward: 0.7633587786259568
Completed MCTS Level/Depth: #8
root->5->18->0->3->6->17->2->0
Best Reward: 0.7633587786259568
iteration: 4
found coverage increase 0.7633587786259568
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46414e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aa20> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cde10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 67.93893129770993
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aef4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7afc136668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc73f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc73f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47893c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc736358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47893c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47893c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47893c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aee4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47898d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1240> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47747f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47747f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47747f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47747f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47004e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc645c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6454e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.3816793893129642 8
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.3816793893129642 9
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.3816793893129642 10
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.7633587786259284 11
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.1450381679388926 12
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.1450381679388926 13
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.5267175572518568 14
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.5267175572518568 15
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.908396946564821 16
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.908396946564821 17
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.908396946564821 18
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.908396946564821 19
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 1.908396946564821 20
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a42e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 2.290076335877785 21
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 2.6717557251907493 22
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 2.6717557251907493 23
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 3.0534351145037135 24
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 3.0534351145037135 25
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 3.4351145038166777 26
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47271d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 3.816793893129642 27
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfbe0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 4.198473282442606 28
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 4.198473282442606 29
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8cc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b84e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774208> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 4.58015267175557 17
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 4.58015267175557 30
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 4.58015267175557 18
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 4.58015267175557 31
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8a90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 4.9618320610685345 19
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 4.9618320610685345 32
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 4.9618320610685345 20
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 4.9618320610685345 33
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 5.343511450381499 21
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 5.343511450381499 34
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4a20> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 5.725190839694463 22
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 5.725190839694463 35
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789668> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4a20> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 6.106870229007427 23
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 6.106870229007427 36
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 6.488549618320391 24
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 6.488549618320391 37
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->8->5
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
coverage_call_count 800
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 6.870229007633355 38
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 7.25190839694632 26
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 7.25190839694632 39
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 7.633587786259284 40
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 8.015267175572248 41
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 8.396946564885212 42
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->8->5->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 8.778625954198176 30
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 8.778625954198176 43
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df9b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 9.16030534351114 31
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 9.16030534351114 44
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->8->5->0->8
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 9.541984732824105 32
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 9.541984732824105 45
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 9.923664122137069 33
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 9.923664122137069 46
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 10.305343511450033 34
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 10.305343511450033 47
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 6.870229007633355 19
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 10.687022900762997 35
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 10.687022900762997 48
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 7.25190839694632 20
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 11.068702290075962 36
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 11.068702290075962 49
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->8->5->0->8->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 7.633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 11.450381679388926 37
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 11.450381679388926 50
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 11.450381679388926 38
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 11.450381679388926 51
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd9b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 11.83206106870189 39
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 11.83206106870189 52
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ca90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 12.213740458014854 40
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 12.213740458014854 53
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46beba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 12.595419847327818 41
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 12.595419847327818 54
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae748> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 12.977099236640782 42
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 12.977099236640782 55
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->8->5->0->8->0->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 12.977099236640782 43
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 12.977099236640782 56
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 13.358778625953747 44
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 13.358778625953747 57
Completed Iteration #3
Best Reward: 0.3816793893129642
coverage_call_count 900
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 13.74045801526671 45
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 13.74045801526671 58
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ca90> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 10.305343511450033 30
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 14.122137404579675 46
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 14.122137404579675 59
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 10.687022900762997 31
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 14.50381679389264 47
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 14.50381679389264 60
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->8->5->0->8->0->0->8
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac471da20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 11.068702290075962 32
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 14.885496183205603 48
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 14.885496183205603 61
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ac50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 11.450381679388926 33
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 15.267175572518568 49
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 15.267175572518568 62
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641dd8> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cd30> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2e8> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a20> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 10.305343511450033 30
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 11.83206106870189 34
backprop <src.mcts.MCTS_Node object at 0x7f7acc645518> 15.648854961831532 50
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 15.648854961831532 63
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->8->5->0->8->0->0->8->6
Best Reward: 0.3816793893129642
iteration: 20
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a390> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa80378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa805df60> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4390> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074908> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 1200
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00549e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00549e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00549e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718854e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00542e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718854e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71885898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718854e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718854e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718541d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ccc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a71868a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718856d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5278> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47277f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47275f8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 1800
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6457b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752160> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70ff28> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b56d47278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aac88> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0af0ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47002e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47002e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b56d41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6456a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47898d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f780> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd7b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 2100
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0cfd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c0f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd0b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 10
Completed Iteration #16
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c5c0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854400> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.3816793893129926 11
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.3816793893129926 12
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.3816793893129926 13
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.3816793893129926 14
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.3816793893129926 15
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.3816793893129926 16
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.7633587786259852 17
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.7633587786259852 18
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.7633587786259852 19
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecf60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.1450381679389778 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.1450381679389778 20
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecf60> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.1450381679389778 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.1450381679389778 21
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.1450381679389778 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.1450381679389778 22
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.1450381679389778 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.1450381679389778 23
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.1450381679389778 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.1450381679389778 24
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.1450381679389778 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.1450381679389778 25
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.5267175572519704 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.5267175572519704 26
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.5267175572519704 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.5267175572519704 27
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.5267175572519704 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.5267175572519704 28
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.5267175572519704 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.5267175572519704 29
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 1.908396946564963 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 1.908396946564963 30
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f60> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 2.2900763358779557 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 2.2900763358779557 31
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 2.2900763358779557 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 2.2900763358779557 32
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 2.2900763358779557 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 2.2900763358779557 33
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dbe0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 2.6717557251909483 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 2.6717557251909483 34
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f60> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 2.6717557251909483 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 2.6717557251909483 35
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 1.908396946564963 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 2.6717557251909483 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 2.6717557251909483 36
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a71868fd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.1450381679389778 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.053435114503941 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.053435114503941 37
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.1450381679389778 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 2.2900763358779557 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.053435114503941 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.053435114503941 38
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 2.2900763358779557 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.053435114503941 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.053435114503941 39
Completed Iteration #15
Best Reward: 0.3816793893129926
coverage_call_count 2500
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f99e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.5267175572519704 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 2.6717557251909483 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.4351145038169335 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.4351145038169335 40
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f60> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 2.6717557251909483 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.4351145038169335 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.4351145038169335 41
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.908396946564963 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 42
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f99e8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.908396946564963 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 43
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f60> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 44
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f60> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 45
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->5->2
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.908396946564963 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 46
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.908396946564963 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 47
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 1.908396946564963 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.053435114503941 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 3.816793893129926 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 3.816793893129926 48
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9c50> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 2.2900763358779557 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.4351145038169335 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 4.198473282442919 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 4.198473282442919 49
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398dd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d588> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 2.6717557251909483 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 3.816793893129926 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 4.580152671755911 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 4.580152671755911 50
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398e48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3984e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f99e8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 3.053435114503941 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 4.198473282442919 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 4.961832061068904 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 4.961832061068904 51
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 3.4351145038169335 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 4.580152671755911 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 5.343511450381897 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 5.343511450381897 52
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 3.4351145038169335 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 4.580152671755911 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 5.343511450381897 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 5.343511450381897 53
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b94a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 3.816793893129926 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 4.961832061068904 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 5.725190839694889 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 5.725190839694889 54
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->5->2->8
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b94a8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 3.816793893129926 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 4.961832061068904 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 5.725190839694889 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 5.725190839694889 55
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 4.198473282442919 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 5.343511450381897 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 6.106870229007882 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 6.106870229007882 56
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 4.580152671755911 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 5.725190839694889 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 6.488549618320874 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 6.488549618320874 57
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 4.580152671755911 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 5.725190839694889 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 6.488549618320874 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 6.488549618320874 58
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adfd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 4.961832061068904 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 6.106870229007882 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 6.870229007633867 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 6.870229007633867 59
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 5.343511450381897 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 6.488549618320874 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 7.25190839694686 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 7.25190839694686 60
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 5.343511450381897 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 6.488549618320874 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 7.25190839694686 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 7.25190839694686 61
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c390> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 5.343511450381897 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 6.488549618320874 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 7.25190839694686 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 7.25190839694686 62
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 5.725190839694889 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 6.870229007633867 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 7.633587786259852 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 7.633587786259852 63
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3467f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 3.053435114503941 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 6.106870229007882 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 7.25190839694686 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 8.015267175572845 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 8.015267175572845 64
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adfd0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 6.488549618320874 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 7.633587786259852 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 8.396946564885837 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 8.396946564885837 65
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->5->2->8->3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 3.816793893129926 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 6.870229007633867 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 8.015267175572845 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 8.77862595419883 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 8.77862595419883 66
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41780> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 7.25190839694686 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 8.396946564885837 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 9.160305343511823 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 9.160305343511823 67
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad7f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 7.633587786259852 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 8.77862595419883 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 9.541984732824815 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 9.541984732824815 68
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7ac46639e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 8.015267175572845 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 9.160305343511823 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 9.923664122137808 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 9.923664122137808 69
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398358> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41780> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 8.396946564885837 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 9.541984732824815 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 10.3053435114508 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 10.3053435114508 70
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9518> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41780> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 8.396946564885837 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 9.541984732824815 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 10.3053435114508 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 10.3053435114508 71
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 5.725190839694889 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 8.77862595419883 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 9.923664122137808 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 10.687022900763793 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 10.687022900763793 72
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 5.725190839694889 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 8.77862595419883 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 9.923664122137808 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 10.687022900763793 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 10.687022900763793 73
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46639e8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 5.725190839694889 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 8.77862595419883 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 9.923664122137808 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 10.687022900763793 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 10.687022900763793 74
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad278> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 6.106870229007882 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 9.160305343511823 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 10.3053435114508 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 11.068702290076786 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 11.068702290076786 75
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 6.488549618320874 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 9.541984732824815 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 10.687022900763793 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 11.450381679389778 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 11.450381679389778 76
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->5->2->8->3->1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 6.870229007633867 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 9.923664122137808 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 11.068702290076786 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 11.832061068702771 66
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 11.832061068702771 77
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 4.580152671755911 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 7.25190839694686 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 10.3053435114508 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 11.450381679389778 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 12.213740458015764 67
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 12.213740458015764 78
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41780> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 7.25190839694686 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 10.3053435114508 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 11.450381679389778 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 12.213740458015764 68
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 12.213740458015764 79
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 7.633587786259852 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 10.687022900763793 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 11.832061068702771 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 12.595419847328756 69
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 12.595419847328756 80
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9b70> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374be0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 4.961832061068904 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 7.633587786259852 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 10.687022900763793 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 11.832061068702771 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 12.595419847328756 70
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 12.595419847328756 81
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 8.015267175572845 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 11.068702290076786 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 12.213740458015764 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 12.977099236641749 71
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 12.977099236641749 82
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374828> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a58> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 5.725190839694889 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 8.396946564885837 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 11.450381679389778 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 12.595419847328756 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 13.358778625954741 72
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 13.358778625954741 83
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374828> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a58> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 3.816793893129926 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 5.725190839694889 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 8.396946564885837 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 11.450381679389778 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 12.595419847328756 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 13.358778625954741 73
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 13.358778625954741 84
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f90b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 6.106870229007882 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 8.77862595419883 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 11.832061068702771 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 12.977099236641749 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 13.740458015267734 74
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 13.740458015267734 85
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
coverage_call_count 2600
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854748> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 6.488549618320874 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 9.160305343511823 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 12.213740458015764 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 13.358778625954741 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 14.122137404580727 75
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 14.122137404580727 86
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346dd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362e48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 6.870229007633867 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 9.541984732824815 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 12.595419847328756 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 13.740458015267734 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 14.50381679389372 76
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 14.50381679389372 87
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad7f0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 7.25190839694686 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 9.923664122137808 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 12.977099236641749 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.122137404580727 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 14.885496183206712 77
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 14.885496183206712 88
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3627f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346dd8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362e48> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 5.725190839694889 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 7.633587786259852 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 10.3053435114508 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 13.358778625954741 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.50381679389372 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 15.267175572519704 78
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 15.267175572519704 89
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.106870229007882 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.015267175572845 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 10.687022900763793 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 13.740458015267734 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.885496183206712 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 15.648854961832697 79
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 15.648854961832697 90
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->5->2->8->3->1->10
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.106870229007882 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.015267175572845 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 10.687022900763793 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 13.740458015267734 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.885496183206712 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 15.648854961832697 80
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 15.648854961832697 91
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd208> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.106870229007882 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.015267175572845 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 10.687022900763793 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 13.740458015267734 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.885496183206712 66
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 15.648854961832697 81
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 15.648854961832697 92
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.106870229007882 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.015267175572845 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 10.687022900763793 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 13.740458015267734 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.885496183206712 67
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 15.648854961832697 82
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 15.648854961832697 93
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.106870229007882 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.015267175572845 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 10.687022900763793 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 13.740458015267734 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 14.885496183206712 68
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 15.648854961832697 83
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 15.648854961832697 94
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.1450381679389778 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.488549618320874 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.396946564885837 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.068702290076786 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.122137404580727 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 15.267175572519704 69
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.03053435114569 84
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.03053435114569 95
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.5267175572519704 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.870229007633867 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.77862595419883 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.450381679389778 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.50381679389372 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 15.648854961832697 70
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.412213740458682 85
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.412213740458682 96
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329438> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.5267175572519704 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.870229007633867 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.77862595419883 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.450381679389778 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.50381679389372 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 15.648854961832697 71
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.412213740458682 86
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.412213740458682 97
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.5267175572519704 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 6.870229007633867 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 8.77862595419883 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.450381679389778 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.50381679389372 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 15.648854961832697 72
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.412213740458682 87
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.412213740458682 98
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c18> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.908396946564963 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 7.25190839694686 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 9.160305343511823 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.832061068702771 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.885496183206712 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 16.03053435114569 73
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.793893129771675 88
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.793893129771675 99
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3294a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3113c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329438> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.908396946564963 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 7.25190839694686 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 9.160305343511823 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.832061068702771 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.885496183206712 66
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 16.03053435114569 74
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.793893129771675 89
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.793893129771675 100
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c18> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 1.908396946564963 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 7.25190839694686 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 9.160305343511823 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 11.832061068702771 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 14.885496183206712 67
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 16.03053435114569 75
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 16.793893129771675 90
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 16.793893129771675 101
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->5->2->8->3->1->10->1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 2.2900763358779557 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 7.633587786259852 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 9.541984732824815 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 12.213740458015764 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 15.267175572519704 68
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 16.412213740458682 76
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 17.175572519084668 91
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 17.175572519084668 102
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 2.6717557251909483 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 8.015267175572845 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 9.923664122137808 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 12.595419847328756 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 15.648854961832697 69
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 16.793893129771675 77
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 17.55725190839766 92
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 17.55725190839766 103
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c19e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 3.053435114503941 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 8.396946564885837 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 10.3053435114508 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 12.977099236641749 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 16.03053435114569 70
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 17.175572519084668 78
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 17.938931297710653 93
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 17.938931297710653 104
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 3.4351145038169335 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 8.77862595419883 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 10.687022900763793 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 13.358778625954741 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 16.412213740458682 71
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 17.55725190839766 79
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 18.320610687023645 94
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 18.320610687023645 105
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd9e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3627b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1710> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 9.160305343511823 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 11.068702290076786 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 13.740458015267734 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 16.793893129771675 72
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 17.938931297710653 80
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 18.702290076336638 95
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 18.702290076336638 106
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 4.198473282442919 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 9.541984732824815 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 11.450381679389778 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 14.122137404580727 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 17.175572519084668 73
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 18.320610687023645 81
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 19.08396946564963 96
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 19.08396946564963 107
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 4.580152671755911 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 9.923664122137808 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 11.832061068702771 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 14.50381679389372 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 17.55725190839766 74
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 18.702290076336638 82
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 19.465648854962623 97
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 19.465648854962623 108
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3115c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329ef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1198> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 4.961832061068904 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 10.3053435114508 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 12.213740458015764 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 14.885496183206712 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 17.938931297710653 75
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 19.08396946564963 83
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 19.847328244275616 98
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 19.847328244275616 109
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329a90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 10.687022900763793 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 12.595419847328756 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 15.267175572519704 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 18.320610687023645 76
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 19.465648854962623 84
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 20.22900763358861 99
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 20.22900763358861 110
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a20> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 5.343511450381897 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 10.687022900763793 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 12.595419847328756 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 15.267175572519704 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 18.320610687023645 77
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 19.465648854962623 85
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 20.22900763358861 100
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 20.22900763358861 111
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3d30> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311ef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329a90> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 5.725190839694889 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 11.068702290076786 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 12.977099236641749 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 15.648854961832697 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 18.702290076336638 78
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 19.847328244275616 86
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 20.6106870229016 101
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 20.6106870229016 112
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a20> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 6.106870229007882 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 11.450381679389778 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 13.358778625954741 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 16.03053435114569 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 19.08396946564963 79
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 20.22900763358861 87
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 20.992366412214594 102
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 20.992366412214594 113
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a20> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9be0> 4.580152671755911 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398940> 6.106870229007882 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3983c8> 11.450381679389778 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad208> 13.358778625954741 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad668> 16.03053435114569 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 19.08396946564963 80
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 20.22900763358861 88
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce908> 20.992366412214594 103
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 20.992366412214594 114
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->5->2->8->3->1->10->1->0
Best Reward: 0.3816793893129926
iteration: 79
found coverage increase 0.3816793893129926
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 2700
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dd68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa80375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa80379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718684e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718684e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718684e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718684e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecfd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802af60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00540f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ab38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aef4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0af7bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7afc136668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aee4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc746240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aef4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ceb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3000
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7365c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ac8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff28> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47006a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66ec88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc645588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc73f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae9e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3115f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3111d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc2e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 23
Completed Iteration #24
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdbe0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3620f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3626a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0850f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3465c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0857f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085390> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3623c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0605c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf28> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af862b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af862b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af953c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af862b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af954e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af499e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 11
Completed Iteration #19
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af950f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af950f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af147f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af955f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af955f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 3800
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae599b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af864e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495656d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495655c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fa58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c00b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494d81d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d88d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0198> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebda0> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 4200
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0851d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0851d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0851d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03beb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7afc136668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc73f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47520f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc7208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc774d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47741d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0ae0a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa009b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bdd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bbe0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc774eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.3816793893129642 7
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c12e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 8
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 9
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 10
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 11
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 12
Completed Iteration #17
Best Reward: 0.3816793893129642
coverage_call_count 4400
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 13
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 14
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 15
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 0.7633587786259284 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 16
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 17
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 0.7633587786259284 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 0.7633587786259284 18
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.1450381679388926 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.1450381679388926 19
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.1450381679388926 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.1450381679388926 20
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.1450381679388926 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.1450381679388926 21
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.1450381679388926 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.1450381679388926 22
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.5267175572518568 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.5267175572518568 23
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.5267175572518568 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.5267175572518568 24
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1828> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 1.908396946564821 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 1.908396946564821 25
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 2.290076335877785 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 2.290076335877785 26
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 2.6717557251907493 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 2.6717557251907493 27
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 3.0534351145037135 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 3.0534351145037135 28
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2b0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 3.4351145038166777 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 3.4351145038166777 29
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 3.816793893129642 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 3.816793893129642 30
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663160> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 4.198473282442606 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 4.198473282442606 31
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a4e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2b0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 4.58015267175557 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 4.58015267175557 32
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b828> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663160> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 4.9618320610685345 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 4.9618320610685345 33
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0be0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2b0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 5.343511450381499 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 5.343511450381499 34
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 5.725190839694463 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 5.725190839694463 35
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3240> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085438> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1828> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 6.106870229007427 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 6.106870229007427 36
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663160> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 6.488549618320391 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 6.488549618320391 37
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 6.870229007633355 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 6.870229007633355 38
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663160> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 6.870229007633355 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 6.870229007633355 39
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a160> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 7.25190839694632 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 7.25190839694632 40
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 7.633587786259284 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 7.633587786259284 41
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->4->18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a5c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 8.015267175572248 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 8.015267175572248 42
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 8.396946564885212 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 8.396946564885212 43
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3627b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3744e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 8.778625954198176 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 8.778625954198176 44
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3744e0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 9.16030534351114 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 9.16030534351114 45
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2b0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 9.16030534351114 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 9.16030534351114 46
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2b0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 8.778625954198176 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 9.541984732824105 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 9.541984732824105 47
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb208> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a5c0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37b8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 8.778625954198176 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 9.541984732824105 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 9.541984732824105 48
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc4a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 9.16030534351114 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 9.923664122137069 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 9.923664122137069 49
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 9.541984732824105 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 10.305343511450033 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 10.305343511450033 50
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3626a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311a58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 9.923664122137069 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 10.687022900762997 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 10.687022900762997 51
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1cc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37b8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 10.305343511450033 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 11.068702290075962 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 11.068702290075962 52
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->4->18->6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 10.687022900762997 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 11.450381679388926 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 11.450381679388926 53
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 11.068702290075962 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 11.83206106870189 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 11.83206106870189 54
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 11.450381679388926 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 12.213740458014854 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 12.213740458014854 55
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700978> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311ac8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 11.450381679388926 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 12.213740458014854 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 12.213740458014854 56
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adf98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b00> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 11.83206106870189 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 12.595419847327818 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 12.595419847327818 57
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374828> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 11.83206106870189 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 12.595419847327818 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 12.595419847327818 58
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 8.396946564885212 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 12.213740458014854 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 12.977099236640782 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 12.977099236640782 59
Completed Iteration #16
Best Reward: 0.3816793893129642
coverage_call_count 4500
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d470> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 8.778625954198176 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 12.595419847327818 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 13.358778625953747 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 13.358778625953747 60
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c14a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 9.16030534351114 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 12.977099236640782 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 13.74045801526671 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 13.74045801526671 61
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 9.541984732824105 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 13.358778625953747 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 14.122137404579675 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 14.122137404579675 62
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 9.923664122137069 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 13.74045801526671 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 14.50381679389264 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 14.50381679389264 63
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7cf8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 9.923664122137069 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 13.74045801526671 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 14.50381679389264 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 14.50381679389264 64
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 10.305343511450033 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 14.122137404579675 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 14.885496183205603 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 14.885496183205603 65
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->4->18->6->3
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346358> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 10.305343511450033 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 14.122137404579675 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 14.885496183205603 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 14.885496183205603 66
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362e80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 10.687022900762997 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 14.50381679389264 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 15.267175572518568 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 15.267175572518568 67
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a6a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 11.068702290075962 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 14.885496183205603 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 15.648854961831532 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 15.648854961831532 68
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adf98> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b00> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 6.106870229007427 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 11.068702290075962 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 14.885496183205603 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 15.648854961831532 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 15.648854961831532 69
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 11.450381679388926 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 15.267175572518568 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 16.030534351144496 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 16.030534351144496 70
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362e80> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 3.4351145038166777 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 6.488549618320391 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 11.450381679388926 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 15.267175572518568 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 16.030534351144496 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 16.030534351144496 71
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 3.816793893129642 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 11.83206106870189 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 15.648854961831532 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 16.41221374045746 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 16.41221374045746 72
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 7.25190839694632 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 16.030534351144496 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 16.793893129770424 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 16.793893129770424 73
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374828> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 4.198473282442606 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 7.25190839694632 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 12.213740458014854 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 16.030534351144496 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 16.793893129770424 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 16.793893129770424 74
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d550> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 4.58015267175557 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 7.633587786259284 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 12.595419847327818 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 16.41221374045746 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 17.17557251908339 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 17.17557251908339 75
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a6a0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 4.9618320610685345 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 8.015267175572248 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 12.977099236640782 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 16.793893129770424 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 17.557251908396353 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 17.557251908396353 76
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->4->18->6->3->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 5.343511450381499 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 13.358778625953747 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 17.17557251908339 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 17.938931297709317 66
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 17.938931297709317 77
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 5.725190839694463 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 13.74045801526671 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 17.557251908396353 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 18.32061068702228 67
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 18.32061068702228 78
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 6.106870229007427 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 14.122137404579675 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 17.938931297709317 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 18.702290076335245 68
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 18.702290076335245 79
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a71854550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 14.50381679389264 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 18.32061068702228 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 19.08396946564821 69
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 19.08396946564821 80
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 6.870229007633355 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 14.885496183205603 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 18.702290076335245 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 19.465648854961174 70
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 19.465648854961174 81
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eb38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 7.25190839694632 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 15.267175572518568 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 19.08396946564821 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 19.847328244274138 71
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 19.847328244274138 82
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfd68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074160> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 10.687022900762997 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 15.648854961831532 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 19.465648854961174 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 20.229007633587102 72
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 20.229007633587102 83
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 8.015267175572248 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 11.068702290075962 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 16.030534351144496 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 19.847328244274138 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 20.610687022900066 73
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 20.610687022900066 84
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 8.396946564885212 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 11.450381679388926 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 16.41221374045746 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 20.229007633587102 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 20.99236641221303 74
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 20.99236641221303 85
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a71854ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 8.778625954198176 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 11.83206106870189 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 16.793893129770424 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 20.610687022900066 66
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 21.374045801525995 75
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 21.374045801525995 86
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a6a0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 9.16030534351114 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 12.213740458014854 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 17.17557251908339 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 20.99236641221303 67
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 21.75572519083896 76
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 21.75572519083896 87
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469ae48> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054eb8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a6a0> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46bed30> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 9.16030534351114 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 17.17557251908339 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 20.99236641221303 68
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 21.75572519083896 77
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 21.75572519083896 88
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a15f8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 9.541984732824105 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 12.595419847327818 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 17.557251908396353 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 21.374045801525995 69
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 22.137404580151923 78
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 22.137404580151923 89
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 9.923664122137069 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 12.977099236640782 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 17.938931297709317 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 21.75572519083896 70
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 22.519083969464887 79
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 22.519083969464887 90
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d37f0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 12.977099236640782 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 17.938931297709317 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 21.75572519083896 71
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 22.519083969464887 80
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 22.519083969464887 91
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->4->18->6->3->0->4
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 9.923664122137069 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 12.977099236640782 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 17.938931297709317 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 21.75572519083896 72
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 22.519083969464887 81
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 22.519083969464887 92
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d70b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 10.305343511450033 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 13.358778625953747 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 18.32061068702228 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 22.137404580151923 73
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 22.90076335877785 82
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 22.90076335877785 93
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 6.870229007633355 23
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 10.305343511450033 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 13.358778625953747 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 18.32061068702228 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 22.137404580151923 74
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 22.90076335877785 83
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 22.90076335877785 94
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eb38> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 10.687022900762997 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 18.702290076335245 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 22.519083969464887 75
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 23.282442748090816 84
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 23.282442748090816 95
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 11.068702290075962 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 14.122137404579675 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 19.08396946564821 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 22.90076335877785 76
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 23.66412213740378 85
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 23.66412213740378 96
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 11.068702290075962 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 14.122137404579675 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 19.08396946564821 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 22.90076335877785 77
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 23.66412213740378 86
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 23.66412213740378 97
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 8.015267175572248 27
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 11.450381679388926 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 14.50381679389264 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 19.465648854961174 66
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 23.282442748090816 78
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 24.045801526716744 87
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 24.045801526716744 98
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d70b8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cecc0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 11.450381679388926 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 14.50381679389264 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 19.465648854961174 67
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 23.282442748090816 79
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 24.045801526716744 88
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 24.045801526716744 99
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a71854da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801da20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 4.58015267175557 17
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 11.83206106870189 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 14.885496183205603 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 19.847328244274138 68
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 23.66412213740378 80
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 24.427480916029708 89
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 24.427480916029708 100
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfeb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9710> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 4.9618320610685345 18
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 8.778625954198176 30
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 12.213740458014854 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 15.267175572518568 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 20.229007633587102 69
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 24.045801526716744 81
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 24.809160305342672 90
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 24.809160305342672 101
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 9.16030534351114 31
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 12.595419847327818 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 15.648854961831532 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 20.610687022900066 70
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 24.427480916029708 82
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 25.190839694655637 91
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 25.190839694655637 102
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7acc70feb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398ac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 9.541984732824105 32
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 12.977099236640782 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 16.030534351144496 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 20.99236641221303 71
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 24.809160305342672 83
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 25.5725190839686 92
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 25.5725190839686 103
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->4->18->6->3->0->4->3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 5.725190839694463 21
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 12.977099236640782 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 16.030534351144496 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 20.99236641221303 72
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 24.809160305342672 84
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 25.5725190839686 93
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 25.5725190839686 104
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c7f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f278> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc66eb38> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 6.106870229007427 22
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 13.358778625953747 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 16.41221374045746 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 21.374045801525995 73
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 25.190839694655637 85
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 25.954198473281565 94
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 25.954198473281565 105
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41a90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854550> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 13.74045801526671 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 16.793893129770424 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 21.75572519083896 74
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 25.5725190839686 86
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 26.33587786259453 95
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 26.33587786259453 106
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 2.290076335877785 10
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 6.488549618320391 24
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 10.305343511450033 36
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 13.74045801526671 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 16.793893129770424 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 21.75572519083896 75
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 25.5725190839686 87
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 26.33587786259453 96
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 26.33587786259453 107
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f96a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 2.6717557251907493 11
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 10.687022900762997 37
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 14.122137404579675 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 17.17557251908339 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 22.137404580151923 76
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 25.954198473281565 88
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 26.717557251907493 97
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 26.717557251907493 108
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
coverage_call_count 4600
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a70d418d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 7.25190839694632 26
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 11.068702290075962 38
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 14.50381679389264 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 17.557251908396353 62
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 22.519083969464887 77
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 26.33587786259453 89
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 27.099236641220457 98
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 27.099236641220457 109
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 11.450381679388926 39
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 14.885496183205603 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 17.938931297709317 63
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 22.90076335877785 78
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 26.717557251907493 90
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 27.48091603053342 99
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 27.48091603053342 110
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 11.83206106870189 40
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 15.267175572518568 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 18.32061068702228 64
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 23.282442748090816 79
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 27.099236641220457 91
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 27.862595419846386 100
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 27.862595419846386 111
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c40b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f96a0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7a718547f0> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cee48> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91e80> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba58> 15.648854961831532 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852b0> 18.702290076335245 65
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fdf60> 23.66412213740378 80
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 27.48091603053342 92
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311828> 28.24427480915935 101
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311898> 28.24427480915935 112
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->4->18->6->3->0->4->3->0
Best Reward: 0.3816793893129642
iteration: 147
found coverage increase 0.3816793893129642
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4c50> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ece48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 4700
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fcc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00548d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7d30> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc75cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0470> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 4900
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0602b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af863c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af863c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af863c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495651d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495c03c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 5100
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fcc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdada0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b70> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa80374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c1d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5200
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487597f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487597f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af868d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487598d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487364a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486de780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487364a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487364a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486de780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486acc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486acc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487594e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af492b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487364e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b5f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184630> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486deef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481936d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481440f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481580f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481443c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481443c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481443c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481252e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481252e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481932e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481932e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481586a0> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480feef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48093080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48125c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a34a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a34a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71885080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a34a8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a480a33c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71868ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48093dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71868908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481eda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481edac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481edfd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af495f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af495f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af14a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480930b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480930b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c04a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4876bbe0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d30> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6100
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495c06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed7b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac471df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc69fc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2898> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0042ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00420b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dd96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac471d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f470> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481ed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4864a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c060ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718a9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcbe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71885518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecc88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a7189c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4870bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49585c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47a14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49577438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa008f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00749b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49585240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa0074668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 69.08396946564885
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49577ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f90f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af490f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af86c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc69ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa001c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b86d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4700be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495b0e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afcb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4876b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae59160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 6400
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70da1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47ce908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d419b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7080> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3629e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa805d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3629e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b93c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4727da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af3dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac475c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7acc65bd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc65b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4789c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aedc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aea4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc72add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac469a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3298d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3292e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa00c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af958d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4870b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aee4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3620f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc73f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3620f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c362630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4752dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc75cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c374b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc75cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3addd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70dae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d913c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac468c828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3740f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc720908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c03bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0aee4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac4774128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c311358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc645240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2c1128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c398898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c329358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc73f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d91208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a71854f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7b0cf93048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac468cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa009bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d41be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a487366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c04a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c0858d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa978d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc7209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c085400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fef28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480feeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480feb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac4641668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48759860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3116a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47aab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70d914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afebe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a718a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48193a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdeb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa80379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486deda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b630> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa802a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cef0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa97b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4861cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a70d912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48193b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa801d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4afeba90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48158438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70daea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4950c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4952f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d2e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa8037390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a487362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480feef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c346fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4aec9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7ac46f59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48736630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481936a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afdadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac469afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481141d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac46be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a5c3f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a495656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481444a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481847b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481144e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af56390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7ac47cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481846a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4af866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a49565d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481846a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481846a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481144e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7acc70feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481846a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48114f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480fe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a70dc4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4950cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4867b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486f3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48125550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48184748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a494e8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486acac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481250f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481938d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486accf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486accf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac400> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48759cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48125eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4813dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7aa0054860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4813d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4860ba58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4869d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4952fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a48144128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.3816793893129926 6
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4afda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.3816793893129926 7
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 8
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4860bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 9
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 10
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48114c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 11
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48144b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 12
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a486c7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 13
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48184a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 0.7633587786259852 9
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 14
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4816da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 15
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4860b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 0.7633587786259852 16
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 1.1450381679389778 10
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 1.1450381679389778 17
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a481d94a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 1.5267175572519704 11
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 1.5267175572519704 18
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 1.5267175572519704 12
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 1.5267175572519704 19
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 1.5267175572519704 13
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 1.5267175572519704 20
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 1.908396946564963 14
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 1.908396946564963 21
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b2b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 2.2900763358779557 15
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 2.2900763358779557 22
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07ba90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b2b0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a49565fd0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 2.6717557251909483 16
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 2.6717557251909483 23
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07be10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.053435114503941 17
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.053435114503941 24
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07be10> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.053435114503941 18
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.053435114503941 25
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07be10> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.053435114503941 19
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.053435114503941 26
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.4351145038169335 20
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.4351145038169335 27
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.4351145038169335 21
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.4351145038169335 28
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd0b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4816d080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481cd710> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.816793893129926 22
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.816793893129926 29
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a481d9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae8fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 3.816793893129926 23
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 3.816793893129926 30
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 4.198473282442919 24
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 4.198473282442919 31
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 4.580152671755911 25
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 4.580152671755911 32
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 4.961832061068904 26
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 4.961832061068904 33
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 5.343511450381897 27
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 5.343511450381897 34
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b01e940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b01e198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000860> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8b38> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 5.725190839694889 28
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 5.725190839694889 35
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3b01eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b01ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b470> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b588> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 5.725190839694889 29
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 5.725190839694889 36
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 6.106870229007882 30
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 6.106870229007882 37
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a48158438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000860> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8b38> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 6.106870229007882 31
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 6.106870229007882 38
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02b978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 3.816793893129926 13
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 6.488549618320874 32
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 6.488549618320874 39
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->6->5
Best Reward: 0.3816793893129926
coverage_call_count 7300
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a481d93c8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 4.198473282442919 14
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 6.870229007633867 33
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 6.870229007633867 40
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02bdd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02ba58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d93c8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 4.580152671755911 15
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 7.25190839694686 34
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 7.25190839694686 41
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0004a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 4.961832061068904 16
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 7.633587786259852 35
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 7.633587786259852 42
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 5.343511450381897 17
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 8.015267175572845 36
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 8.015267175572845 43
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b01e9e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 5.725190839694889 18
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 8.396946564885837 37
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 8.396946564885837 44
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a480b8a58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02b208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0004a8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 6.106870229007882 19
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 8.77862595419883 38
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 8.77862595419883 45
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abc24e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02bc18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a4877a438> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 6.488549618320874 20
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 9.160305343511823 39
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 9.160305343511823 46
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abc28d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 5.725190839694889 17
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 6.870229007633867 21
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 9.541984732824815 40
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 9.541984732824815 47
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abc2c50> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02b208> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0004a8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 6.106870229007882 18
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 7.25190839694686 22
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 9.923664122137808 41
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 9.923664122137808 48
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000e10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 6.488549618320874 19
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 7.633587786259852 23
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 10.3053435114508 42
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 10.3053435114508 49
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->6->5->0
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3abcc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b588> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 6.488549618320874 20
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 7.633587786259852 24
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 10.3053435114508 43
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 10.3053435114508 50
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abcca58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abccb38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b470> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b588> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 6.870229007633867 21
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 8.015267175572845 25
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 10.687022900763793 44
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 10.687022900763793 51
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd7630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 7.25190839694686 22
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 8.396946564885837 26
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 11.068702290076786 45
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 11.068702290076786 52
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abc2630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b07b588> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 7.633587786259852 23
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 8.77862595419883 27
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 11.450381679389778 46
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 11.450381679389778 53
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02beb8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02bc50> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 3.816793893129926 13
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 8.015267175572845 24
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 9.160305343511823 28
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 11.832061068702771 47
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 11.832061068702771 54
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abcc198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abccef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd7630> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 4.198473282442919 14
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 8.396946564885837 25
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 9.541984732824815 29
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 12.213740458015764 48
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 12.213740458015764 55
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3abcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02bc50> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 8.396946564885837 26
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 9.541984732824815 30
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 12.213740458015764 49
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 12.213740458015764 56
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd78d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 4.580152671755911 16
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 8.77862595419883 27
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 9.923664122137808 31
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 12.595419847328756 50
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 12.595419847328756 57
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd7fd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02b208> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0004a8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 4.961832061068904 17
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 9.160305343511823 28
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 10.3053435114508 32
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 12.977099236641749 51
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 12.977099236641749 58
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->6->5->0->4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abccef0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd7630> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 9.160305343511823 29
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 10.3053435114508 33
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 12.977099236641749 52
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 12.977099236641749 59
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd71d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 9.541984732824815 30
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 10.687022900763793 34
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 13.358778625954741 53
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 13.358778625954741 60
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 5.725190839694889 20
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 9.923664122137808 31
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 11.068702290076786 35
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 13.740458015267734 54
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 13.740458015267734 61
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abfb8d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 6.106870229007882 21
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 10.3053435114508 32
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 11.450381679389778 36
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 14.122137404580727 55
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 14.122137404580727 62
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3b02b7f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 6.488549618320874 22
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 10.687022900763793 33
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 11.832061068702771 37
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 14.50381679389372 56
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 14.50381679389372 63
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd7860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 6.870229007633867 23
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 11.068702290076786 34
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 12.213740458015764 38
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 14.885496183206712 57
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 14.885496183206712 64
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1358> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf15f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 7.25190839694686 24
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 11.450381679389778 35
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 12.595419847328756 39
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 15.267175572519704 58
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 15.267175572519704 65
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abfb5f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 5.725190839694889 17
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 7.633587786259852 25
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 11.832061068702771 36
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 12.977099236641749 40
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 15.648854961832697 59
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 15.648854961832697 66
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->6->5->0->4->0
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 6.106870229007882 18
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 8.015267175572845 26
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 12.213740458015764 37
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 13.358778625954741 41
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 16.03053435114569 60
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 16.03053435114569 67
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abfbfd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf15f8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 6.488549618320874 19
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 8.396946564885837 27
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 12.595419847328756 38
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 13.740458015267734 42
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 16.412213740458682 61
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 16.412213740458682 68
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9def0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 6.870229007633867 20
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 8.77862595419883 28
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 12.977099236641749 39
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 14.122137404580727 43
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 16.793893129771675 62
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 16.793893129771675 69
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9db38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9dcf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1358> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf15f8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 7.25190839694686 21
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 9.160305343511823 29
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 13.358778625954741 40
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 14.50381679389372 44
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 17.175572519084668 63
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 17.175572519084668 70
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3aba62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf15f8> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 7.25190839694686 22
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 9.160305343511823 30
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 13.358778625954741 41
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 14.50381679389372 45
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 17.175572519084668 64
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 17.175572519084668 71
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 7.633587786259852 23
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 9.541984732824815 31
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 13.740458015267734 42
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 14.885496183206712 46
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 17.55725190839766 65
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 17.55725190839766 72
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abfb9e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9dcf8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1358> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf15f8> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 8.015267175572845 24
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 9.923664122137808 32
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 14.122137404580727 43
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 15.267175572519704 47
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 17.938931297710653 66
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 17.938931297710653 73
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abfb278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 5.725190839694889 17
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 8.396946564885837 25
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 10.3053435114508 33
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 14.50381679389372 44
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 15.648854961832697 48
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 18.320610687023645 67
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 18.320610687023645 74
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
coverage_call_count 7400
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd7390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 6.106870229007882 18
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 8.77862595419883 26
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 10.687022900763793 34
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 14.885496183206712 45
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 16.03053435114569 49
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 18.702290076336638 68
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 18.702290076336638 75
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->6->5->0->4->0->0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abc27b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 6.488549618320874 19
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 9.160305343511823 27
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 11.068702290076786 35
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 15.267175572519704 46
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 16.412213740458682 50
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 19.08396946564963 69
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 19.08396946564963 76
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3aba6e48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 6.870229007633867 20
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 9.541984732824815 28
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 11.450381679389778 36
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 15.648854961832697 47
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 16.793893129771675 51
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 19.465648854962623 70
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 19.465648854962623 77
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3aba6f28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 7.25190839694686 21
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 9.923664122137808 29
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 11.832061068702771 37
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 16.03053435114569 48
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 17.175572519084668 52
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 19.847328244275616 71
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 19.847328244275616 78
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9de10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 7.633587786259852 22
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 10.3053435114508 30
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 12.213740458015764 38
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 16.412213740458682 49
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 17.55725190839766 53
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 20.22900763358861 72
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 20.22900763358861 79
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abbf668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abbf160> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd78d0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 8.015267175572845 23
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 10.687022900763793 31
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 12.595419847328756 39
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 16.793893129771675 50
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 17.938931297710653 54
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 20.6106870229016 73
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 20.6106870229016 80
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abfbe10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 6.488549618320874 18
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 8.396946564885837 24
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 11.068702290076786 32
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 12.977099236641749 40
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 17.175572519084668 51
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 18.320610687023645 55
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 20.992366412214594 74
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 20.992366412214594 81
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7a3aba6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abbf160> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3abd78d0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 6.488549618320874 19
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 8.396946564885837 25
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 11.068702290076786 33
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 12.977099236641749 41
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 17.175572519084668 52
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 18.320610687023645 56
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 20.992366412214594 75
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 20.992366412214594 82
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abc2e48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 6.870229007633867 20
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 8.77862595419883 26
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 11.450381679389778 34
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 13.358778625954741 42
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 17.55725190839766 53
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 18.702290076336638 57
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 21.374045801527586 76
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 21.374045801527586 83
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->6->5->0->4->0->0->0
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3abbff28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abbf518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 7.25190839694686 21
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 9.160305343511823 27
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 11.832061068702771 35
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 13.740458015267734 43
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 17.938931297710653 54
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 19.08396946564963 58
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 21.75572519084058 77
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 21.75572519084058 84
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab5fd68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 7.633587786259852 22
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 9.541984732824815 28
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 12.213740458015764 36
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 14.122137404580727 44
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 18.320610687023645 55
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 19.465648854962623 59
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 22.13740458015357 78
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 22.13740458015357 85
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab5ff60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3abbf518> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 8.015267175572845 23
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 9.923664122137808 29
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 12.595419847328756 37
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 14.50381679389372 45
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 18.702290076336638 56
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 19.847328244275616 60
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 22.519083969466564 79
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 22.519083969466564 86
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab69f28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7a3ab9da90> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f7a3abf1f98> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000be0> 8.396946564885837 24
backprop <src.mcts.MCTS_Node object at 0x7f7a3b000da0> 10.3053435114508 30
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0006d8> 12.977099236641749 38
backprop <src.mcts.MCTS_Node object at 0x7f7a3b0009b0> 14.885496183206712 46
backprop <src.mcts.MCTS_Node object at 0x7f7a481d92e8> 19.08396946564963 57
backprop <src.mcts.MCTS_Node object at 0x7f7a4ae6c390> 20.22900763358861 61
backprop <src.mcts.MCTS_Node object at 0x7f7a5c2fda20> 22.900763358779557 80
backprop <src.mcts.MCTS_Node object at 0x7f7a486ac160> 22.900763358779557 87
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->6->5->0->4->0->0->0->5
Best Reward: 0.3816793893129926
iteration: 250
found coverage increase 0.3816793893129926
Current Total Coverage 69.46564885496184
initial coverage: 67.1756
time passed (minutes): 63.0346
iterations: 251
number of new inputs: 320
final coverage: 69.4656
total coverage increase: 2.29008
