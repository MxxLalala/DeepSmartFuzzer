Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, kmn_k=10000, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=2, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7f824fe70f28>, tc2=<function tc2 at 0x7f824fe82048>, tc3=<function tc3 at 0x7f824fe82158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 37.786
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.03437500000000426
backprop <src.mcts.MCTS_Node object at 0x7f818017fda0> 0.03437500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fba8> 0.03437500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.03437500000000426 2
Completed Iteration #0
Best Reward: 0.03437500000000426
Completed Iteration #1
Best Reward: 0.03437500000000426
Reward: 0.10812500000000824
backprop <src.mcts.MCTS_Node object at 0x7f8180114198> 0.10812500000000824 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114278> 0.10812500000000824 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.1425000000000125 3
Completed Iteration #2
Best Reward: 0.10812500000000824
Reward: 0.10249999999999915
backprop <src.mcts.MCTS_Node object at 0x7f81801145c0> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114048> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.24500000000001165 4
Completed Iteration #3
Best Reward: 0.10812500000000824
Reward: 0.10437500000000455
backprop <src.mcts.MCTS_Node object at 0x7f8180114940> 0.10437500000000455 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114588> 0.10437500000000455 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.3493750000000162 5
Completed Iteration #4
Best Reward: 0.10812500000000824
Reward: 0.09812500000000313
backprop <src.mcts.MCTS_Node object at 0x7f8180114cc0> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114908> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.4475000000000193 6
Completed Iteration #5
Best Reward: 0.10812500000000824
Reward: 0.0956250000000054
backprop <src.mcts.MCTS_Node object at 0x7f8180114f98> 0.0956250000000054 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114588> 0.20000000000000995 3
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.5431250000000247 7
Completed Iteration #6
Best Reward: 0.10812500000000824
Reward: 0.05812500000000398
backprop <src.mcts.MCTS_Node object at 0x7f8180114d68> 0.05812500000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114048> 0.16062500000000313 3
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.6012500000000287 8
Completed Iteration #7
Best Reward: 0.10812500000000824
Reward: 0.09541666666667226
backprop <src.mcts.MCTS_Node object at 0x7f81801143c8> 0.09541666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114278> 0.2035416666666805 3
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.696666666666701 9
Completed Iteration #8
Best Reward: 0.10812500000000824
Reward: 0.07333333333333769
backprop <src.mcts.MCTS_Node object at 0x7f818012e4a8> 0.07333333333333769 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e2e8> 0.07333333333333769 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.7700000000000387 10
Completed Iteration #9
Best Reward: 0.10812500000000824
Reward: 0.08354166666666885
backprop <src.mcts.MCTS_Node object at 0x7f818012e780> 0.08354166666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114588> 0.2835416666666788 4
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.8535416666667075 11
Completed Iteration #10
Best Reward: 0.10812500000000824
Reward: 0.09875000000000256
backprop <src.mcts.MCTS_Node object at 0x7f818012ea58> 0.09875000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114278> 0.30229166666668306 4
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 0.9522916666667101 12
Completed Iteration #11
Best Reward: 0.10812500000000824
Reward: 0.09500000000000597
backprop <src.mcts.MCTS_Node object at 0x7f818012ed30> 0.09500000000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f818017ff98> 0.09500000000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.047291666666716 13
Completed Iteration #12
Best Reward: 0.10812500000000824
Reward: 0.10729166666666856
backprop <src.mcts.MCTS_Node object at 0x7f818012efd0> 0.10729166666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114908> 0.2054166666666717 3
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.1545833333333846 14
Completed Iteration #13
Best Reward: 0.10812500000000824
Reward: 0.07166666666667254
backprop <src.mcts.MCTS_Node object at 0x7f818013b320> 0.07166666666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114048> 0.23229166666667567 4
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.2262500000000571 15
Completed Iteration #14
Best Reward: 0.10812500000000824
Reward: 0.0837500000000091
backprop <src.mcts.MCTS_Node object at 0x7f818012eb70> 0.0837500000000091 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b2e8> 0.0837500000000091 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e4a8> 0.1570833333333468 3
backprop <src.mcts.MCTS_Node object at 0x7f818012e2e8> 0.1570833333333468 3
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.3100000000000662 16
Completed Iteration #15
Best Reward: 0.10812500000000824
Completed Iteration #16
Best Reward: 0.10812500000000824
Reward: 0.09958333333333513
backprop <src.mcts.MCTS_Node object at 0x7f818013b780> 0.09958333333333513 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b630> 0.09958333333333513 2
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.4095833333334014 17
Completed Iteration #17
Best Reward: 0.10812500000000824
Reward: 0.09937500000000199
backprop <src.mcts.MCTS_Node object at 0x7f818013ba58> 0.09937500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114588> 0.3829166666666808 5
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.5089583333334033 18
Completed Iteration #18
Best Reward: 0.10812500000000824
Reward: 0.11416666666666941
backprop <src.mcts.MCTS_Node object at 0x7f81f815dba8> 0.11416666666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114908> 0.3195833333333411 4
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.6231250000000728 19
Completed Iteration #19
Best Reward: 0.11416666666666941
Completed Iteration #20
Best Reward: 0.11416666666666941
Completed Iteration #21
Best Reward: 0.11416666666666941
Reward: 0.09458333333333968
backprop <src.mcts.MCTS_Node object at 0x7f818017fd68> 0.09458333333333968 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114588> 0.47750000000002046 6
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.7177083333334124 20
Completed Iteration #22
Best Reward: 0.11416666666666941
Reward: 0.07583333333333542
backprop <src.mcts.MCTS_Node object at 0x7f818012e940> 0.07583333333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e2e8> 0.2329166666666822 4
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.7935416666667479 21
Completed Iteration #23
Best Reward: 0.11416666666666941
Reward: 0.11729166666667368
backprop <src.mcts.MCTS_Node object at 0x7f818012ec50> 0.11729166666667368 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e4e0> 0.11729166666667368 2
backprop <src.mcts.MCTS_Node object at 0x7f818012efd0> 0.22458333333334224 3
backprop <src.mcts.MCTS_Node object at 0x7f8180114908> 0.4368750000000148 5
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.9108333333334215 22
Completed Iteration #24
Best Reward: 0.11729166666667368
Reward: 0.0520833333333357
backprop <src.mcts.MCTS_Node object at 0x7f818012eb00> 0.0520833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114278> 0.35437500000001876 5
backprop <src.mcts.MCTS_Node object at 0x7f81f81d74e0> 1.9629166666667572 23
Completed Iteration #25
Best Reward: 0.11729166666667368
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11729166666667368
No reward increase. Abort.
iteration: 0
found coverage increase 0.11729166666667368
Current Total Coverage 37.903333333333336
Reward: 0.05999999999999517
backprop <src.mcts.MCTS_Node object at 0x7f818012ebe0> 0.05999999999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114630> 0.05999999999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.05999999999999517 2
Completed Iteration #0
Best Reward: 0.05999999999999517
Reward: 0.10458333333333059
backprop <src.mcts.MCTS_Node object at 0x7f8180114978> 0.10458333333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114da0> 0.10458333333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.16458333333332575 3
Completed Iteration #1
Best Reward: 0.10458333333333059
Completed Iteration #2
Best Reward: 0.10458333333333059
Reward: 0.1074999999999946
backprop <src.mcts.MCTS_Node object at 0x7f818013b080> 0.1074999999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114630> 0.16749999999998977 3
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.27208333333332035 4
Completed Iteration #3
Best Reward: 0.1074999999999946
Completed Iteration #4
Best Reward: 0.1074999999999946
Completed Iteration #5
Best Reward: 0.1074999999999946
Reward: 0.10520833333333002
backprop <src.mcts.MCTS_Node object at 0x7f818013bd68> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f818013bdd8> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.37729166666665037 5
Completed Iteration #6
Best Reward: 0.1074999999999946
Reward: 0.03520833333332973
backprop <src.mcts.MCTS_Node object at 0x7f81800f11d0> 0.03520833333332973 2
backprop <src.mcts.MCTS_Node object at 0x7f818013be80> 0.03520833333332973 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.4124999999999801 6
Completed Iteration #7
Best Reward: 0.1074999999999946
Completed Iteration #8
Best Reward: 0.1074999999999946
Completed Iteration #9
Best Reward: 0.1074999999999946
Completed Iteration #10
Best Reward: 0.1074999999999946
Completed Iteration #11
Best Reward: 0.1074999999999946
Reward: 0.10583333333332945
backprop <src.mcts.MCTS_Node object at 0x7f81800f1978> 0.10583333333332945 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114630> 0.2733333333333192 4
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.5183333333333096 7
Completed Iteration #12
Best Reward: 0.1074999999999946
Reward: 0.10916666666665975
backprop <src.mcts.MCTS_Node object at 0x7f81800f1be0> 0.10916666666665975 2
backprop <src.mcts.MCTS_Node object at 0x7f81800f1198> 0.10916666666665975 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.6274999999999693 8
Completed Iteration #13
Best Reward: 0.10916666666665975
Completed Iteration #14
Best Reward: 0.10916666666665975
Completed Iteration #15
Best Reward: 0.10916666666665975
Reward: 0.11062499999999176
backprop <src.mcts.MCTS_Node object at 0x7f81800fb160> 0.11062499999999176 2
backprop <src.mcts.MCTS_Node object at 0x7f81800f1198> 0.2197916666666515 3
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.7381249999999611 9
Completed Iteration #16
Best Reward: 0.11062499999999176
Reward: 0.08374999999999488
backprop <src.mcts.MCTS_Node object at 0x7f81800f1e80> 0.08374999999999488 2
backprop <src.mcts.MCTS_Node object at 0x7f81800f1198> 0.3035416666666464 4
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.821874999999956 10
Completed Iteration #17
Best Reward: 0.11062499999999176
Completed Iteration #18
Best Reward: 0.11062499999999176
Completed Iteration #19
Best Reward: 0.11062499999999176
Reward: 0.10166666666666657
backprop <src.mcts.MCTS_Node object at 0x7f81800fb6d8> 0.10166666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114da0> 0.20624999999999716 3
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 0.9235416666666225 11
Completed Iteration #20
Best Reward: 0.11062499999999176
Completed Iteration #21
Best Reward: 0.11062499999999176
Completed Iteration #22
Best Reward: 0.11062499999999176
Reward: 0.08958333333333002
backprop <src.mcts.MCTS_Node object at 0x7f81800fbc18> 0.08958333333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb9b0> 0.08958333333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114c50> 1.0131249999999525 12
Completed Iteration #23
Best Reward: 0.11062499999999176
Completed Iteration #24
Best Reward: 0.11062499999999176
Completed Iteration #25
Best Reward: 0.11062499999999176
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11062499999999176
No reward increase. Abort.
iteration: 1
found coverage increase 0.11062499999999176
Current Total Coverage 38.01395833333333
Reward: 0.0975000000000037
backprop <src.mcts.MCTS_Node object at 0x7f81800fb6a0> 0.0975000000000037 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb898> 0.0975000000000037 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.0975000000000037 2
Completed Iteration #0
Best Reward: 0.0975000000000037
Reward: 0.10520833333333712
backprop <src.mcts.MCTS_Node object at 0x7f821c150470> 0.10520833333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815dba8> 0.10520833333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.20270833333334082 3
Completed Iteration #1
Best Reward: 0.10520833333333712
Completed Iteration #2
Best Reward: 0.10520833333333712
Completed Iteration #3
Best Reward: 0.10520833333333712
Reward: 0.03729166666666828
backprop <src.mcts.MCTS_Node object at 0x7f818013b9e8> 0.03729166666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114160> 0.03729166666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.2400000000000091 4
Completed Iteration #4
Best Reward: 0.10520833333333712
Reward: 0.10062500000000796
backprop <src.mcts.MCTS_Node object at 0x7f81800f1fd0> 0.10062500000000796 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815dba8> 0.20583333333334508 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.34062500000001705 5
Completed Iteration #5
Best Reward: 0.10520833333333712
Completed Iteration #6
Best Reward: 0.10520833333333712
Reward: 0.06854166666667538
backprop <src.mcts.MCTS_Node object at 0x7f818017fbe0> 0.06854166666667538 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e780> 0.06854166666667538 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.40916666666669244 6
Completed Iteration #7
Best Reward: 0.10520833333333712
Reward: 0.07083333333333997
backprop <src.mcts.MCTS_Node object at 0x7f81800fb278> 0.07083333333333997 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e780> 0.13937500000001535 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.4800000000000324 7
Completed Iteration #8
Best Reward: 0.10520833333333712
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f81800fbc88> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb630> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.5808333333333664 8
Completed Iteration #9
Best Reward: 0.10520833333333712
Reward: 0.0662500000000037
backprop <src.mcts.MCTS_Node object at 0x7f81800fb550> 0.0662500000000037 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb898> 0.1637500000000074 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.6470833333333701 9
Completed Iteration #10
Best Reward: 0.10520833333333712
Reward: 0.11333333333334394
backprop <src.mcts.MCTS_Node object at 0x7f818013b390> 0.11333333333334394 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb898> 0.27708333333335133 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.760416666666714 10
Completed Iteration #11
Best Reward: 0.11333333333334394
Reward: 0.10187500000000682
backprop <src.mcts.MCTS_Node object at 0x7f81800fb860> 0.10187500000000682 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b630> 0.10187500000000682 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.8622916666667209 11
Completed Iteration #12
Best Reward: 0.11333333333334394
Completed Iteration #13
Best Reward: 0.11333333333334394
Reward: 0.10208333333333997
backprop <src.mcts.MCTS_Node object at 0x7f8180114470> 0.10208333333333997 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b550> 0.10208333333333997 2
backprop <src.mcts.MCTS_Node object at 0x7f821c150470> 0.2072916666666771 3
backprop <src.mcts.MCTS_Node object at 0x7f81f815dba8> 0.30791666666668505 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 0.9643750000000608 12
Completed Iteration #14
Best Reward: 0.11333333333334394
Reward: 0.11375000000000313
backprop <src.mcts.MCTS_Node object at 0x7f81801142e8> 0.11375000000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f81801148d0> 0.11375000000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 1.078125000000064 13
Completed Iteration #15
Best Reward: 0.11375000000000313
Completed Iteration #16
Best Reward: 0.11375000000000313
Completed Iteration #17
Best Reward: 0.11375000000000313
Completed Iteration #18
Best Reward: 0.11375000000000313
Completed Iteration #19
Best Reward: 0.11375000000000313
Completed Iteration #20
Best Reward: 0.11375000000000313
Reward: 0.10250000000000625
backprop <src.mcts.MCTS_Node object at 0x7f81f815dc18> 0.10250000000000625 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb630> 0.20333333333334025 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 1.1806250000000702 14
Completed Iteration #21
Best Reward: 0.11375000000000313
Reward: 0.09854166666666941
backprop <src.mcts.MCTS_Node object at 0x7f818012ed30> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f818012ef98> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 1.2791666666667396 15
Completed Iteration #22
Best Reward: 0.11375000000000313
Reward: 0.1060416666666697
backprop <src.mcts.MCTS_Node object at 0x7f818012eef0> 0.1060416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb898> 0.38312500000002103 5
backprop <src.mcts.MCTS_Node object at 0x7f81800fb3c8> 1.3852083333334093 16
Completed Iteration #23
Best Reward: 0.11375000000000313
Completed Iteration #24
Best Reward: 0.11375000000000313
Completed Iteration #25
Best Reward: 0.11375000000000313
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11375000000000313
No reward increase. Abort.
iteration: 2
found coverage increase 0.11375000000000313
Current Total Coverage 38.12770833333333
Reward: 0.07166666666667254
backprop <src.mcts.MCTS_Node object at 0x7f818012e358> 0.07166666666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fe48> 0.07166666666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.07166666666667254 2
Completed Iteration #0
Best Reward: 0.07166666666667254
Reward: 0.09520833333333911
backprop <src.mcts.MCTS_Node object at 0x7f81800f16d8> 0.09520833333333911 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114080> 0.09520833333333911 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.16687500000001165 3
Completed Iteration #1
Best Reward: 0.09520833333333911
Reward: 0.04916666666666458
backprop <src.mcts.MCTS_Node object at 0x7f81821c2160> 0.04916666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fd68> 0.04916666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.21604166666667624 4
Completed Iteration #2
Best Reward: 0.09520833333333911
Reward: 0.09437500000000654
backprop <src.mcts.MCTS_Node object at 0x7f81821c25c0> 0.09437500000000654 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2320> 0.09437500000000654 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.3104166666666828 5
Completed Iteration #3
Best Reward: 0.09520833333333911
Reward: 0.10249999999999915
backprop <src.mcts.MCTS_Node object at 0x7f81821c2898> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fe48> 0.1741666666666717 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.4129166666666819 6
Completed Iteration #4
Best Reward: 0.10249999999999915
Reward: 0.07041666666666657
backprop <src.mcts.MCTS_Node object at 0x7f81821c2be0> 0.07041666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2860> 0.07041666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.4833333333333485 7
Completed Iteration #5
Best Reward: 0.10249999999999915
Reward: 0.026666666666670835
backprop <src.mcts.MCTS_Node object at 0x7f81821c2eb8> 0.026666666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2ba8> 0.026666666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.5100000000000193 8
Completed Iteration #6
Best Reward: 0.10249999999999915
Reward: 0.08833333333333826
backprop <src.mcts.MCTS_Node object at 0x7f81821c2240> 0.08833333333333826 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114080> 0.18354166666667737 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.5983333333333576 9
Completed Iteration #7
Best Reward: 0.10249999999999915
Reward: 0.10020833333333456
backprop <src.mcts.MCTS_Node object at 0x7f8182187278> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fd68> 0.14937499999999915 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.6985416666666922 10
Completed Iteration #8
Best Reward: 0.10249999999999915
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f8182187550> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fd68> 0.25020833333333314 4
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.7993750000000261 11
Completed Iteration #9
Best Reward: 0.10249999999999915
Reward: 0.032083333333332575
backprop <src.mcts.MCTS_Node object at 0x7f8182187828> 0.032083333333332575 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2ba8> 0.05875000000000341 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.8314583333333587 12
Completed Iteration #10
Best Reward: 0.10249999999999915
Reward: 0.09333333333333371
backprop <src.mcts.MCTS_Node object at 0x7f8182187b00> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114080> 0.2768750000000111 4
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 0.9247916666666924 13
Completed Iteration #11
Best Reward: 0.10249999999999915
Reward: 0.09958333333333513
backprop <src.mcts.MCTS_Node object at 0x7f8182187dd8> 0.09958333333333513 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fd68> 0.3497916666666683 5
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.0243750000000276 14
Completed Iteration #12
Best Reward: 0.10249999999999915
Reward: 0.05250000000000199
backprop <src.mcts.MCTS_Node object at 0x7f81821900f0> 0.05250000000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2320> 0.14687500000000853 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.0768750000000296 15
Completed Iteration #13
Best Reward: 0.10249999999999915
Reward: 0.1027083333333394
backprop <src.mcts.MCTS_Node object at 0x7f81800fb4a8> 0.1027083333333394 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fd68> 0.4525000000000077 6
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.179583333333369 16
Completed Iteration #14
Best Reward: 0.1027083333333394
Reward: 0.09125000000000227
backprop <src.mcts.MCTS_Node object at 0x7f81f815d7f0> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fbeb8> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.2708333333333712 17
Completed Iteration #15
Best Reward: 0.1027083333333394
Completed Iteration #16
Best Reward: 0.1027083333333394
Completed Iteration #17
Best Reward: 0.1027083333333394
Completed Iteration #18
Best Reward: 0.1027083333333394
Reward: 0.0625
backprop <src.mcts.MCTS_Node object at 0x7f818012e630> 0.0625 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2860> 0.13291666666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.3333333333333712 18
Completed Iteration #19
Best Reward: 0.1027083333333394
Completed Iteration #20
Best Reward: 0.1027083333333394
coverage_call_count 100
Reward: 0.09354166666666686
backprop <src.mcts.MCTS_Node object at 0x7f818017ff60> 0.09354166666666686 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fbeb8> 0.18479166666666913 3
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.426875000000038 19
Completed Iteration #21
Best Reward: 0.1027083333333394
Reward: 0.11062500000000597
backprop <src.mcts.MCTS_Node object at 0x7f818012e828> 0.11062500000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2860> 0.24354166666667254 4
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.537500000000044 20
Completed Iteration #22
Best Reward: 0.11062500000000597
Reward: 0.09708333333333741
backprop <src.mcts.MCTS_Node object at 0x7f8180114748> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2ba8> 0.15583333333334082 4
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.6345833333333815 21
Completed Iteration #23
Best Reward: 0.11062500000000597
Reward: 0.06687500000000313
backprop <src.mcts.MCTS_Node object at 0x7f81821c2780> 0.06687500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2860> 0.31041666666667567 5
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.7014583333333846 22
Completed Iteration #24
Best Reward: 0.11062500000000597
Reward: 0.10645833333333599
backprop <src.mcts.MCTS_Node object at 0x7f81821c2cc0> 0.10645833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2320> 0.2533333333333445 4
backprop <src.mcts.MCTS_Node object at 0x7f818017fa20> 1.8079166666667206 23
Completed Iteration #25
Best Reward: 0.11062500000000597
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11062500000000597
No reward increase. Abort.
iteration: 3
found coverage increase 0.11062500000000597
Current Total Coverage 38.23833333333334
Reward: 0.10958333333332604
backprop <src.mcts.MCTS_Node object at 0x7f81821c29b0> 0.10958333333332604 2
backprop <src.mcts.MCTS_Node object at 0x7f81821878d0> 0.10958333333332604 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.10958333333332604 2
Completed Iteration #0
Best Reward: 0.10958333333332604
Reward: 0.10270833333332519
backprop <src.mcts.MCTS_Node object at 0x7f8182187780> 0.10270833333332519 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b2e8> 0.10270833333332519 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.21229166666665122 3
Completed Iteration #1
Best Reward: 0.10958333333332604
Reward: 0.10770833333333485
backprop <src.mcts.MCTS_Node object at 0x7f8182187630> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187940> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.3199999999999861 4
Completed Iteration #2
Best Reward: 0.10958333333332604
Reward: 0.0952083333333249
backprop <src.mcts.MCTS_Node object at 0x7f8182187cf8> 0.0952083333333249 2
backprop <src.mcts.MCTS_Node object at 0x7f81821878d0> 0.20479166666665094 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.415208333333311 5
Completed Iteration #3
Best Reward: 0.10958333333332604
Reward: 0.12166666666666259
backprop <src.mcts.MCTS_Node object at 0x7f8182190320> 0.12166666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187eb8> 0.12166666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c29b0> 0.23124999999998863 3
backprop <src.mcts.MCTS_Node object at 0x7f81821878d0> 0.32645833333331353 4
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.5368749999999736 6
Completed Iteration #4
Best Reward: 0.12166666666666259
Reward: 0.1004166666666606
backprop <src.mcts.MCTS_Node object at 0x7f8182187358> 0.1004166666666606 2
backprop <src.mcts.MCTS_Node object at 0x7f81821904a8> 0.1004166666666606 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.6372916666666342 7
Completed Iteration #5
Best Reward: 0.12166666666666259
Completed Iteration #6
Best Reward: 0.12166666666666259
Completed Iteration #7
Best Reward: 0.12166666666666259
Reward: 0.08270833333332916
backprop <src.mcts.MCTS_Node object at 0x7f81821c2e10> 0.08270833333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b2e8> 0.18541666666665435 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.7199999999999633 8
Completed Iteration #8
Best Reward: 0.12166666666666259
Reward: 0.10479166666666373
backprop <src.mcts.MCTS_Node object at 0x7f818017fa58> 0.10479166666666373 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2160> 0.10479166666666373 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.8247916666666271 9
Completed Iteration #9
Best Reward: 0.12166666666666259
Reward: 0.10874999999999346
backprop <src.mcts.MCTS_Node object at 0x7f8180114dd8> 0.10874999999999346 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114748> 0.10874999999999346 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 0.9335416666666205 10
Completed Iteration #10
Best Reward: 0.12166666666666259
Completed Iteration #11
Best Reward: 0.12166666666666259
Completed Iteration #12
Best Reward: 0.12166666666666259
Reward: 0.10604166666666259
backprop <src.mcts.MCTS_Node object at 0x7f81800f19b0> 0.10604166666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187940> 0.21374999999999744 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.0395833333332831 11
Completed Iteration #13
Best Reward: 0.12166666666666259
Reward: 0.11062499999999886
backprop <src.mcts.MCTS_Node object at 0x7f81801148d0> 0.11062499999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187550> 0.11062499999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.150208333333282 12
Completed Iteration #14
Best Reward: 0.12166666666666259
Completed Iteration #15
Best Reward: 0.12166666666666259
Reward: 0.08812499999999801
backprop <src.mcts.MCTS_Node object at 0x7f81800fbeb8> 0.08812499999999801 2
backprop <src.mcts.MCTS_Node object at 0x7f81801142e8> 0.08812499999999801 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.23833333333328 13
Completed Iteration #16
Best Reward: 0.12166666666666259
Completed Iteration #17
Best Reward: 0.12166666666666259
Reward: 0.03812500000000085
backprop <src.mcts.MCTS_Node object at 0x7f818013b978> 0.03812500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114748> 0.14687499999999432 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.2764583333332808 14
Completed Iteration #18
Best Reward: 0.12166666666666259
Reward: 0.10624999999999574
backprop <src.mcts.MCTS_Node object at 0x7f818012ec88> 0.10624999999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2160> 0.21104166666665947 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.3827083333332766 15
Completed Iteration #19
Best Reward: 0.12166666666666259
Completed Iteration #20
Best Reward: 0.12166666666666259
Reward: 0.08645833333333286
backprop <src.mcts.MCTS_Node object at 0x7f818012e898> 0.08645833333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b2e8> 0.2718749999999872 4
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.4691666666666094 16
Completed Iteration #21
Best Reward: 0.12166666666666259
Completed Iteration #22
Best Reward: 0.12166666666666259
Reward: 0.0814583333333303
backprop <src.mcts.MCTS_Node object at 0x7f818012e0b8> 0.0814583333333303 2
backprop <src.mcts.MCTS_Node object at 0x7f818013b2e8> 0.3533333333333175 5
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.5506249999999397 17
Completed Iteration #23
Best Reward: 0.12166666666666259
Completed Iteration #24
Best Reward: 0.12166666666666259
Reward: 0.08124999999999716
backprop <src.mcts.MCTS_Node object at 0x7f818013b048> 0.08124999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f81801142e8> 0.16937499999999517 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187c18> 1.631874999999937 18
Completed Iteration #25
Best Reward: 0.12166666666666259
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12166666666666259
No reward increase. Abort.
iteration: 4
found coverage increase 0.12166666666666259
Current Total Coverage 38.36
Reward: 0.11145833333333854
backprop <src.mcts.MCTS_Node object at 0x7f818013b630> 0.11145833333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb1d0> 0.11145833333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.11145833333333854 2
Completed Iteration #0
Best Reward: 0.11145833333333854
Completed Iteration #1
Best Reward: 0.11145833333333854
Reward: 0.054999999999999716
backprop <src.mcts.MCTS_Node object at 0x7f81821872b0> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fbcc0> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.16645833333333826 3
Completed Iteration #2
Best Reward: 0.11145833333333854
Reward: 0.10187499999999972
backprop <src.mcts.MCTS_Node object at 0x7f8182187c88> 0.10187499999999972 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb1d0> 0.21333333333333826 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.268333333333338 4
Completed Iteration #3
Best Reward: 0.11145833333333854
Reward: 0.11145833333333854
backprop <src.mcts.MCTS_Node object at 0x7f81821c26a0> 0.11145833333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187b70> 0.11145833333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.3797916666666765 5
Completed Iteration #4
Best Reward: 0.11145833333333854
Reward: 0.08041666666666458
backprop <src.mcts.MCTS_Node object at 0x7f81821c2748> 0.08041666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c28d0> 0.08041666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.4602083333333411 6
Completed Iteration #5
Best Reward: 0.11145833333333854
Reward: 0.06937500000000085
backprop <src.mcts.MCTS_Node object at 0x7f81821c2668> 0.06937500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187b70> 0.1808333333333394 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.529583333333342 7
Completed Iteration #6
Best Reward: 0.11145833333333854
Reward: 0.05354166666666771
backprop <src.mcts.MCTS_Node object at 0x7f8182187898> 0.05354166666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fbcc0> 0.10854166666666742 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.5831250000000097 8
Completed Iteration #7
Best Reward: 0.11145833333333854
Completed Iteration #8
Best Reward: 0.11145833333333854
Reward: 0.030416666666667425
backprop <src.mcts.MCTS_Node object at 0x7f8180114208> 0.030416666666667425 2
backprop <src.mcts.MCTS_Node object at 0x7f81800f1240> 0.030416666666667425 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.6135416666666771 9
Completed Iteration #9
Best Reward: 0.11145833333333854
Completed Iteration #10
Best Reward: 0.11145833333333854
Completed Iteration #11
Best Reward: 0.11145833333333854
Reward: 0.11729166666666657
backprop <src.mcts.MCTS_Node object at 0x7f81821907f0> 0.11729166666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187b70> 0.29812500000000597 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.7308333333333437 10
Completed Iteration #12
Best Reward: 0.11729166666666657
Reward: 0.085208333333334
backprop <src.mcts.MCTS_Node object at 0x7f8180114c18> 0.085208333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190518> 0.085208333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.8160416666666777 11
Completed Iteration #13
Best Reward: 0.11729166666666657
Completed Iteration #14
Best Reward: 0.11729166666666657
Completed Iteration #15
Best Reward: 0.11729166666666657
Reward: 0.11229166666667112
backprop <src.mcts.MCTS_Node object at 0x7f8182190c88> 0.11229166666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f818017f908> 0.11229166666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.9283333333333488 12
Completed Iteration #16
Best Reward: 0.11729166666666657
Completed Iteration #17
Best Reward: 0.11729166666666657
Reward: 0.10437500000000455
backprop <src.mcts.MCTS_Node object at 0x7f818217d128> 0.10437500000000455 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114b70> 0.10437500000000455 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 1.0327083333333533 13
Completed Iteration #18
Best Reward: 0.11729166666666657
Reward: 0.10916666666666686
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.10916666666666686 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d0b8> 0.10916666666666686 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 1.1418750000000202 14
Completed Iteration #19
Best Reward: 0.11729166666666657
Completed Iteration #20
Best Reward: 0.11729166666666657
Reward: 0.0743749999999963
backprop <src.mcts.MCTS_Node object at 0x7f8182190e48> 0.0743749999999963 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c28d0> 0.1547916666666609 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 1.2162500000000165 15
Completed Iteration #21
Best Reward: 0.11729166666666657
Reward: 0.10854166666666742
backprop <src.mcts.MCTS_Node object at 0x7f818217d710> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f81800f1240> 0.13895833333333485 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 1.324791666666684 16
Completed Iteration #22
Best Reward: 0.11729166666666657
Completed Iteration #23
Best Reward: 0.11729166666666657
Reward: 0.11375000000000313
backprop <src.mcts.MCTS_Node object at 0x7f818217dcc0> 0.11375000000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f81800f1240> 0.252708333333338 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 1.438541666666687 17
Completed Iteration #24
Best Reward: 0.11729166666666657
Completed Iteration #25
Best Reward: 0.11729166666666657
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11729166666666657
No reward increase. Abort.
iteration: 5
found coverage increase 0.11729166666666657
Current Total Coverage 38.477291666666666
Reward: 0.10520833333333002
backprop <src.mcts.MCTS_Node object at 0x7f818217dd68> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d208> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.10520833333333002 2
Completed Iteration #0
Best Reward: 0.10520833333333002
Completed Iteration #1
Best Reward: 0.10520833333333002
Reward: 0.051666666666669414
backprop <src.mcts.MCTS_Node object at 0x7f818210d4a8> 0.051666666666669414 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6a0> 0.051666666666669414 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.15687499999999943 3
Completed Iteration #2
Best Reward: 0.10520833333333002
Reward: 0.0941666666666734
backprop <src.mcts.MCTS_Node object at 0x7f818210d978> 0.0941666666666734 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d128> 0.0941666666666734 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.2510416666666728 4
Completed Iteration #3
Best Reward: 0.10520833333333002
Completed Iteration #4
Best Reward: 0.10520833333333002
Reward: 0.11374999999999602
backprop <src.mcts.MCTS_Node object at 0x7f818210df98> 0.11374999999999602 2
backprop <src.mcts.MCTS_Node object at 0x7f818210deb8> 0.11374999999999602 2
backprop <src.mcts.MCTS_Node object at 0x7f818217dd68> 0.21895833333332604 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d208> 0.21895833333332604 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.36479166666666885 5
Completed Iteration #5
Best Reward: 0.11374999999999602
Reward: 0.07208333333333883
backprop <src.mcts.MCTS_Node object at 0x7f818013b860> 0.07208333333333883 2
backprop <src.mcts.MCTS_Node object at 0x7f818017ff60> 0.07208333333333883 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.4368750000000077 6
Completed Iteration #6
Best Reward: 0.11374999999999602
Reward: 0.06687500000000313
backprop <src.mcts.MCTS_Node object at 0x7f818012e908> 0.06687500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d940> 0.06687500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.5037500000000108 7
Completed Iteration #7
Best Reward: 0.11374999999999602
Reward: 0.07541666666666913
backprop <src.mcts.MCTS_Node object at 0x7f8180114940> 0.07541666666666913 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d940> 0.14229166666667226 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.5791666666666799 8
Completed Iteration #8
Best Reward: 0.11374999999999602
Completed Iteration #9
Best Reward: 0.11374999999999602
Reward: 0.10854166666666742
backprop <src.mcts.MCTS_Node object at 0x7f81821c2f28> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f81821872e8> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.6877083333333474 9
Completed Iteration #10
Best Reward: 0.11374999999999602
Reward: 0.07187499999999858
backprop <src.mcts.MCTS_Node object at 0x7f81821c2898> 0.07187499999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d940> 0.21416666666667084 4
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.7595833333333459 10
Completed Iteration #11
Best Reward: 0.11374999999999602
Reward: 0.12083333333333712
backprop <src.mcts.MCTS_Node object at 0x7f8182190a58> 0.12083333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f81821905f8> 0.12083333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2f28> 0.22937500000000455 3
backprop <src.mcts.MCTS_Node object at 0x7f81821872e8> 0.22937500000000455 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.8804166666666831 11
Completed Iteration #12
Best Reward: 0.12083333333333712
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f81821c27b8> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d940> 0.31500000000000483 5
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.981250000000017 12
Completed Iteration #13
Best Reward: 0.12083333333333712
Reward: 0.069583333333334
backprop <src.mcts.MCTS_Node object at 0x7f81800fb5f8> 0.069583333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f818017ff60> 0.14166666666667282 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 1.050833333333351 13
Completed Iteration #14
Best Reward: 0.12083333333333712
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f818217d320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6a0> 0.15583333333334082 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 1.1550000000000225 14
Completed Iteration #15
Best Reward: 0.12083333333333712
Completed Iteration #16
Best Reward: 0.12083333333333712
Completed Iteration #17
Best Reward: 0.12083333333333712
Completed Iteration #18
Best Reward: 0.12083333333333712
Reward: 0.09979166666666828
backprop <src.mcts.MCTS_Node object at 0x7f818210da90> 0.09979166666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d208> 0.3187499999999943 4
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 1.2547916666666907 15
Completed Iteration #19
Best Reward: 0.12083333333333712
Completed Iteration #20
Best Reward: 0.12083333333333712
Completed Iteration #21
Best Reward: 0.12083333333333712
Reward: 0.10770833333333485
backprop <src.mcts.MCTS_Node object at 0x7f818217d6a0> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d940> 0.4227083333333397 6
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 1.3625000000000256 16
Completed Iteration #22
Best Reward: 0.12083333333333712
Completed Iteration #23
Best Reward: 0.12083333333333712
Reward: 0.08104166666666401
backprop <src.mcts.MCTS_Node object at 0x7f81821c2828> 0.08104166666666401 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d3c8> 0.08104166666666401 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 1.4435416666666896 17
Completed Iteration #24
Best Reward: 0.12083333333333712
Completed Iteration #25
Best Reward: 0.12083333333333712
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12083333333333712
No reward increase. Abort.
iteration: 6
found coverage increase 0.12083333333333712
Current Total Coverage 38.598125
Reward: 0.09854166666666231
backprop <src.mcts.MCTS_Node object at 0x7f81821c2748> 0.09854166666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190898> 0.09854166666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.09854166666666231 2
Completed Iteration #0
Best Reward: 0.09854166666666231
Reward: 0.09604166666666458
backprop <src.mcts.MCTS_Node object at 0x7f81821900f0> 0.09604166666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.09604166666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.1945833333333269 3
Completed Iteration #1
Best Reward: 0.09854166666666231
Completed Iteration #2
Best Reward: 0.09854166666666231
Reward: 0.10125000000000028
backprop <src.mcts.MCTS_Node object at 0x7f818013bf28> 0.10125000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187320> 0.10125000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.2958333333333272 4
Completed Iteration #3
Best Reward: 0.10125000000000028
Reward: 0.069583333333334
backprop <src.mcts.MCTS_Node object at 0x7f81800f1390> 0.069583333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187320> 0.17083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.36541666666666117 5
Completed Iteration #4
Best Reward: 0.10125000000000028
Completed Iteration #5
Best Reward: 0.10125000000000028
Completed Iteration #6
Best Reward: 0.10125000000000028
Reward: 0.10916666666665975
backprop <src.mcts.MCTS_Node object at 0x7f81821872b0> 0.10916666666665975 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123470> 0.10916666666665975 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2748> 0.20770833333332206 3
backprop <src.mcts.MCTS_Node object at 0x7f8182190898> 0.20770833333332206 3
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.4745833333333209 6
Completed Iteration #7
Best Reward: 0.10916666666665975
Reward: 0.10479166666666373
backprop <src.mcts.MCTS_Node object at 0x7f8182123320> 0.10479166666666373 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.2008333333333283 3
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.5793749999999847 7
Completed Iteration #8
Best Reward: 0.10916666666665975
Completed Iteration #9
Best Reward: 0.10916666666665975
Reward: 0.09833333333332916
backprop <src.mcts.MCTS_Node object at 0x7f8182123898> 0.09833333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123908> 0.09833333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.6777083333333138 8
Completed Iteration #10
Best Reward: 0.10916666666665975
Reward: 0.09833333333332916
backprop <src.mcts.MCTS_Node object at 0x7f8182123c50> 0.09833333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123048> 0.09833333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.776041666666643 9
Completed Iteration #11
Best Reward: 0.10916666666665975
Reward: 0.058749999999996305
backprop <src.mcts.MCTS_Node object at 0x7f8182123f98> 0.058749999999996305 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123908> 0.15708333333332547 3
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.8347916666666393 10
Completed Iteration #12
Best Reward: 0.10916666666665975
coverage_call_count 200
Completed Iteration #13
Best Reward: 0.10916666666665975
Reward: 0.0691666666666606
backprop <src.mcts.MCTS_Node object at 0x7f8182123d68> 0.0691666666666606 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187320> 0.23999999999999488 4
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 0.9039583333332999 11
Completed Iteration #14
Best Reward: 0.10916666666665975
Reward: 0.10208333333333286
backprop <src.mcts.MCTS_Node object at 0x7f81821c2d68> 0.10208333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123048> 0.20041666666666202 3
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.0060416666666328 12
Completed Iteration #15
Best Reward: 0.10916666666665975
Reward: 0.06666666666666288
backprop <src.mcts.MCTS_Node object at 0x7f81821c24a8> 0.06666666666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187320> 0.30666666666665776 5
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.0727083333332956 13
Completed Iteration #16
Best Reward: 0.10916666666665975
Reward: 0.10187499999999972
backprop <src.mcts.MCTS_Node object at 0x7f818217def0> 0.10187499999999972 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb1d0> 0.10187499999999972 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.1745833333332953 14
Completed Iteration #17
Best Reward: 0.10916666666665975
Completed Iteration #18
Best Reward: 0.10916666666665975
Reward: 0.09624999999999773
backprop <src.mcts.MCTS_Node object at 0x7f81821909e8> 0.09624999999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190470> 0.09624999999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.270833333333293 15
Completed Iteration #19
Best Reward: 0.10916666666665975
Reward: 0.10145833333332632
backprop <src.mcts.MCTS_Node object at 0x7f818013bc88> 0.10145833333332632 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123048> 0.30187499999998835 4
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.3722916666666194 16
Completed Iteration #20
Best Reward: 0.10916666666665975
Reward: 0.057083333333331154
backprop <src.mcts.MCTS_Node object at 0x7f818012eef0> 0.057083333333331154 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e6d8> 0.057083333333331154 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.4293749999999505 17
Completed Iteration #21
Best Reward: 0.10916666666665975
Completed Iteration #22
Best Reward: 0.10916666666665975
Reward: 0.09479166666666572
backprop <src.mcts.MCTS_Node object at 0x7f81821907f0> 0.09479166666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.29562499999999403 4
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.5241666666666163 18
Completed Iteration #23
Best Reward: 0.10916666666665975
Completed Iteration #24
Best Reward: 0.10916666666665975
Reward: 0.06166666666666032
backprop <src.mcts.MCTS_Node object at 0x7f81f815dc18> 0.06166666666666032 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123908> 0.2187499999999858 4
backprop <src.mcts.MCTS_Node object at 0x7f8182190da0> 1.5858333333332766 19
Completed Iteration #25
Best Reward: 0.10916666666665975
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10916666666665975
No reward increase. Abort.
iteration: 7
found coverage increase 0.10916666666665975
Current Total Coverage 38.70729166666666
Reward: 0.10770833333333485
backprop <src.mcts.MCTS_Node object at 0x7f818210d550> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d7f0> 0.10770833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.10770833333333485 2
Completed Iteration #0
Best Reward: 0.10770833333333485
Reward: 0.10125000000000739
backprop <src.mcts.MCTS_Node object at 0x7f81821239b0> 0.10125000000000739 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.10125000000000739 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.20895833333334224 3
Completed Iteration #1
Best Reward: 0.10770833333333485
Reward: 0.03520833333333684
backprop <src.mcts.MCTS_Node object at 0x7f8182123ef0> 0.03520833333333684 2
backprop <src.mcts.MCTS_Node object at 0x7f81821238d0> 0.03520833333333684 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.24416666666667908 4
Completed Iteration #2
Best Reward: 0.10770833333333485
Reward: 0.11625000000000085
backprop <src.mcts.MCTS_Node object at 0x7f8182123748> 0.11625000000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123dd8> 0.11625000000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d550> 0.2239583333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d7f0> 0.2239583333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.36041666666667993 5
Completed Iteration #3
Best Reward: 0.11625000000000085
Reward: 0.10833333333333428
backprop <src.mcts.MCTS_Node object at 0x7f81820e0630> 0.10833333333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0278> 0.10833333333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.4687500000000142 6
Completed Iteration #4
Best Reward: 0.11625000000000085
Reward: 0.0956249999999983
backprop <src.mcts.MCTS_Node object at 0x7f81820e07f0> 0.0956249999999983 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0588> 0.0956249999999983 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.5643750000000125 7
Completed Iteration #5
Best Reward: 0.11625000000000085
Reward: 0.09812500000000313
backprop <src.mcts.MCTS_Node object at 0x7f81820e0ac8> 0.09812500000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0278> 0.2064583333333374 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.6625000000000156 8
Completed Iteration #6
Best Reward: 0.11625000000000085
Completed Iteration #7
Best Reward: 0.11625000000000085
Reward: 0.09354166666667396
backprop <src.mcts.MCTS_Node object at 0x7f81820e0eb8> 0.09354166666667396 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.19479166666668135 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.7560416666666896 9
Completed Iteration #8
Best Reward: 0.11625000000000085
Reward: 0.09875000000000256
backprop <src.mcts.MCTS_Node object at 0x7f81820e0e10> 0.09875000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0d68> 0.09875000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.8547916666666922 10
Completed Iteration #9
Best Reward: 0.11625000000000085
Reward: 0.0629166666666734
backprop <src.mcts.MCTS_Node object at 0x7f81820952b0> 0.0629166666666734 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0588> 0.1585416666666717 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 0.9177083333333655 11
Completed Iteration #10
Best Reward: 0.11625000000000085
Completed Iteration #11
Best Reward: 0.11625000000000085
Reward: 0.0937500000000071
backprop <src.mcts.MCTS_Node object at 0x7f8182095710> 0.0937500000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095780> 0.0937500000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.0114583333333727 12
Completed Iteration #12
Best Reward: 0.11625000000000085
Reward: 0.11270833333333741
backprop <src.mcts.MCTS_Node object at 0x7f8182095ac8> 0.11270833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095780> 0.2064583333333445 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.12416666666671 13
Completed Iteration #13
Best Reward: 0.11625000000000085
Reward: 0.10812500000000824
backprop <src.mcts.MCTS_Node object at 0x7f8182095da0> 0.10812500000000824 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0278> 0.31458333333334565 4
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.2322916666667183 14
Completed Iteration #14
Best Reward: 0.11625000000000085
Reward: 0.09583333333333854
backprop <src.mcts.MCTS_Node object at 0x7f8182095be0> 0.09583333333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.2906250000000199 4
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.3281250000000568 15
Completed Iteration #15
Best Reward: 0.11625000000000085
Completed Iteration #16
Best Reward: 0.11625000000000085
Reward: 0.09854166666666941
backprop <src.mcts.MCTS_Node object at 0x7f81820a2160> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0d68> 0.19729166666667197 3
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.4266666666667263 16
Completed Iteration #17
Best Reward: 0.11625000000000085
Completed Iteration #18
Best Reward: 0.11625000000000085
Reward: 0.0989583333333357
backprop <src.mcts.MCTS_Node object at 0x7f818013be48> 0.0989583333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.3895833333333556 5
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.525625000000062 17
Completed Iteration #19
Best Reward: 0.11625000000000085
Reward: 0.10249999999999915
backprop <src.mcts.MCTS_Node object at 0x7f8182190438> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.49208333333335474 6
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.628125000000061 18
Completed Iteration #20
Best Reward: 0.11625000000000085
Reward: 0.09541666666667226
backprop <src.mcts.MCTS_Node object at 0x7f81800fb4a8> 0.09541666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.587500000000027 7
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.7235416666667334 19
Completed Iteration #21
Best Reward: 0.11625000000000085
Completed Iteration #22
Best Reward: 0.11625000000000085
Completed Iteration #23
Best Reward: 0.11625000000000085
Reward: 0.10437500000000455
backprop <src.mcts.MCTS_Node object at 0x7f818012ee48> 0.10437500000000455 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0588> 0.26291666666667624 4
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.827916666666738 20
Completed Iteration #24
Best Reward: 0.11625000000000085
Reward: 0.10104166666667425
backprop <src.mcts.MCTS_Node object at 0x7f81821c2860> 0.10104166666667425 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0588> 0.3639583333333505 5
backprop <src.mcts.MCTS_Node object at 0x7f818210d6d8> 1.9289583333334122 21
Completed Iteration #25
Best Reward: 0.11625000000000085
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11625000000000085
No reward increase. Abort.
iteration: 8
found coverage increase 0.11625000000000085
Current Total Coverage 38.823541666666664
Reward: 0.10145833333333343
backprop <src.mcts.MCTS_Node object at 0x7f8182123978> 0.10145833333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123668> 0.10145833333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.10145833333333343 2
Completed Iteration #0
Best Reward: 0.10145833333333343
Completed Iteration #1
Best Reward: 0.10145833333333343
Reward: 0.09854166666666941
backprop <src.mcts.MCTS_Node object at 0x7f8180114240> 0.09854166666666941 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123668> 0.20000000000000284 3
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.20000000000000284 3
Completed Iteration #2
Best Reward: 0.10145833333333343
Reward: 0.06562500000000426
backprop <src.mcts.MCTS_Node object at 0x7f81800f1390> 0.06562500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f818012ee48> 0.06562500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.2656250000000071 4
Completed Iteration #3
Best Reward: 0.10145833333333343
Reward: 0.09687500000000426
backprop <src.mcts.MCTS_Node object at 0x7f818210d550> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f818210de80> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.36250000000001137 5
Completed Iteration #4
Best Reward: 0.10145833333333343
Reward: 0.08416666666666828
backprop <src.mcts.MCTS_Node object at 0x7f81821c20b8> 0.08416666666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f818210de80> 0.18104166666667254 3
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.44666666666667965 6
Completed Iteration #5
Best Reward: 0.10145833333333343
Reward: 0.09875000000000256
backprop <src.mcts.MCTS_Node object at 0x7f818217d6d8> 0.09875000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f818012ee48> 0.16437500000000682 3
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.5454166666666822 7
Completed Iteration #6
Best Reward: 0.10145833333333343
Reward: 0.058958333333336554
backprop <src.mcts.MCTS_Node object at 0x7f8182123550> 0.058958333333336554 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d978> 0.058958333333336554 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.6043750000000188 8
Completed Iteration #7
Best Reward: 0.10145833333333343
Completed Iteration #8
Best Reward: 0.10145833333333343
Completed Iteration #9
Best Reward: 0.10145833333333343
Reward: 0.08583333333334053
backprop <src.mcts.MCTS_Node object at 0x7f81800fb518> 0.08583333333334053 2
backprop <src.mcts.MCTS_Node object at 0x7f818210de80> 0.2668750000000131 4
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.6902083333333593 9
Completed Iteration #10
Best Reward: 0.10145833333333343
Completed Iteration #11
Best Reward: 0.10145833333333343
Reward: 0.09791666666666998
backprop <src.mcts.MCTS_Node object at 0x7f81821909e8> 0.09791666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123668> 0.2979166666666728 4
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.7881250000000293 10
Completed Iteration #12
Best Reward: 0.10145833333333343
Reward: 0.06791666666666885
backprop <src.mcts.MCTS_Node object at 0x7f8182095828> 0.06791666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d978> 0.1268750000000054 3
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.8560416666666981 11
Completed Iteration #13
Best Reward: 0.10145833333333343
Reward: 0.10958333333334025
backprop <src.mcts.MCTS_Node object at 0x7f81820953c8> 0.10958333333334025 2
backprop <src.mcts.MCTS_Node object at 0x7f818210de80> 0.3764583333333533 5
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 0.9656250000000384 12
Completed Iteration #14
Best Reward: 0.10958333333334025
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f8182095e48> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095160> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.0647916666667072 13
Completed Iteration #15
Best Reward: 0.10958333333334025
Reward: 0.030833333333340818
backprop <src.mcts.MCTS_Node object at 0x7f8182095898> 0.030833333333340818 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095be0> 0.030833333333340818 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.095625000000048 14
Completed Iteration #16
Best Reward: 0.10958333333334025
Reward: 0.10145833333333343
backprop <src.mcts.MCTS_Node object at 0x7f81820955c0> 0.10145833333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d978> 0.22833333333333883 4
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.1970833333333815 15
Completed Iteration #17
Best Reward: 0.10958333333334025
Reward: 0.09937500000000199
backprop <src.mcts.MCTS_Node object at 0x7f8182123320> 0.09937500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f818210de80> 0.4758333333333553 6
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.2964583333333835 16
Completed Iteration #18
Best Reward: 0.10958333333334025
Reward: 0.10020833333333456
backprop <src.mcts.MCTS_Node object at 0x7f81820e02b0> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f818012eb70> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.396666666666718 17
Completed Iteration #19
Best Reward: 0.10958333333334025
Reward: 0.0956250000000054
backprop <src.mcts.MCTS_Node object at 0x7f81820e0780> 0.0956250000000054 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123668> 0.3935416666666782 5
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.4922916666667234 18
Completed Iteration #20
Best Reward: 0.10958333333334025
Reward: 0.10875000000000767
backprop <src.mcts.MCTS_Node object at 0x7f81820e0320> 0.10875000000000767 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095be0> 0.1395833333333485 3
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.601041666666731 19
Completed Iteration #21
Best Reward: 0.10958333333334025
Completed Iteration #22
Best Reward: 0.10958333333334025
Completed Iteration #23
Best Reward: 0.10958333333334025
Reward: 0.0643750000000054
backprop <src.mcts.MCTS_Node object at 0x7f81820a2470> 0.0643750000000054 2
backprop <src.mcts.MCTS_Node object at 0x7f818012ee48> 0.22875000000001222 4
backprop <src.mcts.MCTS_Node object at 0x7f8182123828> 1.6654166666667365 20
Completed Iteration #24
Best Reward: 0.10958333333334025
Completed Iteration #25
Best Reward: 0.10958333333334025
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10958333333334025
No reward increase. Abort.
iteration: 9
found coverage increase 0.10958333333334025
Current Total Coverage 38.933125000000004
Reward: 0.11520833333332803
backprop <src.mcts.MCTS_Node object at 0x7f81800f1208> 0.11520833333332803 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d860> 0.11520833333332803 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.11520833333332803 2
Completed Iteration #0
Best Reward: 0.11520833333332803
Reward: 0.05916666666666259
backprop <src.mcts.MCTS_Node object at 0x7f81821c2550> 0.05916666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.05916666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.17437499999999062 3
Completed Iteration #1
Best Reward: 0.11520833333332803
Reward: 0.0625
backprop <src.mcts.MCTS_Node object at 0x7f81800fbac8> 0.0625 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.12166666666666259 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.23687499999999062 4
Completed Iteration #2
Best Reward: 0.11520833333332803
Reward: 0.10062499999999375
backprop <src.mcts.MCTS_Node object at 0x7f81821c2be0> 0.10062499999999375 2
backprop <src.mcts.MCTS_Node object at 0x7f818013bf28> 0.10062499999999375 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.33749999999998437 5
Completed Iteration #3
Best Reward: 0.11520833333332803
Reward: 0.09312500000000057
backprop <src.mcts.MCTS_Node object at 0x7f8182095978> 0.09312500000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d860> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.43062499999998494 6
Completed Iteration #4
Best Reward: 0.11520833333332803
Reward: 0.07208333333333172
backprop <src.mcts.MCTS_Node object at 0x7f8182095b00> 0.07208333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f81820957b8> 0.07208333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.5027083333333167 7
Completed Iteration #5
Best Reward: 0.11520833333332803
Reward: 0.05999999999999517
backprop <src.mcts.MCTS_Node object at 0x7f8182190ba8> 0.05999999999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.18166666666665776 4
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.5627083333333118 8
Completed Iteration #6
Best Reward: 0.11520833333332803
Completed Iteration #7
Best Reward: 0.11520833333332803
Reward: 0.10374999999999801
backprop <src.mcts.MCTS_Node object at 0x7f8182123630> 0.10374999999999801 2
backprop <src.mcts.MCTS_Node object at 0x7f81821234e0> 0.10374999999999801 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.6664583333333098 9
Completed Iteration #8
Best Reward: 0.11520833333332803
Reward: 0.10333333333333172
backprop <src.mcts.MCTS_Node object at 0x7f81820e0b00> 0.10333333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f818013bf28> 0.20395833333332547 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.7697916666666416 10
Completed Iteration #9
Best Reward: 0.11520833333332803
Reward: 0.016874999999998863
backprop <src.mcts.MCTS_Node object at 0x7f8182190dd8> 0.016874999999998863 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0fd0> 0.016874999999998863 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.7866666666666404 11
Completed Iteration #10
Best Reward: 0.11520833333332803
Reward: 0.12166666666666259
backprop <src.mcts.MCTS_Node object at 0x7f8182095320> 0.12166666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123e10> 0.12166666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.908333333333303 12
Completed Iteration #11
Best Reward: 0.12166666666666259
Completed Iteration #12
Best Reward: 0.12166666666666259
Reward: 0.05291666666666117
backprop <src.mcts.MCTS_Node object at 0x7f81820a2208> 0.05291666666666117 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123e10> 0.17458333333332376 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 0.9612499999999642 13
Completed Iteration #13
Best Reward: 0.12166666666666259
Reward: 0.05999999999999517
backprop <src.mcts.MCTS_Node object at 0x7f81820a27f0> 0.05999999999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f8182123e10> 0.23458333333331893 4
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.0212499999999594 14
Completed Iteration #14
Best Reward: 0.12166666666666259
Reward: 0.11020833333333258
backprop <src.mcts.MCTS_Node object at 0x7f81820a29e8> 0.11020833333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f81820957b8> 0.1822916666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.131458333333292 15
Completed Iteration #15
Best Reward: 0.12166666666666259
Reward: 0.10645833333332888
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.10645833333332888 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.28812499999998664 5
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.2379166666666208 16
Completed Iteration #16
Best Reward: 0.12166666666666259
Reward: 0.08499999999999375
backprop <src.mcts.MCTS_Node object at 0x7f81820a2f98> 0.08499999999999375 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d860> 0.29333333333332234 4
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.3229166666666146 17
Completed Iteration #17
Best Reward: 0.12166666666666259
Completed Iteration #18
Best Reward: 0.12166666666666259
Reward: 0.10437499999999744
backprop <src.mcts.MCTS_Node object at 0x7f8182003160> 0.10437499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f81820e0da0> 0.10437499999999744 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.427291666666612 18
Completed Iteration #19
Best Reward: 0.12166666666666259
Reward: 0.08270833333332916
backprop <src.mcts.MCTS_Node object at 0x7f8182003470> 0.08270833333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d860> 0.3760416666666515 5
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.5099999999999412 19
Completed Iteration #20
Best Reward: 0.12166666666666259
Reward: 0.054999999999999716
backprop <src.mcts.MCTS_Node object at 0x7f8182003748> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f818217d470> 0.34312499999998636 6
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.5649999999999409 20
Completed Iteration #21
Best Reward: 0.12166666666666259
Completed Iteration #22
Best Reward: 0.12166666666666259
Completed Iteration #23
Best Reward: 0.12166666666666259
Reward: 0.08166666666666345
backprop <src.mcts.MCTS_Node object at 0x7f8182003cf8> 0.08166666666666345 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003a90> 0.08166666666666345 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190dd8> 0.09854166666666231 3
backprop <src.mcts.MCTS_Node object at 0x7f81820e0fd0> 0.09854166666666231 3
backprop <src.mcts.MCTS_Node object at 0x7f8182187f60> 1.6466666666666043 21
Completed Iteration #24
Best Reward: 0.12166666666666259
Completed Iteration #25
Best Reward: 0.12166666666666259
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12166666666666259
No reward increase. Abort.
iteration: 10
found coverage increase 0.12166666666666259
Current Total Coverage 39.05479166666667
Reward: 0.09395833333333314
backprop <src.mcts.MCTS_Node object at 0x7f8182003b38> 0.09395833333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b198> 0.09395833333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.09395833333333314 2
Completed Iteration #0
Best Reward: 0.09395833333333314
Completed Iteration #1
Best Reward: 0.09395833333333314
Completed Iteration #2
Best Reward: 0.09395833333333314
Reward: 0.09000000000000341
backprop <src.mcts.MCTS_Node object at 0x7f818200b780> 0.09000000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003c50> 0.09000000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.18395833333333655 3
Completed Iteration #3
Best Reward: 0.09395833333333314
Completed Iteration #4
Best Reward: 0.09395833333333314
Completed Iteration #5
Best Reward: 0.09395833333333314
Reward: 0.06645833333333684
backprop <src.mcts.MCTS_Node object at 0x7f81820030b8> 0.06645833333333684 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b390> 0.06645833333333684 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.2504166666666734 4
Completed Iteration #6
Best Reward: 0.09395833333333314
Reward: 0.054375000000000284
backprop <src.mcts.MCTS_Node object at 0x7f818013be48> 0.054375000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187400> 0.054375000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.3047916666666737 5
Completed Iteration #7
Best Reward: 0.09395833333333314
coverage_call_count 300
Reward: 0.09083333333333599
backprop <src.mcts.MCTS_Node object at 0x7f8182190470> 0.09083333333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2748> 0.09083333333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.39562500000000966 6
Completed Iteration #8
Best Reward: 0.09395833333333314
Completed Iteration #9
Best Reward: 0.09395833333333314
Completed Iteration #10
Best Reward: 0.09395833333333314
Completed Iteration #11
Best Reward: 0.09395833333333314
Completed Iteration #12
Best Reward: 0.09395833333333314
Reward: 0.08937500000000398
backprop <src.mcts.MCTS_Node object at 0x7f8182123748> 0.08937500000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b198> 0.18333333333333712 3
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.48500000000001364 7
Completed Iteration #13
Best Reward: 0.09395833333333314
Reward: 0.071041666666666
backprop <src.mcts.MCTS_Node object at 0x7f81800fb1d0> 0.071041666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b390> 0.13750000000000284 3
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.5560416666666796 8
Completed Iteration #14
Best Reward: 0.09395833333333314
Reward: 0.09812499999999602
backprop <src.mcts.MCTS_Node object at 0x7f81820a2668> 0.09812499999999602 2
backprop <src.mcts.MCTS_Node object at 0x7f818200bbe0> 0.09812499999999602 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.6541666666666757 9
Completed Iteration #15
Best Reward: 0.09812499999999602
Reward: 0.07583333333333542
backprop <src.mcts.MCTS_Node object at 0x7f81820a2d30> 0.07583333333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003c50> 0.16583333333333883 3
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.7300000000000111 10
Completed Iteration #16
Best Reward: 0.09812499999999602
Reward: 0.10708333333333542
backprop <src.mcts.MCTS_Node object at 0x7f81820031d0> 0.10708333333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003c50> 0.27291666666667425 4
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.8370833333333465 11
Completed Iteration #17
Best Reward: 0.10708333333333542
Reward: 0.09124999999999517
backprop <src.mcts.MCTS_Node object at 0x7f81820037b8> 0.09124999999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2748> 0.18208333333333115 3
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 0.9283333333333417 12
Completed Iteration #18
Best Reward: 0.10708333333333542
Completed Iteration #19
Best Reward: 0.10708333333333542
Completed Iteration #20
Best Reward: 0.10708333333333542
Completed Iteration #21
Best Reward: 0.10708333333333542
Completed Iteration #22
Best Reward: 0.10708333333333542
Reward: 0.0885416666666714
backprop <src.mcts.MCTS_Node object at 0x7f8182095b00> 0.0885416666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2748> 0.27062500000000256 4
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 1.016875000000013 13
Completed Iteration #23
Best Reward: 0.10708333333333542
Completed Iteration #24
Best Reward: 0.10708333333333542
Reward: 0.035000000000003695
backprop <src.mcts.MCTS_Node object at 0x7f81820039b0> 0.035000000000003695 2
backprop <src.mcts.MCTS_Node object at 0x7f81820036d8> 0.035000000000003695 2
backprop <src.mcts.MCTS_Node object at 0x7f818200b320> 1.0518750000000168 14
Completed Iteration #25
Best Reward: 0.10708333333333542
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10708333333333542
No reward increase. Abort.
iteration: 11
found coverage increase 0.10708333333333542
Current Total Coverage 39.161875
Reward: 0.10187499999999261
backprop <src.mcts.MCTS_Node object at 0x7f827739e9b0> 0.10187499999999261 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2f98> 0.10187499999999261 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.10187499999999261 2
Completed Iteration #0
Best Reward: 0.10187499999999261
Completed Iteration #1
Best Reward: 0.10187499999999261
Reward: 0.11895833333333172
backprop <src.mcts.MCTS_Node object at 0x7f8182003f60> 0.11895833333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f81820037b8> 0.11895833333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.22083333333332433 3
Completed Iteration #2
Best Reward: 0.11895833333333172
Reward: 0.10708333333332831
backprop <src.mcts.MCTS_Node object at 0x7f8182003080> 0.10708333333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003390> 0.10708333333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.32791666666665265 4
Completed Iteration #3
Best Reward: 0.11895833333333172
Reward: 0.10874999999999346
backprop <src.mcts.MCTS_Node object at 0x7f81820a21d0> 0.10874999999999346 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.10874999999999346 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.4366666666666461 5
Completed Iteration #4
Best Reward: 0.11895833333333172
Reward: 0.0293749999999946
backprop <src.mcts.MCTS_Node object at 0x7f81820a2470> 0.0293749999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.13812499999998806 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.4660416666666407 6
Completed Iteration #5
Best Reward: 0.11895833333333172
Completed Iteration #6
Best Reward: 0.11895833333333172
Reward: 0.05833333333333002
backprop <src.mcts.MCTS_Node object at 0x7f81820957b8> 0.05833333333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2f98> 0.16020833333332263 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.5243749999999707 7
Completed Iteration #7
Best Reward: 0.11895833333333172
Reward: 0.057708333333330586
backprop <src.mcts.MCTS_Node object at 0x7f8182095470> 0.057708333333330586 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2f98> 0.2179166666666532 4
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.5820833333333013 8
Completed Iteration #8
Best Reward: 0.11895833333333172
Reward: 0.029166666666661456
backprop <src.mcts.MCTS_Node object at 0x7f8182095048> 0.029166666666661456 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.16729166666664952 4
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.6112499999999628 9
Completed Iteration #9
Best Reward: 0.11895833333333172
Completed Iteration #10
Best Reward: 0.11895833333333172
Reward: 0.03624999999999545
backprop <src.mcts.MCTS_Node object at 0x7f81820a2908> 0.03624999999999545 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.20354166666664497 5
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.6474999999999582 10
Completed Iteration #11
Best Reward: 0.11895833333333172
Reward: 0.11166666666666458
backprop <src.mcts.MCTS_Node object at 0x7f818210d2b0> 0.11166666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.31520833333330955 6
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.7591666666666228 11
Completed Iteration #12
Best Reward: 0.11895833333333172
Completed Iteration #13
Best Reward: 0.11895833333333172
Completed Iteration #14
Best Reward: 0.11895833333333172
Reward: 0.032083333333332575
backprop <src.mcts.MCTS_Node object at 0x7f818210d710> 0.032083333333332575 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.34729166666664213 7
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.7912499999999554 12
Completed Iteration #15
Best Reward: 0.11895833333333172
Reward: 0.06083333333333485
backprop <src.mcts.MCTS_Node object at 0x7f818210d4a8> 0.06083333333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f818210d208> 0.06083333333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.8520833333332902 13
Completed Iteration #16
Best Reward: 0.11895833333333172
Reward: 0.11354166666666288
backprop <src.mcts.MCTS_Node object at 0x7f818017fc88> 0.11354166666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2c88> 0.460833333333305 8
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 0.9656249999999531 14
Completed Iteration #17
Best Reward: 0.11895833333333172
Completed Iteration #18
Best Reward: 0.11895833333333172
Completed Iteration #19
Best Reward: 0.11895833333333172
Reward: 0.0918749999999946
backprop <src.mcts.MCTS_Node object at 0x7f8182003c50> 0.0918749999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003390> 0.1989583333333229 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 1.0574999999999477 15
Completed Iteration #20
Best Reward: 0.11895833333333172
Reward: 0.05833333333333002
backprop <src.mcts.MCTS_Node object at 0x7f8182095f60> 0.05833333333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f81820037f0> 0.05833333333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 1.1158333333332777 16
Completed Iteration #21
Best Reward: 0.11895833333333172
Completed Iteration #22
Best Reward: 0.11895833333333172
Reward: 0.09416666666666629
backprop <src.mcts.MCTS_Node object at 0x7f8182095a20> 0.09416666666666629 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003208> 0.09416666666666629 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 1.209999999999944 17
Completed Iteration #23
Best Reward: 0.11895833333333172
Completed Iteration #24
Best Reward: 0.11895833333333172
Reward: 0.07687500000000114
backprop <src.mcts.MCTS_Node object at 0x7f81820a2208> 0.07687500000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f81820037b8> 0.19583333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cc0> 1.2868749999999451 18
Completed Iteration #25
Best Reward: 0.11895833333333172
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11895833333333172
No reward increase. Abort.
iteration: 12
found coverage increase 0.11895833333333172
Current Total Coverage 39.280833333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.06812500000000199
backprop <src.mcts.MCTS_Node object at 0x7f818210d240> 0.06812500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f81820958d0> 0.06812500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.06812500000000199 2
Completed Iteration #2
Best Reward: 0.06812500000000199
Reward: 0.08291666666666231
backprop <src.mcts.MCTS_Node object at 0x7f818210d4e0> 0.08291666666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f818210dda0> 0.08291666666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.1510416666666643 3
Completed Iteration #3
Best Reward: 0.08291666666666231
Completed Iteration #4
Best Reward: 0.08291666666666231
Completed Iteration #5
Best Reward: 0.08291666666666231
Reward: 0.05354166666666771
backprop <src.mcts.MCTS_Node object at 0x7f818017f978> 0.05354166666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f818210def0> 0.05354166666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.204583333333332 4
Completed Iteration #6
Best Reward: 0.08291666666666231
Reward: 0.048749999999998295
backprop <src.mcts.MCTS_Node object at 0x7f81821905c0> 0.048749999999998295 2
backprop <src.mcts.MCTS_Node object at 0x7f818210def0> 0.102291666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.2533333333333303 5
Completed Iteration #7
Best Reward: 0.08291666666666231
Reward: 0.041458333333331154
backprop <src.mcts.MCTS_Node object at 0x7f8182190ac8> 0.041458333333331154 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190b00> 0.041458333333331154 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.29479166666666146 6
Completed Iteration #8
Best Reward: 0.08291666666666231
Reward: 0.06791666666666174
backprop <src.mcts.MCTS_Node object at 0x7f8182190160> 0.06791666666666174 2
backprop <src.mcts.MCTS_Node object at 0x7f81820958d0> 0.13604166666666373 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.3627083333333232 7
Completed Iteration #9
Best Reward: 0.08291666666666231
Reward: 0.06687499999999602
backprop <src.mcts.MCTS_Node object at 0x7f8182190320> 0.06687499999999602 2
backprop <src.mcts.MCTS_Node object at 0x7f81820958d0> 0.20291666666665975 4
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.4295833333333192 8
Completed Iteration #10
Best Reward: 0.08291666666666231
Reward: 0.09645833333333087
backprop <src.mcts.MCTS_Node object at 0x7f81821877f0> 0.09645833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f821c150470> 0.09645833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.5260416666666501 9
Completed Iteration #11
Best Reward: 0.09645833333333087
Reward: 0.10104166666666714
backprop <src.mcts.MCTS_Node object at 0x7f8182187400> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187518> 0.10104166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.6270833333333172 10
Completed Iteration #12
Best Reward: 0.10104166666666714
Reward: 0.1131250000000037
backprop <src.mcts.MCTS_Node object at 0x7f81821902b0> 0.1131250000000037 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187518> 0.21416666666667084 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.7402083333333209 11
Completed Iteration #13
Best Reward: 0.1131250000000037
Reward: 0.06583333333333741
backprop <src.mcts.MCTS_Node object at 0x7f818210d7b8> 0.06583333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f81820958d0> 0.26874999999999716 5
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.8060416666666583 12
Completed Iteration #14
Best Reward: 0.1131250000000037
Reward: 0.05458333333333343
backprop <src.mcts.MCTS_Node object at 0x7f8182187cf8> 0.05458333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f818210def0> 0.15687499999999943 4
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.8606249999999918 13
Completed Iteration #15
Best Reward: 0.1131250000000037
Completed Iteration #16
Best Reward: 0.1131250000000037
Completed Iteration #17
Best Reward: 0.1131250000000037
Reward: 0.06104166666666799
backprop <src.mcts.MCTS_Node object at 0x7f81821c2b00> 0.06104166666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d7f0> 0.06104166666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 0.9216666666666598 14
Completed Iteration #18
Best Reward: 0.1131250000000037
Completed Iteration #19
Best Reward: 0.1131250000000037
Reward: 0.09916666666666174
backprop <src.mcts.MCTS_Node object at 0x7f818017fc50> 0.09916666666666174 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cf8> 0.09916666666666174 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 1.0208333333333215 15
Completed Iteration #20
Best Reward: 0.1131250000000037
Reward: 0.10020833333333456
backprop <src.mcts.MCTS_Node object at 0x7f81821c2550> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a28d0> 0.10020833333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 1.121041666666656 16
Completed Iteration #21
Best Reward: 0.1131250000000037
Reward: 0.10270833333333229
backprop <src.mcts.MCTS_Node object at 0x7f81821c2898> 0.10270833333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a28d0> 0.20291666666666686 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 1.2237499999999883 17
Completed Iteration #22
Best Reward: 0.1131250000000037
Reward: 0.10062500000000085
backprop <src.mcts.MCTS_Node object at 0x7f81821c2128> 0.10062500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187518> 0.3147916666666717 4
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 1.3243749999999892 18
Completed Iteration #23
Best Reward: 0.1131250000000037
Reward: 0.09687499999999716
backprop <src.mcts.MCTS_Node object at 0x7f818012eda0> 0.09687499999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2cf8> 0.1960416666666589 3
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 1.4212499999999864 19
Completed Iteration #24
Best Reward: 0.1131250000000037
Reward: 0.09437499999999943
backprop <src.mcts.MCTS_Node object at 0x7f818012eb70> 0.09437499999999943 2
backprop <src.mcts.MCTS_Node object at 0x7f8182187518> 0.4091666666666711 5
backprop <src.mcts.MCTS_Node object at 0x7f81820a23c8> 1.5156249999999858 20
Completed Iteration #25
Best Reward: 0.1131250000000037
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1131250000000037
No reward increase. Abort.
iteration: 13
found coverage increase 0.1131250000000037
Current Total Coverage 39.39395833333334
Reward: 0.04708333333332604
backprop <src.mcts.MCTS_Node object at 0x7f8182003e10> 0.04708333333332604 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ba8> 0.04708333333332604 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.04708333333332604 2
Completed Iteration #0
Best Reward: 0.04708333333332604
Reward: 0.09979166666666117
backprop <src.mcts.MCTS_Node object at 0x7f81820a2a90> 0.09979166666666117 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a20f0> 0.09979166666666117 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.1468749999999872 3
Completed Iteration #1
Best Reward: 0.09979166666666117
Reward: 0.045208333333327744
backprop <src.mcts.MCTS_Node object at 0x7f81820959e8> 0.045208333333327744 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ba8> 0.09229166666665378 3
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.19208333333331495 4
Completed Iteration #2
Best Reward: 0.09979166666666117
Reward: 0.07729166666666742
backprop <src.mcts.MCTS_Node object at 0x7f8182190518> 0.07729166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190ba8> 0.07729166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.2693749999999824 5
Completed Iteration #3
Best Reward: 0.09979166666666117
Reward: 0.10249999999999915
backprop <src.mcts.MCTS_Node object at 0x7f8182190be0> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f81821908d0> 0.10249999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.3718749999999815 6
Completed Iteration #4
Best Reward: 0.10249999999999915
Reward: 0.05937499999999574
backprop <src.mcts.MCTS_Node object at 0x7f818210dc50> 0.05937499999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f818210df28> 0.05937499999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.43124999999997726 7
Completed Iteration #5
Best Reward: 0.10249999999999915
Reward: 0.09791666666666288
backprop <src.mcts.MCTS_Node object at 0x7f81821909b0> 0.09791666666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190ba8> 0.1752083333333303 3
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.5291666666666401 8
Completed Iteration #6
Best Reward: 0.10249999999999915
Reward: 0.1089583333333266
backprop <src.mcts.MCTS_Node object at 0x7f8182190160> 0.1089583333333266 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190ba8> 0.2841666666666569 4
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.6381249999999667 9
Completed Iteration #7
Best Reward: 0.1089583333333266
Completed Iteration #8
Best Reward: 0.1089583333333266
Reward: 0.10458333333333059
backprop <src.mcts.MCTS_Node object at 0x7f8182003438> 0.10458333333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f818017ff60> 0.10458333333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.7427083333332973 10
Completed Iteration #9
Best Reward: 0.1089583333333266
Completed Iteration #10
Best Reward: 0.1089583333333266
Completed Iteration #11
Best Reward: 0.1089583333333266
Reward: 0.1127083333333303
backprop <src.mcts.MCTS_Node object at 0x7f81f815dba8> 0.1127083333333303 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ba8> 0.20499999999998408 4
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.8554166666666276 11
Completed Iteration #12
Best Reward: 0.1127083333333303
Reward: 0.06624999999999659
backprop <src.mcts.MCTS_Node object at 0x7f81820a2400> 0.06624999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d860> 0.06624999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 0.9216666666666242 12
Completed Iteration #13
Best Reward: 0.1127083333333303
Completed Iteration #14
Best Reward: 0.1127083333333303
Reward: 0.11041666666666572
backprop <src.mcts.MCTS_Node object at 0x7f8182187ef0> 0.11041666666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ba8> 0.3154166666666498 5
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.03208333333329 13
Completed Iteration #15
Best Reward: 0.1127083333333303
Completed Iteration #16
Best Reward: 0.1127083333333303
Reward: 0.07708333333332718
backprop <src.mcts.MCTS_Node object at 0x7f8182187630> 0.07708333333332718 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190ba8> 0.3612499999999841 5
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.1091666666666171 14
Completed Iteration #17
Best Reward: 0.1127083333333303
Reward: 0.09687499999999005
backprop <src.mcts.MCTS_Node object at 0x7f81821c2128> 0.09687499999999005 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a20f0> 0.19666666666665122 3
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.2060416666666072 15
Completed Iteration #18
Best Reward: 0.1127083333333303
Reward: 0.10854166666666742
backprop <src.mcts.MCTS_Node object at 0x7f81821c24e0> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ba8> 0.4239583333333172 6
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.3145833333332746 16
Completed Iteration #19
Best Reward: 0.1127083333333303
Reward: 0.042083333333330586
backprop <src.mcts.MCTS_Node object at 0x7f81821c2358> 0.042083333333330586 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ba8> 0.4660416666666478 7
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.3566666666666052 17
Completed Iteration #20
Best Reward: 0.1127083333333303
Reward: 0.08395833333332803
backprop <src.mcts.MCTS_Node object at 0x7f81821c2828> 0.08395833333332803 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2ac8> 0.08395833333332803 2
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.4406249999999332 18
Completed Iteration #21
Best Reward: 0.1127083333333303
Reward: 0.07958333333333201
backprop <src.mcts.MCTS_Node object at 0x7f8182187b00> 0.07958333333333201 2
backprop <src.mcts.MCTS_Node object at 0x7f81820a2ac8> 0.16354166666666003 3
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.5202083333332652 19
Completed Iteration #22
Best Reward: 0.1127083333333303
Reward: 0.10354166666666487
backprop <src.mcts.MCTS_Node object at 0x7f818012e748> 0.10354166666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f818017ff60> 0.20812499999999545 3
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.62374999999993 20
Completed Iteration #23
Best Reward: 0.1127083333333303
Completed Iteration #24
Best Reward: 0.1127083333333303
Reward: 0.1089583333333266
backprop <src.mcts.MCTS_Node object at 0x7f818012ee10> 0.1089583333333266 2
backprop <src.mcts.MCTS_Node object at 0x7f8182190ba8> 0.4702083333333107 6
backprop <src.mcts.MCTS_Node object at 0x7f8182003ef0> 1.7327083333332567 21
Completed Iteration #25
Best Reward: 0.1127083333333303
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1127083333333303
No reward increase. Abort.
iteration: 14
found coverage increase 0.1127083333333303
Current Total Coverage 39.50666666666667
Reward: 0.07229166666666487
backprop <src.mcts.MCTS_Node object at 0x7f818012e908> 0.07229166666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb240> 0.07229166666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.07229166666666487 2
Completed Iteration #0
Best Reward: 0.07229166666666487
coverage_call_count 400
Reward: 0.058749999999996305
backprop <src.mcts.MCTS_Node object at 0x7f81800fbcf8> 0.058749999999996305 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c2898> 0.058749999999996305 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.13104166666666117 3
Completed Iteration #1
Best Reward: 0.07229166666666487
Reward: 0.09645833333333087
backprop <src.mcts.MCTS_Node object at 0x7f81800fb5f8> 0.09645833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fbdd8> 0.09645833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.22749999999999204 4
Completed Iteration #2
Best Reward: 0.09645833333333087
Completed Iteration #3
Best Reward: 0.09645833333333087
Reward: 0.09416666666666629
backprop <src.mcts.MCTS_Node object at 0x7f81800f1b38> 0.09416666666666629 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb240> 0.16645833333333115 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.32166666666665833 5
Completed Iteration #4
Best Reward: 0.09645833333333087
Reward: 0.09874999999999545
backprop <src.mcts.MCTS_Node object at 0x7f8182003d30> 0.09874999999999545 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb7f0> 0.09874999999999545 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.4204166666666538 6
Completed Iteration #5
Best Reward: 0.09874999999999545
Reward: 0.04958333333333087
backprop <src.mcts.MCTS_Node object at 0x7f81820a2048> 0.04958333333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d7f0> 0.04958333333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.46999999999998465 7
Completed Iteration #6
Best Reward: 0.09874999999999545
Reward: 0.07499999999999574
backprop <src.mcts.MCTS_Node object at 0x7f8182095d30> 0.07499999999999574 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb240> 0.2414583333333269 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.5449999999999804 8
Completed Iteration #7
Best Reward: 0.09874999999999545
Reward: 0.1060416666666697
backprop <src.mcts.MCTS_Node object at 0x7f818017fc18> 0.1060416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095518> 0.1060416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.6510416666666501 9
Completed Iteration #8
Best Reward: 0.1060416666666697
Completed Iteration #9
Best Reward: 0.1060416666666697
Reward: 0.10145833333333343
backprop <src.mcts.MCTS_Node object at 0x7f8182190978> 0.10145833333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fbdd8> 0.1979166666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.7524999999999835 10
Completed Iteration #10
Best Reward: 0.1060416666666697
Completed Iteration #11
Best Reward: 0.1060416666666697
Completed Iteration #12
Best Reward: 0.1060416666666697
Reward: 0.07124999999999915
backprop <src.mcts.MCTS_Node object at 0x7f818210d390> 0.07124999999999915 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb240> 0.31270833333332604 5
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.8237499999999827 11
Completed Iteration #13
Best Reward: 0.1060416666666697
Reward: 0.031041666666666856
backprop <src.mcts.MCTS_Node object at 0x7f818012ee48> 0.031041666666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e3c8> 0.031041666666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.8547916666666495 12
Completed Iteration #14
Best Reward: 0.1060416666666697
Reward: 0.03541666666666288
backprop <src.mcts.MCTS_Node object at 0x7f818012e9b0> 0.03541666666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e3c8> 0.06645833333332973 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.8902083333333124 13
Completed Iteration #15
Best Reward: 0.1060416666666697
Completed Iteration #16
Best Reward: 0.1060416666666697
Reward: 0.10312499999999858
backprop <src.mcts.MCTS_Node object at 0x7f8182187d30> 0.10312499999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d7f0> 0.15270833333332945 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 0.993333333333311 14
Completed Iteration #17
Best Reward: 0.1060416666666697
Completed Iteration #18
Best Reward: 0.1060416666666697
Reward: 0.09624999999999773
backprop <src.mcts.MCTS_Node object at 0x7f81800fb438> 0.09624999999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f8182095518> 0.20229166666666742 3
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 1.0895833333333087 15
Completed Iteration #19
Best Reward: 0.1060416666666697
Completed Iteration #20
Best Reward: 0.1060416666666697
Reward: 0.09291666666666742
backprop <src.mcts.MCTS_Node object at 0x7f81800f1c88> 0.09291666666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f81f815d7f0> 0.24562499999999687 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 1.1824999999999761 16
Completed Iteration #21
Best Reward: 0.1060416666666697
Completed Iteration #22
Best Reward: 0.1060416666666697
Completed Iteration #23
Best Reward: 0.1060416666666697
Reward: 0.07395833333333712
backprop <src.mcts.MCTS_Node object at 0x7f81800fbda0> 0.07395833333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f81821c20f0> 0.07395833333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 1.2564583333333132 17
Completed Iteration #24
Best Reward: 0.1060416666666697
Reward: 0.0345833333333303
backprop <src.mcts.MCTS_Node object at 0x7f81800f1e80> 0.0345833333333303 2
backprop <src.mcts.MCTS_Node object at 0x7f818012e3c8> 0.10104166666666003 4
backprop <src.mcts.MCTS_Node object at 0x7f81800fb080> 1.2910416666666436 18
Completed Iteration #25
Best Reward: 0.1060416666666697
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1060416666666697
No reward increase. Abort.
iteration: 15
found coverage increase 0.1060416666666697
Current Total Coverage 39.61270833333334
initial coverage: 37.786
time passed (minutes): 14.0408
iterations: 16
number of new inputs: 1024
final coverage: 39.6127
total coverage increase: 1.82667
