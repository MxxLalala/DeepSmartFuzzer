Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fe8359a3f28>, tc2=<function tc2 at 0x7fe8359b4048>, tc3=<function tc3 at 0x7fe8359b4158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 25.625
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.10416666666666785 15
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.10416666666666785 16
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.10416666666666785 17
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.10416666666666785 18
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.10416666666666785 19
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.10416666666666785 20
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.2083333333333357 21
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.2083333333333357 22
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.2083333333333357 23
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.2083333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.2083333333333357 24
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.31250000000000355 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.31250000000000355 25
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.31250000000000355 26
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.31250000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.31250000000000355 27
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.31250000000000355 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.31250000000000355 28
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.4166666666666714 29
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.4166666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.4166666666666714 30
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.4166666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.4166666666666714 31
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.5208333333333393 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.5208333333333393 32
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157d30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81657b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165828> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.6250000000000071 33
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81659e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.729166666666675 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.729166666666675 34
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.729166666666675 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.729166666666675 35
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b6d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.8333333333333428 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.8333333333333428 36
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165d30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.9375000000000107 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.9375000000000107 37
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b2e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.0416666666666785 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.0416666666666785 38
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.1458333333333464 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.1458333333333464 39
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.2500000000000142 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.2500000000000142 40
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ebe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e9e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b2e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.354166666666682 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.354166666666682 41
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.2500000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.354166666666682 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.354166666666682 42
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.2500000000000142 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.354166666666682 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.354166666666682 43
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c817edd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652b0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.354166666666682 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.45833333333335 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.45833333333335 44
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652b0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.45833333333335 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.5625000000000178 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.5625000000000178 45
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.5625000000000178 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.6666666666666856 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.6666666666666856 46
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->5->19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.6666666666666856 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.7708333333333535 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.7708333333333535 47
Completed Iteration #0
Best Reward: 0.10416666666666785
coverage_call_count 100
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.7708333333333535 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.8750000000000213 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.8750000000000213 48
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ecf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.8750000000000213 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 1.9791666666666892 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 1.9791666666666892 49
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e7b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 1.9791666666666892 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.083333333333357 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.083333333333357 50
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5d30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.083333333333357 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.187500000000025 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.187500000000025 51
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.187500000000025 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.2916666666666927 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.2916666666666927 52
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.2916666666666927 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.3958333333333606 36
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.3958333333333606 53
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107da0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5d30> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.3958333333333606 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.5000000000000284 37
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.5000000000000284 54
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107d30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.5000000000000284 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.6041666666666963 38
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.6041666666666963 55
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e860> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.5000000000000284 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.6041666666666963 39
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.6041666666666963 56
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->5->19->3
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a6d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.6041666666666963 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.708333333333364 40
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.708333333333364 57
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812ab70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a8d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.708333333333364 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.812500000000032 41
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.812500000000032 58
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 2.812500000000032 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 2.9166666666667 42
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 2.9166666666667 59
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.3125000000000071
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.3125000000000071 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 0.3125000000000071 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.41666666666667496 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.41666666666667496 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.9375000000000142 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.1875000000000284 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.125000000000039 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.229166666666707 43
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.229166666666707 60
Completed Iteration #5
Best Reward: 0.3125000000000071
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a8d0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.9375000000000142 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.1875000000000284 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.125000000000039 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.229166666666707 44
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.229166666666707 61
Completed Iteration #6
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e3c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.5208333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.041666666666682 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.2916666666666963 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.229166666666707 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.333333333333375 45
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.333333333333375 62
Completed Iteration #7
Best Reward: 0.3125000000000071
Completed Iteration #8
Best Reward: 0.3125000000000071
Completed Iteration #9
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81079b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.6250000000000107 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.14583333333335 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.395833333333364 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.333333333333375 36
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.4375000000000426 46
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.4375000000000426 63
Completed Iteration #10
Best Reward: 0.3125000000000071
Completed Iteration #11
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107cf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f898> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.2500000000000178 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.500000000000032 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.4375000000000426 37
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.5416666666667105 47
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.5416666666667105 64
Completed Iteration #12
Best Reward: 0.3125000000000071
Completed Iteration #13
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107978> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.3541666666666856 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.6041666666667 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.5416666666667105 38
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.6458333333333783 48
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.6458333333333783 65
Completed Iteration #14
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a0f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a6d8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.4583333333333535 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.7083333333333677 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.6458333333333783 39
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.750000000000046 49
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.750000000000046 66
Completed Iteration #15
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fc18> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.7291666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.5625000000000213 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.8125000000000355 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.750000000000046 40
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.854166666666714 50
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.854166666666714 67
Completed Iteration #16
Best Reward: 0.3125000000000071
Completed Iteration #17
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107978> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.6666666666666892 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 2.9166666666667034 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.854166666666714 41
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 3.958333333333382 51
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 3.958333333333382 68
Completed Iteration #18
Best Reward: 0.3125000000000071
Completed Iteration #19
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a6a0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.770833333333357 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.0208333333333712 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 3.958333333333382 42
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.06250000000005 52
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.06250000000005 69
Completed Iteration #20
Best Reward: 0.3125000000000071
Completed Iteration #21
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7a90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7b00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.8750000000000249 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.125000000000039 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.06250000000005 43
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.166666666666718 53
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.166666666666718 70
Completed Iteration #22
Best Reward: 0.3125000000000071
Completed Iteration #23
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d42b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107978> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 1.9791666666666927 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.229166666666707 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.166666666666718 44
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.270833333333385 54
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.270833333333385 71
Completed Iteration #24
Best Reward: 0.3125000000000071
Completed Iteration #25
Best Reward: 0.3125000000000071
Completed MCTS Level/Depth: #4
root->5->19->3->19
Best Reward: 0.3125000000000071
Completed Iteration #0
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.8333333333333464 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.0833333333333606 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.333333333333375 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.270833333333385 45
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.375000000000053 55
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.375000000000053 72
Completed Iteration #1
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107fd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e3c8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.9375000000000142 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.1875000000000284 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.4375000000000426 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.375000000000053 46
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.479166666666721 56
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.479166666666721 73
Completed Iteration #2
Best Reward: 0.3125000000000071
Completed Iteration #3
Best Reward: 0.3125000000000071
Completed Iteration #4
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.041666666666682 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.2916666666666963 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.5416666666667105 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.479166666666721 47
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.583333333333389 57
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.583333333333389 74
Completed Iteration #5
Best Reward: 0.3125000000000071
Completed Iteration #6
Best Reward: 0.3125000000000071
Completed Iteration #7
Best Reward: 0.3125000000000071
Completed Iteration #8
Best Reward: 0.3125000000000071
Completed Iteration #9
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.14583333333335 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.395833333333364 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.6458333333333783 36
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.583333333333389 48
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.687500000000057 58
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.687500000000057 75
Completed Iteration #10
Best Reward: 0.3125000000000071
Completed Iteration #11
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c811feb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c77f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fc18> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.2500000000000178 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.500000000000032 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.750000000000046 37
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.687500000000057 49
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.791666666666725 59
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.791666666666725 76
Completed Iteration #12
Best Reward: 0.3125000000000071
Completed Iteration #13
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.5208333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.3541666666666856 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.6041666666667 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.854166666666714 38
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.791666666666725 50
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 4.8958333333333925 60
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 4.8958333333333925 77
Completed Iteration #14
Best Reward: 0.3125000000000071
Completed Iteration #15
Best Reward: 0.3125000000000071
Completed Iteration #16
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.4583333333333535 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.7083333333333677 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 3.958333333333382 39
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 4.8958333333333925 51
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.00000000000006 61
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.00000000000006 78
Completed Iteration #17
Best Reward: 0.3125000000000071
Completed Iteration #18
Best Reward: 0.3125000000000071
Completed Iteration #19
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c75f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7710> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.5625000000000213 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.8125000000000355 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.06250000000005 40
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.00000000000006 52
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.104166666666728 62
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.104166666666728 79
Completed Iteration #20
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81658d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81079b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.6666666666666892 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 2.9166666666667034 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.166666666666718 41
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.104166666666728 53
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.208333333333396 63
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.208333333333396 80
Completed Iteration #21
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e208> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e3c8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.770833333333357 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.0208333333333712 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.270833333333385 42
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.208333333333396 54
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.312500000000064 64
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.312500000000064 81
Completed Iteration #22
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edcc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.8750000000000249 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.125000000000039 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.375000000000053 43
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.312500000000064 55
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.416666666666732 65
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.416666666666732 82
Completed Iteration #23
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44a8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81079b0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 1.9791666666666927 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.229166666666707 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.479166666666721 44
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.416666666666732 56
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.5208333333334 66
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.5208333333334 83
Completed Iteration #24
Best Reward: 0.3125000000000071
Completed Iteration #25
Best Reward: 0.3125000000000071
Completed MCTS Level/Depth: #5
root->5->19->3->19->6
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4358> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.6250000000000107 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 2.0833333333333606 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.333333333333375 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.583333333333389 45
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.5208333333334 57
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.6250000000000675 67
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.6250000000000675 84
Completed Iteration #0
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c76d8> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 0.5208333333333464 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.8333333333333499 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 2.2916666666667 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.541666666666714 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 4.791666666666728 46
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.729166666666739 58
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 5.833333333333407 68
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 5.833333333333407 85
Completed Iteration #1
Best Reward: 0.3125000000000071
Completed Iteration #2
Best Reward: 0.3125000000000071
Completed Iteration #3
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c81659b0> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f240> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.5208333333333464 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 0.7291666666666856 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 1.0416666666666892 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 2.500000000000039 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.7500000000000533 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 5.0000000000000675 47
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 5.937500000000078 59
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 6.041666666666746 69
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 6.041666666666746 86
Completed Iteration #4
Best Reward: 0.3125000000000071
Completed Iteration #5
Best Reward: 0.3125000000000071
Completed Iteration #6
Best Reward: 0.3125000000000071
Completed Iteration #7
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed940> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 0.9375000000000249 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 1.2500000000000284 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 2.7083333333333783 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 3.9583333333333925 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 5.208333333333407 48
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 6.145833333333417 60
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 6.250000000000085 70
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 6.250000000000085 87
Completed Iteration #8
Best Reward: 0.3125000000000071
Completed Iteration #9
Best Reward: 0.3125000000000071
Completed Iteration #10
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80800b8> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed6d8> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81659b0> 0.4166666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f240> 0.4166666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.7291666666666856 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 1.1458333333333641 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 1.4583333333333677 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 2.9166666666667176 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 4.166666666666732 36
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 5.416666666666746 49
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 6.354166666666757 61
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 6.4583333333334245 71
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 6.4583333333334245 88
Completed Iteration #11
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080668> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80804a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 1.5625000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 3.0208333333333854 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 4.2708333333334 37
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 5.520833333333414 50
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 6.4583333333334245 62
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 6.562500000000092 72
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 6.562500000000092 89
Completed Iteration #12
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080a58> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4358> 0.41666666666667496 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 1.7708333333333748 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 3.2291666666667247 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 4.479166666666739 38
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 5.729166666666753 51
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 6.666666666666764 63
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 6.770833333333432 73
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 6.770833333333432 90
Completed Iteration #13
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e80> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 1.3541666666667034 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 1.979166666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 3.437500000000064 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 4.687500000000078 39
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 5.937500000000092 52
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 6.875000000000103 64
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 6.979166666666771 74
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 6.979166666666771 91
Completed Iteration #14
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7860> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157780> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e80> 0.4166666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 1.5625000000000426 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 2.1875000000000533 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 3.645833333333403 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 4.895833333333417 40
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 6.145833333333432 53
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 7.083333333333442 65
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 7.18750000000011 75
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 7.18750000000011 92
Completed Iteration #15
Best Reward: 0.3125000000000071
Completed Iteration #16
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4748> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d42e8> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080668> 0.3125000000000071 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80804a8> 0.3125000000000071 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 2.3958333333333925 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 3.8541666666667425 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 5.104166666666757 41
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 6.354166666666771 54
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 7.2916666666667815 66
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 7.395833333333449 76
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 7.395833333333449 93
Completed Iteration #17
Best Reward: 0.3125000000000071
Completed Iteration #18
Best Reward: 0.3125000000000071
Completed Iteration #19
Best Reward: 0.3125000000000071
Completed Iteration #20
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4358> 0.5208333333333428 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 2.5000000000000604 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 3.9583333333334103 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 5.2083333333334245 42
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 6.458333333333439 55
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 7.395833333333449 67
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 7.500000000000117 77
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 7.500000000000117 94
Completed Iteration #21
Best Reward: 0.3125000000000071
Completed Iteration #22
Best Reward: 0.3125000000000071
Completed Iteration #23
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080c18> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080c50> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.9375000000000249 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 1.7708333333333819 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 2.7083333333333997 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 4.16666666666675 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 5.416666666666764 43
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 6.666666666666778 56
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 7.604166666666789 68
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 7.7083333333334565 78
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 7.7083333333334565 95
Completed Iteration #24
Best Reward: 0.3125000000000071
Completed Iteration #25
Best Reward: 0.3125000000000071
Completed MCTS Level/Depth: #6
root->5->19->3->19->6->18
Best Reward: 0.3125000000000071
Completed Iteration #0
Best Reward: 0.3125000000000071
coverage_call_count 200
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090240> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 1.9791666666667211 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 2.916666666666739 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 4.375000000000089 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 5.625000000000103 44
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 6.875000000000117 57
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 7.812500000000128 69
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 7.916666666666796 79
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 7.916666666666796 96
Completed Iteration #1
Best Reward: 0.3125000000000071
Completed Iteration #2
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090908> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 2.1875000000000604 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 3.125000000000078 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 4.583333333333428 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 5.833333333333442 45
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 7.0833333333334565 58
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 8.020833333333467 70
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 8.125000000000135 80
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 8.125000000000135 97
Completed Iteration #3
Best Reward: 0.3125000000000071
Completed Iteration #4
Best Reward: 0.3125000000000071
Completed Iteration #5
Best Reward: 0.3125000000000071
Completed Iteration #6
Best Reward: 0.3125000000000071
Completed Iteration #7
Best Reward: 0.3125000000000071
Completed Iteration #8
Best Reward: 0.3125000000000071
Completed Iteration #9
Best Reward: 0.3125000000000071
Completed Iteration #10
Best Reward: 0.3125000000000071
Completed Iteration #11
Best Reward: 0.3125000000000071
Reward: 0.3125000000000071
backprop <src.mcts.MCTS_Node object at 0x7fe7c80989e8> 0.3125000000000071 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098a58> 0.3125000000000071 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed940> 0.5208333333333464 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 2.5000000000000675 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 3.4375000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 4.895833333333435 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 6.145833333333449 46
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 7.395833333333464 59
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 8.333333333333474 71
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 8.437500000000142 81
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 8.437500000000142 98
Completed Iteration #12
Best Reward: 0.3125000000000071
Completed Iteration #13
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 2.6041666666667354 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 3.541666666666753 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 5.000000000000103 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 6.250000000000117 47
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 7.5000000000001315 60
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 8.437500000000142 72
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 8.54166666666681 82
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 8.54166666666681 99
Completed Iteration #14
Best Reward: 0.3125000000000071
Completed Iteration #15
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80905f8> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80984e0> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090908> 0.4166666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 2.8125000000000746 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 3.7500000000000924 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 5.208333333333442 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 6.4583333333334565 48
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 7.708333333333471 61
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 8.645833333333481 73
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 8.75000000000015 83
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 8.75000000000015 100
Completed Iteration #16
Best Reward: 0.3125000000000071
Completed Iteration #17
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107278> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c88> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed940> 0.7291666666666856 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 3.020833333333414 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 3.9583333333334316 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 5.4166666666667815 36
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 6.666666666666796 49
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 7.91666666666681 62
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 8.85416666666682 74
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 8.958333333333488 84
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 8.958333333333488 101
Completed Iteration #18
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080cc0> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80809b0> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 1.1458333333333641 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 3.229166666666753 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 4.166666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 5.625000000000121 37
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 6.875000000000135 50
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 8.12500000000015 63
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 9.06250000000016 75
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 9.166666666666828 85
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 9.166666666666828 102
Completed Iteration #19
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ede80> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f240> 0.6250000000000178 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 1.3541666666667034 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 3.4375000000000924 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 4.37500000000011 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 5.83333333333346 38
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 7.083333333333474 51
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 8.333333333333488 64
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 9.2708333333335 76
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 9.375000000000167 86
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 9.375000000000167 103
Completed Iteration #20
Best Reward: 0.3125000000000071
Completed Iteration #21
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80903c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 3.54166666666676 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 4.479166666666778 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 5.937500000000128 39
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 7.187500000000142 52
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 8.437500000000156 65
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 9.375000000000167 77
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 9.479166666666835 87
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 9.479166666666835 104
Completed Iteration #22
Best Reward: 0.3125000000000071
Completed Iteration #23
Best Reward: 0.3125000000000071
Completed Iteration #24
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090ac8> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80809b0> 0.4166666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 1.5625000000000426 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 3.7500000000000995 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 4.687500000000117 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 6.145833333333467 40
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 7.395833333333481 53
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 8.645833333333496 66
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 9.583333333333506 78
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 9.687500000000174 88
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 9.687500000000174 105
Completed Iteration #25
Best Reward: 0.3125000000000071
Completed MCTS Level/Depth: #7
root->5->19->3->19->6->18->1
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 1.6666666666667105 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 3.8541666666667673 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 4.791666666666785 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 6.250000000000135 41
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 7.500000000000149 54
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 8.750000000000163 67
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 9.687500000000174 79
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 9.791666666666842 89
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 9.791666666666842 106
Completed Iteration #0
Best Reward: 0.3125000000000071
Completed Iteration #1
Best Reward: 0.3125000000000071
Completed Iteration #2
Best Reward: 0.3125000000000071
Completed Iteration #3
Best Reward: 0.3125000000000071
Reward: 0.3125000000000071
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6f60> 0.3125000000000071 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c88> 0.41666666666667496 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 1.9791666666667176 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 4.166666666666774 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 5.104166666666792 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 6.562500000000142 42
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 7.812500000000156 55
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 9.06250000000017 68
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 10.000000000000181 80
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 10.104166666666849 90
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 10.104166666666849 107
Completed Iteration #4
Best Reward: 0.3125000000000071
Completed Iteration #5
Best Reward: 0.3125000000000071
Completed Iteration #6
Best Reward: 0.3125000000000071
Completed Iteration #7
Best Reward: 0.3125000000000071
Completed Iteration #8
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c88> 0.6250000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 2.187500000000057 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 4.375000000000114 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 5.3125000000001315 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 6.770833333333481 43
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 8.020833333333496 56
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 9.27083333333351 69
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 10.20833333333352 81
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 10.312500000000188 91
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 10.312500000000188 108
Completed Iteration #9
Best Reward: 0.3125000000000071
Reward: 0.20833333333333925
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a828> 0.20833333333333925 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80809b0> 0.6250000000000178 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 2.395833333333396 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 4.583333333333453 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 5.520833333333471 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 6.979166666666821 44
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 8.229166666666835 57
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 9.479166666666849 70
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 10.41666666666686 82
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 10.520833333333528 92
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 10.520833333333528 109
Completed Iteration #10
Best Reward: 0.3125000000000071
Completed Iteration #11
Best Reward: 0.3125000000000071
Completed Iteration #12
Best Reward: 0.3125000000000071
Completed Iteration #13
Best Reward: 0.3125000000000071
Completed Iteration #14
Best Reward: 0.3125000000000071
Completed Iteration #15
Best Reward: 0.3125000000000071
Completed Iteration #16
Best Reward: 0.3125000000000071
Completed Iteration #17
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6278> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c88> 0.7291666666666821 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 2.500000000000064 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 4.687500000000121 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 5.6250000000001386 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 7.0833333333334885 45
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 8.333333333333503 58
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 9.583333333333517 71
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 10.520833333333528 83
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 10.625000000000195 93
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 10.625000000000195 110
Completed Iteration #18
Best Reward: 0.3125000000000071
Completed Iteration #19
Best Reward: 0.3125000000000071
Completed Iteration #20
Best Reward: 0.3125000000000071
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098c88> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6278> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c88> 0.8333333333333499 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 2.604166666666732 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 4.791666666666789 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 5.729166666666806 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 7.187500000000156 46
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 8.43750000000017 59
backprop <src.mcts.MCTS_Node object at 0x7fe7c81575f8> 9.687500000000185 72
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5668> 10.625000000000195 84
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 10.729166666666863 94
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 10.729166666666863 111
Completed Iteration #21
Best Reward: 0.3125000000000071
Completed Iteration #22
Best Reward: 0.3125000000000071
Completed Iteration #23
Best Reward: 0.3125000000000071
Completed Iteration #24
Best Reward: 0.3125000000000071
Completed Iteration #25
Best Reward: 0.3125000000000071
Completed MCTS Level/Depth: #8
root->5->19->3->19->6->18->1->11
Best Reward: 0.3125000000000071
iteration: 1
found coverage increase 0.3125000000000071
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80418d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80612b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80418d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80612b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80614e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901643c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901643c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901640b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901640b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901640b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6278> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80706a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79012de48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 500
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe79014ac88> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 10
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 11
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 12
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 13
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 14
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 15
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 16
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 17
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 18
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 19
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 20
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 21
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.1041666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.1041666666666643 22
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.2083333333333286 10
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.2083333333333286 23
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.2083333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.2083333333333286 24
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.2083333333333286 12
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.2083333333333286 25
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acb38> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.3124999999999929 13
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.3124999999999929 26
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4470> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 14
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 27
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 15
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 28
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 16
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 29
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 17
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 30
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 18
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 31
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 19
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 32
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.4166666666666572 20
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.4166666666666572 33
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79014a198> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010da90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcd30> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.5208333333333215 21
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.5208333333333215 34
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab00> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.6249999999999858 22
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.6249999999999858 35
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.6249999999999858 23
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.6249999999999858 36
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.7291666666666501 24
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.7291666666666501 37
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc978> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc3c8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.8333333333333144 25
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.8333333333333144 38
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc828> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba6a0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.9374999999999787 26
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.9374999999999787 39
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.9374999999999787 27
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.9374999999999787 40
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #2
root->2->5
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac470> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.041666666666643 28
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.041666666666643 41
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.1458333333333073 29
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.1458333333333073 42
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4b38> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.2499999999999716 30
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.2499999999999716 43
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79009be80> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.3541666666666359 31
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.3541666666666359 44
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79014a780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.4583333333333002 32
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.4583333333333002 45
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe790152d68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.5624999999999645 33
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.5624999999999645 46
Completed Iteration #17
Best Reward: 0.1041666666666643
coverage_call_count 600
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe790164390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 0.9374999999999787 10
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.2499999999999716 14
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.6666666666666288 34
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.6666666666666288 47
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe790164c88> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.041666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.3541666666666359 15
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.770833333333293 35
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.770833333333293 48
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.1458333333333073 12
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.4583333333333002 16
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.8749999999999574 36
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.8749999999999574 49
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #3
root->2->5->0
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fd30> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.2499999999999716 13
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.5624999999999645 17
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 1.9791666666666217 37
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 1.9791666666666217 50
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900acdd8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.3541666666666359 14
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.6666666666666288 18
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.083333333333286 38
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.083333333333286 51
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fd30> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.3541666666666359 15
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.6666666666666288 19
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.083333333333286 39
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.083333333333286 52
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79010d748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.4583333333333002 16
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.770833333333293 20
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.1874999999999503 40
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.1874999999999503 53
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #4
root->2->5->0->24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.5624999999999645 17
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.8749999999999574 21
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.2916666666666146 41
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.2916666666666146 54
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900fca20> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.6666666666666288 18
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 1.9791666666666217 22
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.395833333333279 42
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.395833333333279 55
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.770833333333293 19
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.083333333333286 23
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.499999999999943 43
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.499999999999943 56
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6128> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.8749999999999574 20
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.1874999999999503 24
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.6041666666666075 44
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.6041666666666075 57
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6940> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 1.9791666666666217 21
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.2916666666666146 25
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.7083333333332718 45
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.7083333333332718 58
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed080> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6e80> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.083333333333286 22
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.395833333333279 26
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.812499999999936 46
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.812499999999936 59
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.2499999999999716 14
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.1874999999999503 23
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.499999999999943 27
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.9166666666666003 47
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.9166666666666003 60
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.041666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.1874999999999503 24
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.499999999999943 28
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 2.9166666666666003 48
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 2.9166666666666003 61
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #5
root->2->5->0->24->2
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.3541666666666359 16
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.2916666666666146 25
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.6041666666666075 29
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.0208333333332646 49
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.0208333333332646 62
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6e80> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.2916666666666146 26
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.6041666666666075 30
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.0208333333332646 50
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.0208333333332646 63
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7b70> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.4583333333333002 18
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.395833333333279 27
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.7083333333332718 31
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.124999999999929 51
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.124999999999929 64
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.5624999999999645 19
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.499999999999943 28
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.812499999999936 32
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.2291666666665932 52
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.2291666666665932 65
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #6
root->2->5->0->24->2->5
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aa58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.4583333333333002 18
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.6666666666666288 20
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.6041666666666075 29
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 2.9166666666666003 33
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.3333333333332575 53
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.3333333333332575 66
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81079e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.5624999999999645 19
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.770833333333293 21
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.7083333333332718 30
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.0208333333332646 34
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.437499999999922 54
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.437499999999922 67
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4b70> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.6666666666666288 20
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.8749999999999574 22
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.812499999999936 31
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.124999999999929 35
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.541666666666586 55
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.541666666666586 68
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c80eda58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.770833333333293 21
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 1.9791666666666217 23
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 2.9166666666666003 32
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.2291666666665932 36
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.6458333333332504 56
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.6458333333332504 69
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
coverage_call_count 700
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.9374999999999787 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.8749999999999574 22
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 2.083333333333286 24
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 3.0208333333332646 33
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.3333333333332575 37
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.7499999999999147 57
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.7499999999999147 70
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #7
root->2->5->0->24->2->5->0
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.8749999999999574 23
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 2.083333333333286 25
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 3.0208333333332646 34
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.3333333333332575 38
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.7499999999999147 58
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.7499999999999147 71
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 1.9791666666666217 24
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 2.1874999999999503 26
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 3.124999999999929 35
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.437499999999922 39
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.854166666666579 59
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.854166666666579 72
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e5f8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81079e8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090a90> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041978> 1.3541666666666359 16
backprop <src.mcts.MCTS_Node object at 0x7fe790152ba8> 2.083333333333286 25
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 2.2916666666666146 27
backprop <src.mcts.MCTS_Node object at 0x7fe7900c44e0> 3.2291666666665932 36
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 3.541666666666586 40
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 3.9583333333332433 60
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 3.9583333333332433 73
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #8
root->2->5->0->24->2->5->0->26
Best Reward: 0.1041666666666643
iteration: 12
found coverage increase 0.1041666666666643
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81651d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80eddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 800
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80eddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013ca90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098630> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80803c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80803c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811feb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81572e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80805f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 8
Completed Iteration #9
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80980f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80980f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012deb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 6
Completed Iteration #8
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984128> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a96a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639955f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639955f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639840f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1200
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392ca58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1300
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a0f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638467f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638460f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638467f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaf98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 13
Completed Iteration #21
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638163c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638163c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638163c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763827ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638466a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638466a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d58d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633afdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633affd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633affd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80986a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80615f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5518> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b550> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817eb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 17
Completed Iteration #17
Best Reward: 0
coverage_call_count 1700
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81656a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81656a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81656a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801bd0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a49b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8684f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c79e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80412b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901647f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901647f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901644e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901647f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80800f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901642e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790164588> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81075c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81075c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c46d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79009bc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638469e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 2100
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763846ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633875f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80700f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b64a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639a99e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 8
Completed Iteration #12
Best Reward: 0
coverage_call_count 2300
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639733c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763387470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5080> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76385fd68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639954a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639954a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900acfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638702b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763870780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddd30> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 2500
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638703c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638703c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900505f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584735f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2600
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aafd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584879b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0048> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0b8> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 2800
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81578d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 2900
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79009b048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901524a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d46a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7639d96a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801bd0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8684b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a65f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900507b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80416d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe803f1c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79010dac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014acf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633872b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ebe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80800f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 14
Completed Iteration #12
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 25
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584734a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584734a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801bd0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe84deba400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75844d2b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763827240> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639052b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639059e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639730b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763905dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c73c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75843da58> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8677828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584874a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584874a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e828d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e820f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e825c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c9e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e826a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd908> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d10f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 26.041666666666668
coverage_call_count 3700
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639055c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261021d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261021d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261726d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72614b240> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72613e470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726102898> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260865c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260860f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac2b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260061d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260067b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260065c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260066a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72619be80> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72609a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260337f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260337f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf93c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8684dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0da0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0470> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe758487438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86cd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 4300
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5518> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c8656390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75845c668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633afba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584731d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584731d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aaa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5048> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79012d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79010df98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900aceb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7900ace48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80707b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261e01d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79013c358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638462b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638462b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638169e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638161d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763870e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507995c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507990f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507992e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507992e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507995c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077db70> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 4800
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726172550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8157a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80617b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260869b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72613e390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763995e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584873c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 4900
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd518> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260339e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eda90> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639059b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7639056d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639050f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639057f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790152828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763984c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260869b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260064e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261021d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261024e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261725c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260172b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260176a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260174e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726017710> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607aeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe725200ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252267f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252262b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252350f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252262b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252350f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252350f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7252268d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5300
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763995ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b880b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725235978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724df05f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b884e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b884e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fd30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d497b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d595f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d670f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d670f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d595f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d670f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d595f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe724d59588> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d599e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 21
Completed Iteration #23
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d226d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d229e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d220b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724cc60f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d228d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22160> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d499b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d499b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c492b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c494e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c494e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c494e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c94748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d809e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 5700
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d19da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d197f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c948d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f080> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c267b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c266a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c267b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c266a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb6a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 5900
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb240> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbc50> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763870d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7247616a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247616d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724c49d68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252355c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726017198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725226eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e82c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252355c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72520be10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790164c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7252afbe0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260aca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8041f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726006390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75844dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72607a828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790164b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261025f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e82940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260bf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8070d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726033588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726033748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd320> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726086ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763905438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726006550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cbb0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c493c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252af7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75078ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261edc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72613ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75078a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe72613eb38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726102588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252afc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72474b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72607a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725235fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724761668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725226908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c818b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261eddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aa20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763816278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe85ced19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726086b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638160b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261727b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79013cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c811fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80ed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79014ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639a94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79010d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c86ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c811f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72520b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79010df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79014a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79014a7f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763984400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639d9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247610f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507997f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72609a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72609a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247610f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75077d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247610f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507997f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ed780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7260e1c50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639d90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8061ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790152198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72520bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261722e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638b6630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901527b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901527b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758473438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76339c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758473ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638272b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72613e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8080198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633c16d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726102588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8669160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c81652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724761400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725235dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe763827828> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8165b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633af240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c865fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790176c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 15
Completed Iteration #21
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799748> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7584875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638469e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763973eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75843dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638469e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76391cb00> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c81a4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84deba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe758487d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76391c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7639bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c817ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763973278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76385f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c812a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b882e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633d5780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe725b88c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe758487c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7260337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c8090cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72619b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe750799588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c8107470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75844dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901529b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cbbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c49828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe84dea3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763816908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76391c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726172358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe725b88be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261613c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261613c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261613c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe803ea54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726161da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7900c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c816ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7633afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763846d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79009b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f99e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe801be3240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724df0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7320> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725200668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72474bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe726ebd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76385f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726161710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725be2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725200320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c80900f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d370b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72614ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d224e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d224e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d805f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72614ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d222b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790176e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725bf95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724cc6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d80c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d599e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d370f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d370f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d37c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724df0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725b88b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763387860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7252005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763827898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7252002b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7900509b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f7f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d22f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d598d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d490b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d59c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c945c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d598d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79012d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c020b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d591d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c13c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe790050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72524a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c13630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7901b5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d675c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4550> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ca7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d379e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe72478e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247f90b8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7638ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c269b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c269b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ffe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139bea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139bea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c268d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72478e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe726e5a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe725b88f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe790050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247dde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7139be630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724c265c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d80a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c80a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c13198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe763846d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c023c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247790f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe71395cfd0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713935748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713935518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713935518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7507aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713935da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139351d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139352e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76392c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139351d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713921a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe72619b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7633bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d67978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71390a7b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7261610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d590b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713935c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724ce4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713935c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c02278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c266a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7247eba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c34a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c34a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7247eb1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe725be2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe76388ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7139be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d37b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c94ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d67630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724c02400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d59048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71388c358> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724d22f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71390a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7139bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71395c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395ca20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138fddd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75843dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138631d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d8f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724c026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71395cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713921898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe71389dcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713863a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138637f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138346a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138346a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138346a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138244a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138342b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138342b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138342b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d39e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713834630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138240b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138240b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138240b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713863668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138240b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7133c10b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713921898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71395cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713875fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724d808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71389dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133c13c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f98> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713855828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71339fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71339fb70> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71388cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713824eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138244e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71389d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133d31d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713875048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713310400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133109b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713310898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133101d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713310898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133101d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133107f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7138fd9e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713337128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713337390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713310b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133377b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713310b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713834438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71331f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133377b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe71331fe48> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133596a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713875048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7138559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe724779b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713935208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe75845c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133596a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713349208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713359630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713824160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713337320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7247790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe71388cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713855278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71390a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71339fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138c3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713337550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713337e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7132ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7132ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7132ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713310550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713337748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe713359710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7133f2898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe71331f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe713834780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7132ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7132ef240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7132efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138241d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7132efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7138241d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe713349a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 26.041666666666668
initial coverage: 25.625
time passed (minutes): 60.1139
iterations: 287
number of new inputs: 128
final coverage: 26.0417
total coverage increase: 0.416667
