Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=1, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f79022a8f28>, tc2=<function tc2 at 0x7f79022b9048>, tc3=<function tc3 at 0x7f79022b9158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 66.7939
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771400> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3f98> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc668> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6925f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c658320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 7
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 22
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 23
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 24
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 10
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 25
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 26
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 27
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 28
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 29
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 30
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 31
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 32
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 33
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 34
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 35
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 21
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 36
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 22
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 37
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 23
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 38
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 24
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 39
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 25
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 40
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 26
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 41
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 27
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 42
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 7
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 28
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 43
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 29
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 44
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 30
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 45
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 10
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 31
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 46
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 32
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 47
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 33
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 48
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.3816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.3816793893129784 34
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.3816793893129784 49
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 0.7633587786259568 14
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.7633587786259568 35
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 0.7633587786259568 50
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 1.1450381679389352 15
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 1.1450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 1.1450381679389352 51
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 1.1450381679389352 16
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 1.1450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 1.1450381679389352 52
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66a5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedbe0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 1.5267175572519136 17
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 1.5267175572519136 38
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 1.5267175572519136 53
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a5f8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfedbe0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 1.5267175572519136 18
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 1.5267175572519136 39
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 1.5267175572519136 54
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 1.5267175572519136 19
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 1.5267175572519136 40
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 1.5267175572519136 55
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->0->18
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff91d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 1.908396946564892 20
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 1.908396946564892 41
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 1.908396946564892 56
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 2.2900763358778704 21
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 2.2900763358778704 42
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 2.2900763358778704 57
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66a390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 2.671755725190849 22
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 2.671755725190849 43
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 2.671755725190849 58
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff91d0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5f8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 2.671755725190849 23
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 2.671755725190849 44
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 2.671755725190849 59
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff91d0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5f8> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 2.671755725190849 24
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 2.671755725190849 45
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 2.671755725190849 60
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 3.053435114503827 25
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 3.053435114503827 46
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 3.053435114503827 61
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66aac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 3.4351145038168056 26
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 3.4351145038168056 47
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 3.4351145038168056 62
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5f8> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 3.816793893129784 27
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 3.816793893129784 48
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 3.816793893129784 63
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
coverage_call_count 300
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 4.198473282442762 28
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 4.198473282442762 49
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 4.198473282442762 64
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfd68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfe10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9ef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 4.580152671755741 29
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 4.580152671755741 50
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 4.580152671755741 65
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->0->18->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 4.961832061068719 30
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 4.961832061068719 51
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 4.961832061068719 66
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf8be10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bcc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 5.343511450381698 52
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 5.343511450381698 67
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 5.725190839694676 32
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 5.725190839694676 53
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 5.725190839694676 68
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfaca90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 6.106870229007654 33
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 6.106870229007654 54
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 6.106870229007654 69
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cface80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 6.488549618320633 55
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 6.488549618320633 70
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 6.870229007633611 35
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 6.870229007633611 56
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 6.870229007633611 71
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 7.25190839694659 36
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 7.25190839694659 57
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 7.25190839694659 72
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c64b438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 7.633587786259568 37
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 7.633587786259568 58
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 7.633587786259568 73
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfdff28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 8.015267175572546 38
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 8.015267175572546 59
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 8.015267175572546 74
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfac4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bcc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 8.396946564885525 39
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 8.396946564885525 60
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 8.396946564885525 75
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->0->18->6->19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3780> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 8.778625954198503 40
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 8.778625954198503 61
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 8.778625954198503 76
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfacda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 9.160305343511482 41
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 9.160305343511482 62
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 9.160305343511482 77
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 9.54198473282446 42
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 9.54198473282446 63
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 9.54198473282446 78
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3748> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 9.54198473282446 43
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 9.54198473282446 64
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 9.54198473282446 79
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 9.923664122137438 44
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 9.923664122137438 65
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 9.923664122137438 80
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf488d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bba8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 9.54198473282446 30
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 10.305343511450417 45
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 10.305343511450417 66
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 10.305343511450417 81
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf48d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4e0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 9.923664122137438 31
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 10.687022900763395 46
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 10.687022900763395 67
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 10.687022900763395 82
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48d30> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4e0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 9.923664122137438 32
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 10.687022900763395 47
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 10.687022900763395 68
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 10.687022900763395 83
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 10.305343511450417 33
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 11.068702290076374 48
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 11.068702290076374 69
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 11.068702290076374 84
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bba8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 10.687022900763395 34
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 11.450381679389352 49
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 11.450381679389352 70
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 11.450381679389352 85
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf486d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 11.068702290076374 35
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 11.83206106870233 50
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 11.83206106870233 71
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 11.83206106870233 86
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf48e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9c18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3780> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 11.450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 12.213740458015309 51
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 12.213740458015309 72
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 12.213740458015309 87
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4e0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 11.83206106870233 37
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 12.595419847328287 52
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 12.595419847328287 73
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 12.595419847328287 88
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf48ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 12.213740458015309 38
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 12.977099236641266 53
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 12.977099236641266 74
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 12.977099236641266 89
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->0->18->6->19->4
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 10.305343511450417 30
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 12.595419847328287 39
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 13.358778625954244 54
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 13.358778625954244 75
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 13.358778625954244 90
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6beb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6ba58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf486d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 12.977099236641266 40
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 13.740458015267222 55
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 13.740458015267222 76
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 13.740458015267222 91
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6be48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 13.358778625954244 41
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 14.1221374045802 56
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 14.1221374045802 77
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 14.1221374045802 92
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 13.740458015267222 42
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 14.50381679389318 57
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 14.50381679389318 78
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 14.50381679389318 93
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfac198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 14.1221374045802 43
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 14.885496183206158 58
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 14.885496183206158 79
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 14.885496183206158 94
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfed240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48208> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 14.50381679389318 44
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 15.267175572519136 59
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 15.267175572519136 80
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 15.267175572519136 95
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 10.305343511450417 30
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 12.595419847328287 36
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 14.885496183206158 45
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 15.648854961832114 60
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 15.648854961832114 81
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 15.648854961832114 96
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa31d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48208> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 12.977099236641266 37
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 15.267175572519136 46
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 16.030534351145093 61
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 16.030534351145093 82
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 16.030534351145093 97
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9630> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 13.358778625954244 38
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 15.648854961832114 47
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 16.41221374045807 62
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 16.41221374045807 83
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 16.41221374045807 98
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->0->18->6->19->4->18
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf787b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 13.740458015267222 39
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 16.030534351145093 48
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 16.79389312977105 63
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 16.79389312977105 84
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 16.79389312977105 99
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 14.1221374045802 40
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 16.41221374045807 49
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 17.175572519084028 64
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 17.175572519084028 85
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 17.175572519084028 100
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b2e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 14.50381679389318 41
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 16.79389312977105 50
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 17.557251908397006 65
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 17.557251908397006 86
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 17.557251908397006 101
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 12.595419847328287 36
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 14.885496183206158 42
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 17.175572519084028 51
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 17.938931297709985 66
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 17.938931297709985 87
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 17.938931297709985 102
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 12.977099236641266 37
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 15.267175572519136 43
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 17.557251908397006 52
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 18.320610687022963 67
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 18.320610687022963 88
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 18.320610687022963 103
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedb70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 13.358778625954244 38
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 15.648854961832114 44
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 17.938931297709985 53
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 18.70229007633594 68
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 18.70229007633594 89
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 18.70229007633594 104
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfed898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 13.740458015267222 39
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 16.030534351145093 45
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 18.320610687022963 54
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 19.08396946564892 69
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 19.08396946564892 90
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 19.08396946564892 105
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfd40f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6beb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6ba58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf486d8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 14.1221374045802 40
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 16.41221374045807 46
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 18.70229007633594 55
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 19.4656488549619 70
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 19.4656488549619 91
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 19.4656488549619 106
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 14.50381679389318 41
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 16.79389312977105 47
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 19.08396946564892 56
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 19.847328244274877 71
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 19.847328244274877 92
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 19.847328244274877 107
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e04e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 14.885496183206158 42
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 17.175572519084028 48
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 19.4656488549619 57
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 20.229007633587855 72
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 20.229007633587855 93
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 20.229007633587855 108
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e04a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78ba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 15.267175572519136 43
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 17.557251908397006 49
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 19.847328244274877 58
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 20.610687022900834 73
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 20.610687022900834 94
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 20.610687022900834 109
Completed Iteration #23
Best Reward: 0.3816793893129784
coverage_call_count 400
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e08d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bdd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 15.648854961832114 44
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 17.938931297709985 50
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 20.229007633587855 59
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 20.992366412213812 74
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 20.992366412213812 95
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 20.992366412213812 110
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->0->18->6->19->4->18->1
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6be10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a438> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d30> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 16.030534351145093 45
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 18.320610687022963 51
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 20.610687022900834 60
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 21.37404580152679 75
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 21.37404580152679 96
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 21.37404580152679 111
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d30> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 16.030534351145093 46
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 18.320610687022963 52
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 20.610687022900834 61
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 21.37404580152679 76
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 21.37404580152679 97
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 21.37404580152679 112
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 16.41221374045807 47
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 18.70229007633594 53
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 20.992366412213812 62
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 21.75572519083977 77
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 21.75572519083977 98
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 21.75572519083977 113
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c72f240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 16.79389312977105 48
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 19.08396946564892 54
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 21.37404580152679 63
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 22.137404580152747 78
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 22.137404580152747 99
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 22.137404580152747 114
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 17.175572519084028 49
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 19.4656488549619 55
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 21.75572519083977 64
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 22.519083969465726 79
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 22.519083969465726 100
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 22.519083969465726 115
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c64bda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 11.450381679389352 32
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 17.557251908397006 50
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 19.847328244274877 56
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 22.137404580152747 65
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 22.900763358778704 80
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 22.900763358778704 101
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 22.900763358778704 116
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6587b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a438> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d30> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 11.83206106870233 33
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 17.938931297709985 51
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 20.229007633587855 57
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 22.519083969465726 66
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 23.282442748091682 81
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 23.282442748091682 102
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 23.282442748091682 117
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66ab38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 12.213740458015309 34
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 18.320610687022963 52
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 20.610687022900834 58
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 22.900763358778704 67
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 23.66412213740466 82
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 23.66412213740466 103
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 23.66412213740466 118
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c72f400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 12.595419847328287 35
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 18.70229007633594 53
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 20.992366412213812 59
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 23.282442748091682 68
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 24.04580152671764 83
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 24.04580152671764 104
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 24.04580152671764 119
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f240> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35c0> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 12.977099236641266 36
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 19.08396946564892 54
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 21.37404580152679 60
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 23.66412213740466 69
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 24.427480916030618 84
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 24.427480916030618 105
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 24.427480916030618 120
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b38> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f786cfac9e8> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f98> 13.358778625954244 37
backprop <src.mcts.MCTS_Node object at 0x7f787c66a7b8> 19.4656488549619 55
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfb38> 21.75572519083977 61
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 24.04580152671764 70
backprop <src.mcts.MCTS_Node object at 0x7f787c66a198> 24.809160305343596 85
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 24.809160305343596 106
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff940> 24.809160305343596 121
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->0->18->6->19->4->18->1->3
Best Reward: 0.3816793893129784
iteration: 8
found coverage increase 0.3816793893129784
Current Total Coverage 67.17557251908397
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6923c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6923c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 500
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c00f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6fffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7712b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 17
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.3816793893129784 2
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.7633587786259568 3
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.7633587786259568 4
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.1450381679389352 5
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.1450381679389352 6
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.5267175572519136 7
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.5267175572519136 8
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.908396946564892 9
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.908396946564892 10
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 1.908396946564892 11
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.2900763358778704 12
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb358> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.2900763358778704 13
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.2900763358778704 14
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.2900763358778704 15
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.2900763358778704 16
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.2900763358778704 17
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 2.671755725190849 18
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.053435114503827 19
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1bea58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14eb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.4351145038168056 20
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.4351145038168056 21
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14fd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.816793893129784 22
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.816793893129784 23
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.816793893129784 24
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec50> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14fd0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 3.816793893129784 25
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1caa58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14fd0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 26
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 27
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 16
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 28
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14eb8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 17
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 29
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be5f8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14eb8> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 18
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 30
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 19
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 31
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 2.671755725190849 20
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.198473282442762 32
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c692908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14fd0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 3.053435114503827 21
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.580152671755741 33
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 3.4351145038168056 22
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 4.961832061068719 34
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1caa20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 3.816793893129784 23
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 5.343511450381698 35
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 4.198473282442762 24
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 5.725190839694676 36
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 4.198473282442762 25
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 5.725190839694676 37
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c64bcc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 6.106870229007654 38
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 6.106870229007654 39
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14828> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 4.580152671755741 28
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 6.106870229007654 40
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfac7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1caa20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14828> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 4.961832061068719 29
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 6.488549618320633 41
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 6.870229007633611 42
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14e48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 5.725190839694676 31
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 7.25190839694659 43
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14e48> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 5.725190839694676 32
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 7.25190839694659 44
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1be208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14828> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.106870229007654 33
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 7.633587786259568 45
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 7.633587786259568 46
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14828> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.015267175572546 47
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.870229007633611 36
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.396946564885525 48
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14828> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.396946564885525 49
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.396946564885525 50
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.961832061068719 20
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.870229007633611 39
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.396946564885525 51
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->0->15
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14da0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 4.961832061068719 21
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 6.870229007633611 40
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.396946564885525 52
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1bed30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 5.343511450381698 22
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 8.778625954198503 53
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca208> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14e48> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 5.725190839694676 23
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 7.633587786259568 42
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 9.160305343511482 54
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1736a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 6.106870229007654 24
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 9.54198473282446 55
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 6.488549618320633 25
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 9.923664122137438 56
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b70> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 6.488549618320633 26
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 9.923664122137438 57
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c185438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1736a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 6.870229007633611 27
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 10.305343511450417 58
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c185b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1856d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1736a0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 7.25190839694659 28
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 10.687022900763395 59
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c185f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 9.54198473282446 48
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 11.068702290076374 60
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bed30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 8.015267175572546 30
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 9.923664122137438 49
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 11.450381679389352 61
Completed Iteration #17
Best Reward: 0.3816793893129784
coverage_call_count 700
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 6.488549618320633 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 8.396946564885525 31
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 10.305343511450417 50
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 11.83206106870233 62
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c173518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 6.870229007633611 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 8.778625954198503 32
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 10.687022900763395 51
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 12.213740458015309 63
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->0->15->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c173940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 9.160305343511482 33
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 11.068702290076374 52
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 12.595419847328287 64
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1854a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 9.54198473282446 34
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 11.450381679389352 53
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 12.977099236641266 65
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 9.923664122137438 35
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 11.83206106870233 54
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 13.358778625954244 66
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18e748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 10.305343511450417 36
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 12.213740458015309 55
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 13.740458015267222 67
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 10.687022900763395 37
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 12.595419847328287 56
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 14.1221374045802 68
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18ecc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 11.068702290076374 38
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 12.977099236641266 57
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 14.50381679389318 69
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 11.450381679389352 39
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 13.358778625954244 58
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 14.885496183206158 70
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e6a0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 11.83206106870233 40
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 13.740458015267222 59
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 15.267175572519136 71
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 12.213740458015309 41
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 14.1221374045802 60
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 15.648854961832114 72
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1cad30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 12.595419847328287 42
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 14.50381679389318 61
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 16.030534351145093 73
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 12.977099236641266 43
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 14.885496183206158 62
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 16.41221374045807 74
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c185828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e6a0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 13.358778625954244 44
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 15.267175572519136 63
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 16.79389312977105 75
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a77f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 13.740458015267222 45
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 15.648854961832114 64
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 17.175572519084028 76
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->0->15->5->13
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 14.1221374045802 46
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 16.030534351145093 65
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 17.557251908397006 77
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 14.1221374045802 47
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 16.030534351145093 66
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 17.557251908397006 78
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be588> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc50> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 12.213740458015309 38
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 14.1221374045802 48
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 16.030534351145093 67
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 17.557251908397006 79
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18eef0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 12.595419847328287 39
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 14.50381679389318 49
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 16.41221374045807 68
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 17.938931297709985 80
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18ea90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 12.977099236641266 40
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 14.885496183206158 50
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 16.79389312977105 69
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 18.320610687022963 81
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18eef0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 13.358778625954244 41
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 15.267175572519136 51
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 17.175572519084028 70
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 18.70229007633594 82
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c173390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 13.740458015267222 42
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 15.648854961832114 52
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 17.557251908397006 71
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 19.08396946564892 83
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18e208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185128> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c173940> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 14.1221374045802 43
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 16.030534351145093 53
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 17.938931297709985 72
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 19.4656488549619 84
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 14.50381679389318 44
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 16.41221374045807 54
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 18.320610687022963 73
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 19.847328244274877 85
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a72e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 14.885496183206158 45
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 16.79389312977105 55
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 18.70229007633594 74
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 20.229007633587855 86
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c185e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 15.267175572519136 46
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 17.175572519084028 56
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 19.08396946564892 75
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 20.610687022900834 87
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc50> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 15.267175572519136 47
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 17.175572519084028 57
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 19.08396946564892 76
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 20.610687022900834 88
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a72e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 15.648854961832114 48
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 17.557251908397006 58
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 19.4656488549619 77
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 20.992366412213812 89
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 16.030534351145093 49
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 17.938931297709985 59
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 19.847328244274877 78
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 21.37404580152679 90
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1595c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 16.41221374045807 50
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 18.320610687022963 60
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 20.229007633587855 79
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 21.75572519083977 91
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb0f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 16.79389312977105 51
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 18.70229007633594 61
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 20.610687022900834 80
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 22.137404580152747 92
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c159978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb0f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c159278> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff668> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 17.175572519084028 52
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 19.08396946564892 62
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 20.992366412213812 81
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 22.519083969465726 93
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a70f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 17.557251908397006 53
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 19.4656488549619 63
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 21.37404580152679 82
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 22.900763358778704 94
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->0->15->5->13->3
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c185a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 17.938931297709985 54
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 19.847328244274877 64
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 21.75572519083977 83
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 23.282442748091682 95
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c173780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 12.977099236641266 38
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 18.320610687022963 55
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 20.229007633587855 65
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 22.137404580152747 84
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 23.66412213740466 96
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18e358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 13.358778625954244 39
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 18.70229007633594 56
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 20.610687022900834 66
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 22.519083969465726 85
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 24.04580152671764 97
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 13.740458015267222 40
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 19.08396946564892 57
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 20.992366412213812 67
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 22.900763358778704 86
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 24.427480916030618 98
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1598d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 19.4656488549619 58
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 21.37404580152679 68
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 23.282442748091682 87
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 24.809160305343596 99
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c159908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 19.847328244274877 59
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 21.75572519083977 69
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 23.66412213740466 88
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 25.190839694656574 100
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 20.229007633587855 60
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 22.137404580152747 70
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 24.04580152671764 89
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 25.572519083969553 101
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 12.595419847328287 38
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 14.885496183206158 44
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 20.229007633587855 61
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 22.137404580152747 71
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 24.04580152671764 90
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 25.572519083969553 102
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c159a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 12.977099236641266 39
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 15.267175572519136 45
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 20.610687022900834 62
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 22.519083969465726 72
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 24.427480916030618 91
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 25.95419847328253 103
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c173a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 13.358778625954244 40
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 20.992366412213812 63
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 22.900763358778704 73
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 24.809160305343596 92
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 26.33587786259551 104
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134470> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 13.358778625954244 41
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 15.648854961832114 47
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 20.992366412213812 64
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 22.900763358778704 74
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 24.809160305343596 93
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 26.33587786259551 105
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c159c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 13.740458015267222 42
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 16.030534351145093 48
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 21.37404580152679 65
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 23.282442748091682 75
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 25.190839694656574 94
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 26.717557251908488 106
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1340b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166cc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c159908> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c159a90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 14.1221374045802 43
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 16.41221374045807 49
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 21.75572519083977 66
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 23.66412213740466 76
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 25.572519083969553 95
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 27.099236641221466 107
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 14.50381679389318 44
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 16.79389312977105 50
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 22.137404580152747 67
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 24.04580152671764 77
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 25.95419847328253 96
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 27.480916030534445 108
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166ba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166320> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 14.885496183206158 45
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 17.175572519084028 51
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 22.519083969465726 68
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 24.427480916030618 78
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 26.33587786259551 97
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 27.862595419847423 109
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->0->15->5->13->3->14
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 15.267175572519136 46
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 17.557251908397006 52
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 22.900763358778704 69
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 24.809160305343596 79
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 26.717557251908488 98
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 28.2442748091604 110
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 15.648854961832114 47
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 17.938931297709985 53
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 23.282442748091682 70
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 25.190839694656574 80
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 27.099236641221466 99
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 28.62595419847338 111
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 16.030534351145093 48
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 18.320610687022963 54
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 23.66412213740466 71
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 25.572519083969553 81
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 27.480916030534445 100
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 29.00763358778636 112
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18ea20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e358> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 16.41221374045807 49
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 18.70229007633594 55
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 24.04580152671764 72
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 25.95419847328253 82
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 27.862595419847423 101
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 29.389312977099337 113
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 16.79389312977105 50
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 19.08396946564892 56
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 24.427480916030618 73
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 26.33587786259551 83
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 28.2442748091604 102
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 29.770992366412315 114
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 17.175572519084028 51
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 19.4656488549619 57
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 24.809160305343596 74
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 26.717557251908488 84
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 28.62595419847338 103
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 30.152671755725294 115
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166e10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 17.557251908397006 52
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 19.847328244274877 58
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 25.190839694656574 75
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 27.099236641221466 85
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 29.00763358778636 104
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 30.534351145038272 116
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 10.305343511450417 30
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 17.938931297709985 53
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 20.229007633587855 59
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 25.572519083969553 76
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 27.480916030534445 86
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 29.389312977099337 105
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 30.91603053435125 117
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c14b438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c185a58> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 10.687022900763395 31
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 18.320610687022963 54
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 20.610687022900834 60
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 25.95419847328253 77
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 27.862595419847423 87
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 29.770992366412315 106
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 31.29770992366423 118
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c14b940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 18.70229007633594 55
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 20.992366412213812 61
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 26.33587786259551 78
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 28.2442748091604 88
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 30.152671755725294 107
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 31.679389312977207 119
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b208> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e48> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 19.08396946564892 56
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 21.37404580152679 62
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 26.717557251908488 79
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 28.62595419847338 89
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 30.534351145038272 108
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 32.061068702290186 120
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c18eda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4470> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c185a58> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 19.4656488549619 57
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 21.75572519083977 63
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 27.099236641221466 80
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 29.00763358778636 90
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 30.91603053435125 109
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 32.442748091603164 121
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 19.847328244274877 58
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 22.137404580152747 64
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 27.480916030534445 81
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 29.389312977099337 91
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 31.29770992366423 110
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 32.82442748091614 122
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
coverage_call_count 800
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166240> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f28> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 12.595419847328287 36
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 20.229007633587855 59
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 22.519083969465726 65
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 27.862595419847423 82
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 29.770992366412315 92
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 31.679389312977207 111
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 33.20610687022912 123
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c159ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca860> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e358> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 12.977099236641266 37
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 20.610687022900834 60
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 22.900763358778704 66
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 28.2442748091604 83
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 30.152671755725294 93
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 32.061068702290186 112
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 33.5877862595421 124
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->0->15->5->13->3->14->1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 13.358778625954244 38
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 20.992366412213812 61
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 23.282442748091682 67
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 28.62595419847338 84
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 30.534351145038272 94
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 32.442748091603164 113
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 33.96946564885508 125
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c114588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 13.740458015267222 39
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 21.37404580152679 62
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 23.66412213740466 68
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 29.00763358778636 85
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 30.91603053435125 95
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 32.82442748091614 114
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 34.351145038168056 126
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c114b38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 14.1221374045802 40
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 21.75572519083977 63
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 24.04580152671764 69
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 29.389312977099337 86
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 31.29770992366423 96
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 33.20610687022912 115
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 34.732824427481034 127
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 14.50381679389318 41
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 22.137404580152747 64
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 24.427480916030618 70
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 29.770992366412315 87
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 31.679389312977207 97
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 33.5877862595421 116
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 35.11450381679401 128
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c166ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4710> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 14.885496183206158 42
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 22.519083969465726 65
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 24.809160305343596 71
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 30.152671755725294 88
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 32.061068702290186 98
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 33.96946564885508 117
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 35.49618320610699 129
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1594e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159ba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c166e10> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 15.267175572519136 43
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 22.900763358778704 66
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 25.190839694656574 72
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 30.534351145038272 89
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 32.442748091603164 99
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 34.351145038168056 118
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 35.87786259541997 130
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166e10> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 15.648854961832114 44
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 23.282442748091682 67
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 25.572519083969553 73
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 30.91603053435125 90
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 32.82442748091614 100
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 34.732824427481034 119
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 36.25954198473295 131
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c114320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 11.450381679389352 32
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 16.030534351145093 45
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 23.66412213740466 68
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 25.95419847328253 74
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 31.29770992366423 91
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 33.20610687022912 101
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 35.11450381679401 120
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 36.64122137404593 132
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1144e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 11.83206106870233 33
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 16.41221374045807 46
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 24.04580152671764 69
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 26.33587786259551 75
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 31.679389312977207 92
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 33.5877862595421 102
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 35.49618320610699 121
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 37.022900763358905 133
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1144e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 12.213740458015309 34
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 16.79389312977105 47
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 24.427480916030618 70
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 26.717557251908488 76
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 32.061068702290186 93
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 33.96946564885508 103
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 35.87786259541997 122
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 37.40458015267188 134
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1144e0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 12.595419847328287 35
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 17.175572519084028 48
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 24.809160305343596 71
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 27.099236641221466 77
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 32.442748091603164 94
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 34.351145038168056 104
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 36.25954198473295 123
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 37.78625954198486 135
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 12.977099236641266 36
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 17.557251908397006 49
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 25.190839694656574 72
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 27.480916030534445 78
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 32.82442748091614 95
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 34.732824427481034 105
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 36.64122137404593 124
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 38.16793893129784 136
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1149e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1144e0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 13.358778625954244 37
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 17.938931297709985 50
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 25.572519083969553 73
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 27.862595419847423 79
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 33.20610687022912 96
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 35.11450381679401 106
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 37.022900763358905 125
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 38.54961832061082 137
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1144e0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 13.358778625954244 38
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 17.938931297709985 51
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 25.572519083969553 74
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 27.862595419847423 80
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 33.20610687022912 97
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 35.11450381679401 107
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 37.022900763358905 126
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 38.54961832061082 138
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1669e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f40f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c166e10> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 13.740458015267222 39
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 18.320610687022963 52
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 25.95419847328253 75
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 28.2442748091604 81
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 33.5877862595421 98
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 35.49618320610699 108
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 37.40458015267188 127
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 38.9312977099238 139
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0b36d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 14.1221374045802 40
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 18.70229007633594 53
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 26.33587786259551 76
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 28.62595419847338 82
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 33.96946564885508 99
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 35.87786259541997 109
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 37.78625954198486 128
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 39.312977099236775 140
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114550> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7f786c1730b8> 14.50381679389318 41
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 19.08396946564892 54
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca828> 26.717557251908488 77
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 29.00763358778636 83
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccda0> 34.351145038168056 100
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 36.25954198473295 110
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0668> 38.16793893129784 129
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 39.694656488549754 141
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->0->15->5->13->3->14->1->15
Best Reward: 0.3816793893129784
iteration: 16
found coverage increase 0.3816793893129784
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78ce4494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1669b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c72b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c08a278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0797b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e311d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e311d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826e91400> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e003c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e003c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0372b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124869b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124869b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 1300
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e142e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476ac8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124478d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124864a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124475c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124478d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124183c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124475c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 7
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 8
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 10
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f160> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c166a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1344a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1344a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c18e470> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1859b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1859b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1739e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1beb70> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1660f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c114048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 7
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1857b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f789813bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f789813bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f789813bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bef0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc860> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cabe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1bea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d44e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78ce5920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a38d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca0f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf48550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.3816793893129784 5
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.3816793893129784 6
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.3816793893129784 7
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.3816793893129784 8
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.3816793893129784 9
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.7633587786259568 10
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 0.7633587786259568 11
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.1450381679389352 12
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.1450381679389352 13
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.1450381679389352 14
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.5267175572519136 15
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.5267175572519136 16
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.5267175572519136 17
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf48128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 1.908396946564892 18
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 2.2900763358778704 19
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48550> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 2.2900763358778704 20
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 2.2900763358778704 21
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfacac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 2.671755725190849 22
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacc88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 3.053435114503827 23
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78780> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfacc88> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfacac8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 3.053435114503827 24
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 3.4351145038168056 25
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48550> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 3.4351145038168056 26
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 3.816793893129784 27
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 3.816793893129784 28
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 4.198473282442762 29
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48550> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 4.198473282442762 30
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 4.580152671755741 31
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 4.961832061068719 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 4.961832061068719 32
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7e04a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 5.343511450381698 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 5.343511450381698 33
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf14a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 5.725190839694676 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 5.725190839694676 34
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c134438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 6.106870229007654 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 6.106870229007654 35
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 6.488549618320633 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 6.488549618320633 36
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 6.870229007633611 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 6.870229007633611 37
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 7.25190839694659 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 7.25190839694659 38
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786c1854e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 7.633587786259568 30
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 7.633587786259568 39
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185438> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14a90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3630> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 8.015267175572546 40
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 8.396946564885525 32
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 8.396946564885525 41
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf78c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3630> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 8.778625954198503 33
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 8.778625954198503 42
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfed080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 9.160305343511482 34
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 9.160305343511482 43
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf61358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 9.54198473282446 35
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 9.54198473282446 44
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->8->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf48780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61358> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 9.923664122137438 36
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 9.923664122137438 45
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 9.923664122137438 37
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 9.923664122137438 46
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf788d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 10.305343511450417 38
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 10.305343511450417 47
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfed7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 10.687022900763395 39
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 10.687022900763395 48
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cfeddd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf61358> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 11.068702290076374 40
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 11.068702290076374 49
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 11.450381679389352 41
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 11.450381679389352 50
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144e0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf61358> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 11.83206106870233 42
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 11.83206106870233 51
Completed Iteration #22
Best Reward: 0.3816793893129784
coverage_call_count 1800
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->8->5->8
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 12.213740458015309 43
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 12.213740458015309 52
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66ac50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9550> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 12.595419847328287 44
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 12.595419847328287 53
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c771978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9550> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 12.977099236641266 45
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 12.977099236641266 54
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->8->5->8->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 13.358778625954244 46
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 13.358778625954244 55
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c67fac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 13.740458015267222 47
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 13.740458015267222 56
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->8->5->8->6->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c760eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 14.1221374045802 48
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 14.1221374045802 57
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 8.396946564885525 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 10.305343511450417 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 14.50381679389318 49
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 14.50381679389318 58
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c67f6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71edd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760eb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 10.687022900763395 30
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 14.885496183206158 50
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 14.885496183206158 59
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 15.267175572519136 51
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 15.267175572519136 60
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->8->5->8->6->6->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 9.160305343511482 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 11.068702290076374 32
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 15.267175572519136 52
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 15.267175572519136 61
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c760dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 9.54198473282446 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 11.450381679389352 33
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 15.648854961832114 53
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 15.648854961832114 62
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c658550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1854e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 11.83206106870233 34
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 16.030534351145093 54
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 16.030534351145093 63
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658550> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c67f9e8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1854e0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 16.030534351145093 55
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 16.030534351145093 64
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 16.41221374045807 56
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 16.41221374045807 65
Completed Iteration #23
Best Reward: 0.3816793893129784
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b048> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 16.41221374045807 57
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 16.41221374045807 66
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->8->5->8->6->6->5->8
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c64b7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 12.595419847328287 38
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 16.79389312977105 58
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 16.79389312977105 67
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 12.977099236641266 39
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 17.175572519084028 59
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 17.175572519084028 68
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0a20> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 11.068702290076374 35
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 12.977099236641266 40
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 17.175572519084028 60
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 17.175572519084028 69
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c67f780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 4.198473282442762 16
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 11.450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 13.358778625954244 41
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 17.557251908397006 61
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 17.557251908397006 70
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 11.83206106870233 37
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 13.740458015267222 42
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 17.938931297709985 62
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 17.938931297709985 71
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f787c7716a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebda0> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b898> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f786c0b37f0> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7470> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf147b8> 12.213740458015309 38
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 14.1221374045802 43
backprop <src.mcts.MCTS_Node object at 0x7f786cf48c88> 18.320610687022963 63
backprop <src.mcts.MCTS_Node object at 0x7f786cf14400> 18.320610687022963 72
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->8->5->8->6->6->5->8->0
Best Reward: 0.3816793893129784
iteration: 51
found coverage increase 0.3816793893129784
Current Total Coverage 67.93893129770993
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc198> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc7f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c037828> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 12
Completed Iteration #17
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812418668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0379b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f518> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c14b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e006d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e006d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124866a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 2300
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e002e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124474a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244f2b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72878d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72878d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72878d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72877b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 2400
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72877b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72073c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72073c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72789e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72072e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b9b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781244fac8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c079128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6923c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c64b940> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c66a978> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0370f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 15
Completed Iteration #23
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6926a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 10
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 11
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfedba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 12
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 13
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 14
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 15
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 16
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 17
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 18
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 19
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.3816793893129642 20
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc9e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 21
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 6
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 22
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 7
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 23
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 8
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 24
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 9
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 25
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 10
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 26
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 11
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 27
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 12
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 28
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.7633587786259284 13
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 0.7633587786259284 29
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.1450381679388926 14
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.1450381679388926 30
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
coverage_call_count 2800
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.1450381679388926 15
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.1450381679388926 31
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.1450381679388926 16
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.1450381679388926 32
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.1450381679388926 17
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.1450381679388926 33
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.1450381679388926 18
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.1450381679388926 34
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.5267175572518568 19
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.5267175572518568 35
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.908396946564821 20
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.908396946564821 36
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.908396946564821 21
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.908396946564821 37
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 1.908396946564821 22
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 1.908396946564821 38
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->6->9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 2.290076335877785 23
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 2.290076335877785 39
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786cfacba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf484e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 2.6717557251907493 24
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 2.6717557251907493 40
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 3.0534351145037135 25
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 3.0534351145037135 41
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf484e0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca668> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 3.4351145038166777 26
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 3.4351145038166777 42
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786cfac2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacba8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf484e0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca668> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 3.816793893129642 27
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 3.816793893129642 43
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 3.816793893129642 28
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 3.816793893129642 44
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7278> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 3.816793893129642 15
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 3.816793893129642 29
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 3.816793893129642 45
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c173ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bef60> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7278> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 4.198473282442606 30
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 4.198473282442606 46
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 4.58015267175557 17
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 4.58015267175557 31
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 4.58015267175557 47
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 4.9618320610685345 18
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 4.9618320610685345 32
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 4.9618320610685345 48
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->6->9->6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c159a58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 5.343511450381499 33
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 5.343511450381499 49
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 5.725190839694463 34
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 5.725190839694463 50
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 5.725190839694463 21
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 5.725190839694463 35
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 5.725190839694463 51
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 6.106870229007427 22
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 6.106870229007427 36
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 6.106870229007427 52
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c166160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 6.488549618320391 37
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 6.488549618320391 53
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c159358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 6.870229007633355 24
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 6.870229007633355 38
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 6.870229007633355 54
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c173fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac5f8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 6.870229007633355 23
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 7.25190839694632 25
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 7.25190839694632 39
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 7.25190839694632 55
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1344a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4f60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 7.633587786259284 40
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 7.633587786259284 56
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac5f8> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 7.25190839694632 25
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 7.633587786259284 41
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 7.633587786259284 57
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->6->9->6->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 8.015267175572248 42
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 8.015267175572248 58
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c18e588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 8.015267175572248 27
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 8.396946564885212 43
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 8.396946564885212 59
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159a58> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 8.396946564885212 44
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 8.396946564885212 60
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1147f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1737f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 8.778625954198176 45
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 8.778625954198176 61
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1737f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 8.778625954198176 30
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 9.16030534351114 46
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 9.16030534351114 62
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
coverage_call_count 2900
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46d8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 9.16030534351114 33
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 9.16030534351114 47
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 9.16030534351114 63
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->6->9->6->0->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 9.541984732824105 34
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 9.541984732824105 48
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 9.541984732824105 64
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f78123eb668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 6.870229007633355 23
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 9.923664122137069 35
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 9.923664122137069 49
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 9.923664122137069 65
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 10.305343511450033 36
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 10.305343511450033 50
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 10.305343511450033 66
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 10.687022900762997 37
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 10.687022900762997 51
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 10.687022900762997 67
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 10.305343511450033 36
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 10.687022900762997 38
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 10.687022900762997 52
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 10.687022900762997 68
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1a76d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 8.015267175572248 27
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 10.687022900762997 37
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 11.068702290075962 39
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 11.068702290075962 53
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 11.068702290075962 69
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c159c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 8.396946564885212 28
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 11.068702290075962 38
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 11.450381679388926 40
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 11.450381679388926 54
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 11.450381679388926 70
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c18e978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb1d0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 8.778625954198176 29
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 11.450381679388926 39
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 11.83206106870189 41
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 11.83206106870189 55
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 11.83206106870189 71
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->6->9->6->0->0->26
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c185a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 9.16030534351114 30
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 11.83206106870189 40
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 12.213740458014854 42
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 12.213740458014854 56
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 12.213740458014854 72
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb1d0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 9.541984732824105 31
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 12.595419847327818 43
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 12.595419847327818 57
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 12.595419847327818 73
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7812447320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185a20> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 9.923664122137069 32
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 12.595419847327818 42
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 12.977099236640782 44
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 12.977099236640782 58
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 12.977099236640782 74
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 8.778625954198176 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 10.305343511450033 33
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 12.977099236640782 43
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 13.358778625953747 45
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 13.358778625953747 59
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 13.358778625953747 75
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddaf98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb1d0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 9.16030534351114 28
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 10.687022900762997 34
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 13.358778625953747 44
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 13.74045801526671 46
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 13.74045801526671 60
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 13.74045801526671 76
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f786c1592e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 11.068702290075962 35
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 13.74045801526671 45
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 14.122137404579675 47
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 14.122137404579675 61
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 14.122137404579675 77
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 9.541984732824105 30
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 11.068702290075962 36
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 13.74045801526671 46
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 14.122137404579675 48
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 14.122137404579675 62
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 14.122137404579675 78
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f78123eb550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb4a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 9.923664122137069 31
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 11.450381679388926 37
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 14.122137404579675 47
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 14.50381679389264 49
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 14.50381679389264 63
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 14.50381679389264 79
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb1d0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 10.305343511450033 32
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 11.83206106870189 38
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 14.50381679389264 48
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 14.885496183205603 50
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 14.885496183205603 64
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 14.885496183205603 80
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->6->9->6->0->0->26->8
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7826ed44e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 10.687022900762997 33
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 12.213740458014854 39
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 14.885496183205603 49
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 15.267175572518568 51
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 15.267175572518568 65
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 15.267175572518568 81
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d7287d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea320> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 11.068702290075962 34
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 12.595419847327818 40
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 15.267175572518568 50
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 15.648854961831532 52
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 15.648854961831532 66
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 15.648854961831532 82
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d721bda0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 11.450381679388926 35
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 12.977099236640782 41
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 15.648854961831532 51
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 16.030534351144496 53
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 16.030534351144496 67
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 16.030534351144496 83
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f78123eb198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddaa90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1f98> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 11.83206106870189 36
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 13.358778625953747 42
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 16.030534351144496 52
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 16.41221374045746 54
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 16.41221374045746 68
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 16.41221374045746 84
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1d68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea6d8> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf28> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f787c692e48> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7f786cff9b70> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bbe0> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 13.74045801526671 43
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a58> 16.41221374045746 53
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 16.793893129770424 55
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 16.793893129770424 69
backprop <src.mcts.MCTS_Node object at 0x7f787c760f60> 16.793893129770424 85
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->6->9->6->0->0->26->8->23
Best Reward: 0.3816793893129642
iteration: 84
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124476a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124476a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124476a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1594e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c114cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff98d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bdd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e45f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fcef0> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 3100
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c062470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e91898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6fff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6fff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf789b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e319e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf78630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486160> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0629e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0629e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72077b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124867f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61206a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfde10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d61204e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 13
Completed Iteration #18
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c079ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60937b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60938d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3500
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60937b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6053240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.3816793893129926 11
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.3816793893129926 12
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.3816793893129926 13
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053240> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.7633587786259852 14
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.7633587786259852 15
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6053240> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.1450381679389778 16
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.1450381679389778 17
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 1.1450381679389778 7
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.1450381679389778 18
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.1450381679389778 19
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 1.1450381679389778 8
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.1450381679389778 20
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.5267175572519704 21
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.5267175572519704 22
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.5267175572519704 23
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6066c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 24
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 25
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 26
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 27
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 9
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 28
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 10
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 29
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 11
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 30
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 12
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 31
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 13
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 32
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 0.7633587786259852 14
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 1.908396946564963 33
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 1.1450381679389778 15
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 2.2900763358779557 34
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 1.5267175572519704 16
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 2.6717557251909483 35
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a58> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 1.5267175572519704 8
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 1.5267175572519704 17
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 2.6717557251909483 36
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 1.908396946564963 18
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.053435114503941 37
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7826e14978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073cc0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 2.2900763358779557 19
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.4351145038169335 38
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 2.2900763358779557 20
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.4351145038169335 39
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 2.2900763358779557 12
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 2.2900763358779557 21
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.4351145038169335 40
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073cc0> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 2.2900763358779557 13
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 2.2900763358779557 22
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.4351145038169335 41
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d60004e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073cc0> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 2.6717557251909483 14
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 2.6717557251909483 23
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.816793893129926 42
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073cc0> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 2.6717557251909483 15
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 2.6717557251909483 24
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 3.816793893129926 43
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6000dd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 3.053435114503941 16
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 3.053435114503941 25
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 4.198473282442919 44
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->5->4
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 3.053435114503941 17
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 3.053435114503941 26
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 4.198473282442919 45
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 3.053435114503941 18
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 3.053435114503941 27
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 4.198473282442919 46
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d601cd68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 3.4351145038169335 19
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 3.4351145038169335 28
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 4.580152671755911 47
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d601cf28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cd68> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 3.816793893129926 20
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 3.816793893129926 29
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 4.961832061068904 48
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 3.816793893129926 21
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 3.816793893129926 30
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 4.961832061068904 49
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d613af28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093b00> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf786a0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.053435114503941 13
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.198473282442919 22
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.198473282442919 31
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 5.343511450381897 50
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.580152671755911 23
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.580152671755911 32
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 5.725190839694889 51
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.580152671755911 24
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.580152671755911 33
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 5.725190839694889 52
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa320> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.4351145038169335 16
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.580152671755911 25
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.580152671755911 34
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 5.725190839694889 53
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa320> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.4351145038169335 17
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.580152671755911 26
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.580152671755911 35
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 5.725190839694889 54
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.816793893129926 18
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.961832061068904 27
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.961832061068904 36
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 6.106870229007882 55
Completed Iteration #17
Best Reward: 0.3816793893129926
coverage_call_count 3600
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cd68> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.961832061068904 28
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.961832061068904 37
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 6.106870229007882 56
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 3.816793893129926 20
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 4.961832061068904 29
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 4.961832061068904 38
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 6.106870229007882 57
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 4.198473282442919 21
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 5.343511450381897 30
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 5.343511450381897 39
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 6.488549618320874 58
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 4.580152671755911 22
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 5.725190839694889 31
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 5.725190839694889 40
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 6.870229007633867 59
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->5->4->2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6024dd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 4.961832061068904 23
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 6.106870229007882 32
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 6.106870229007882 41
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 7.25190839694686 60
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024dd8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3048> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 4.961832061068904 24
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 6.106870229007882 33
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 6.106870229007882 42
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 7.25190839694686 61
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3f28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 5.343511450381897 25
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 6.488549618320874 34
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 6.488549618320874 43
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 7.633587786259852 62
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 5.343511450381897 26
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 6.488549618320874 35
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 6.488549618320874 44
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 7.633587786259852 63
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 5.725190839694889 27
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 6.870229007633867 36
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 6.870229007633867 45
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 8.015267175572845 64
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6066cc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3048> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 6.106870229007882 28
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 7.25190839694686 37
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 7.25190839694686 46
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 8.396946564885837 65
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3048> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 6.106870229007882 29
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 7.25190839694686 38
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 7.25190839694686 47
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 8.396946564885837 66
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3f28> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 6.488549618320874 30
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 7.633587786259852 39
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 7.633587786259852 48
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 8.77862595419883 67
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d72e48d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 6.870229007633867 31
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 8.015267175572845 40
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 8.015267175572845 49
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 9.160305343511823 68
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024828> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e48d0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 7.25190839694686 32
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 8.396946564885837 41
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 8.396946564885837 50
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 9.541984732824815 69
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcedd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a20> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3f28> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 7.633587786259852 33
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 8.77862595419883 42
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 8.77862595419883 51
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 9.923664122137808 70
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 8.015267175572845 34
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 9.160305343511823 43
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 9.160305343511823 52
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 10.3053435114508 71
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024dd8> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3048> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 8.015267175572845 35
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 9.160305343511823 44
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 9.160305343511823 53
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 10.3053435114508 72
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->5->4->2->14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3dd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 8.396946564885837 36
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 9.541984732824815 45
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 9.541984732824815 54
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 10.687022900763793 73
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3dd8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 4.580152671755911 18
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 8.396946564885837 37
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 9.541984732824815 46
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 9.541984732824815 55
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 10.687022900763793 74
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce668> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024828> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72e48d0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 3.816793893129926 13
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 4.961832061068904 19
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 8.77862595419883 38
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 9.923664122137808 47
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 9.923664122137808 56
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 11.068702290076786 75
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 4.961832061068904 20
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 8.77862595419883 39
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 9.923664122137808 48
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 9.923664122137808 57
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 11.068702290076786 76
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcea90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a20> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3f28> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 5.343511450381897 21
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 9.160305343511823 40
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 10.3053435114508 49
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 10.3053435114508 58
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 11.450381679389778 77
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6024550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024e10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3f28> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 4.580152671755911 16
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 5.725190839694889 22
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 9.541984732824815 41
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 10.687022900763793 50
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 10.687022900763793 59
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 11.832061068702771 78
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 5.725190839694889 23
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 9.541984732824815 42
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 10.687022900763793 51
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 10.687022900763793 60
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 11.832061068702771 79
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d6066da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3be0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3dd8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 6.106870229007882 24
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 9.923664122137808 43
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 11.068702290076786 52
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 11.068702290076786 61
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 12.213740458015764 80
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 6.488549618320874 25
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 10.3053435114508 44
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 11.450381679389778 53
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 11.450381679389778 62
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 12.595419847328756 81
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3a90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcedd8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a20> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3f28> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 5.725190839694889 20
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 6.870229007633867 26
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 10.687022900763793 45
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 11.832061068702771 54
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 11.832061068702771 63
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 12.977099236641749 82
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 6.106870229007882 21
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 7.25190839694686 27
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 11.068702290076786 46
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 12.213740458015764 55
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 12.213740458015764 64
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 13.358778625954741 83
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3dd8> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 6.488549618320874 22
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 7.633587786259852 28
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 11.450381679389778 47
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 12.595419847328756 56
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 12.595419847328756 65
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 13.740458015267734 84
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->5->4->2->14->4
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 6.870229007633867 23
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 8.015267175572845 29
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 11.832061068702771 48
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 12.977099236641749 57
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 12.977099236641749 66
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 14.122137404580727 85
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3eb8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 7.25190839694686 24
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 8.396946564885837 30
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 12.213740458015764 49
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 13.358778625954741 58
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 13.358778625954741 67
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 14.50381679389372 86
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb5c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 7.633587786259852 25
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 8.77862595419883 31
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 12.595419847328756 50
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 13.740458015267734 59
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 13.740458015267734 68
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 14.885496183206712 87
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbc88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 8.015267175572845 26
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 9.160305343511823 32
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 12.977099236641749 51
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 14.122137404580727 60
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 14.122137404580727 69
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 15.267175572519704 88
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbf28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3eb8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 8.396946564885837 27
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 9.541984732824815 33
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 13.358778625954741 52
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 14.50381679389372 61
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 14.50381679389372 70
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 15.648854961832697 89
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89e10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 8.77862595419883 28
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 9.923664122137808 34
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 13.740458015267734 53
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 14.885496183206712 62
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 14.885496183206712 71
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 16.03053435114569 90
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89d68> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3eb8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 9.160305343511823 29
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 10.3053435114508 35
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 14.122137404580727 54
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 15.267175572519704 63
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 15.267175572519704 72
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 16.412213740458682 91
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92a90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbc88> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 9.541984732824815 30
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 10.687022900763793 36
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 14.50381679389372 55
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 15.648854961832697 64
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 15.648854961832697 73
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 16.793893129771675 92
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d60000b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 9.923664122137808 31
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 11.068702290076786 37
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 14.885496183206712 56
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 16.03053435114569 65
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 16.03053435114569 74
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 17.175572519084668 93
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb5c0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 6.488549618320874 18
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 10.3053435114508 32
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 11.450381679389778 38
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 15.267175572519704 57
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 16.412213740458682 66
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 16.412213740458682 75
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 17.55725190839766 94
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbe48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3240> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 6.870229007633867 19
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 10.687022900763793 33
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 11.832061068702771 39
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 15.648854961832697 58
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 16.793893129771675 67
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 16.793893129771675 76
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 17.938931297710653 95
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b892e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 7.25190839694686 20
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 11.068702290076786 34
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 12.213740458015764 40
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 16.03053435114569 59
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 17.175572519084668 68
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 17.175572519084668 77
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 18.320610687023645 96
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89c50> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ba8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 7.633587786259852 21
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 11.450381679389778 35
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 12.595419847328756 41
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 16.412213740458682 60
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 17.55725190839766 69
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 17.55725190839766 78
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 18.702290076336638 97
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b896a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3240> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 8.015267175572845 22
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 11.832061068702771 36
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 12.977099236641749 42
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 16.793893129771675 61
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 17.938931297710653 70
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 17.938931297710653 79
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 19.08396946564963 98
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc39b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ba8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 8.396946564885837 23
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 12.213740458015764 37
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 13.358778625954741 43
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 17.175572519084668 62
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 18.320610687023645 71
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 18.320610687023645 80
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 19.465648854962623 99
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->5->4->2->14->4->3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb748> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 8.77862595419883 24
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 12.595419847328756 38
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 13.740458015267734 44
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 17.55725190839766 63
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 18.702290076336638 72
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 18.702290076336638 81
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 19.847328244275616 100
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 4.198473282442919 12
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 9.160305343511823 25
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 12.977099236641749 39
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 14.122137404580727 45
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 17.938931297710653 64
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 19.08396946564963 73
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 19.08396946564963 82
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 20.22900763358861 101
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ba8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 4.580152671755911 13
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 9.541984732824815 26
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 13.358778625954741 40
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 14.50381679389372 46
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 18.320610687023645 65
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 19.465648854962623 74
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 19.465648854962623 83
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 20.6106870229016 102
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d60009b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbba8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb748> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 4.961832061068904 14
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 9.923664122137808 27
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 13.740458015267734 41
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 14.885496183206712 47
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 18.702290076336638 66
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 19.847328244275616 75
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 19.847328244275616 84
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 20.992366412214594 103
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 5.343511450381897 15
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 10.3053435114508 28
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 14.122137404580727 42
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 15.267175572519704 48
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 19.08396946564963 67
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 20.22900763358861 76
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 20.22900763358861 85
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 21.374045801527586 104
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92208> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 5.725190839694889 16
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 10.687022900763793 29
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 14.50381679389372 43
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 15.648854961832697 49
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 19.465648854962623 68
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 20.6106870229016 77
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 20.6106870229016 86
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 21.75572519084058 105
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
coverage_call_count 3700
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9dd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92208> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 6.106870229007882 17
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 11.068702290076786 30
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 14.885496183206712 44
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 16.03053435114569 50
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 19.847328244275616 69
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 20.992366412214594 78
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 20.992366412214594 87
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 22.13740458015357 106
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43ac8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc39b0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ba8> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 6.488549618320874 18
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 11.450381679389778 31
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 15.267175572519704 45
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 16.412213740458682 51
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 20.22900763358861 70
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 21.374045801527586 79
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 21.374045801527586 88
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 22.519083969466564 107
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->5->4->2->14->4->3->8
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c9b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 6.870229007633867 19
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 11.832061068702771 32
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 15.648854961832697 46
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 16.793893129771675 52
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 20.6106870229016 71
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 21.75572519084058 80
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 21.75572519084058 89
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 22.900763358779557 108
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d601c080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 7.25190839694686 20
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 12.213740458015764 33
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 16.03053435114569 47
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 17.175572519084668 53
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 20.992366412214594 72
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 22.13740458015357 81
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 22.13740458015357 90
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 23.28244274809255 109
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9e10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 7.633587786259852 21
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 12.595419847328756 34
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 16.412213740458682 48
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 17.55725190839766 54
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 21.374045801527586 73
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 22.519083969466564 82
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 22.519083969466564 91
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 23.664122137405542 110
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c5f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb748> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 8.015267175572845 22
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 12.977099236641749 35
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 16.793893129771675 49
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 17.938931297710653 55
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 21.75572519084058 74
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 22.900763358779557 83
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 22.900763358779557 92
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 24.045801526718535 111
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43be0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 3.816793893129926 11
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 8.396946564885837 23
backprop <src.mcts.MCTS_Node object at 0x7f77d6024f28> 13.358778625954741 36
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 17.175572519084668 50
backprop <src.mcts.MCTS_Node object at 0x7f77d601c3c8> 18.320610687023645 56
backprop <src.mcts.MCTS_Node object at 0x7f77d6073710> 22.13740458015357 75
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 23.28244274809255 84
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3c50> 23.28244274809255 93
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 24.427480916031527 112
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->5->4->2->14->4->3->8->12
Best Reward: 0.3816793893129926
iteration: 106
found coverage increase 0.3816793893129926
Current Total Coverage 68.70229007633588
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b926d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b770f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c710> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b432b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b432b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b223c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5b438d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b222b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b310f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b310f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b313c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b313c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b316a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1a58> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b777f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b777f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 3900
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a904e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a904e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a904e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a904e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90438> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60243c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60243c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60243c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60009b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 4000
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60009b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6000278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6000278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc36d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024a20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60533c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60538d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60cabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812418438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a748> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61205c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72784a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7241550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e009b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124766d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c079860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e91828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60241d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c71e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60faf60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fc470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 22
Completed Iteration #24
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6a20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826ed42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed49e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed42e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721bfd0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d721beb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1599b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124479e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1344a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1345f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1345f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1731d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1731d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e44e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7715f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1666d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72872b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c692080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf142b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf14748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cacf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 11
Completed Iteration #14
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfedf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4828> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66a860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124861d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a75c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826df12e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf145f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1349b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1349b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1349b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf140f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda080> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77588> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b779b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b779b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c037278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be32b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbb00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b224e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b894e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b224e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b894e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b221d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b221d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa58> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c170b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba92b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47835c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b315f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 5400
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47499e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47720b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47720b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47720b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764c88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b315f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd68> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47721d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4772390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47729b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47729b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46cae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d47492e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7cccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c0f4e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5700
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0b3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda7f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c760dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c760f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c67f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfedef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c64b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf6b438> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfdfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c692710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6deae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfba58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b778d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfbda0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c08a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78d05d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c166198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfacba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa30b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cf146a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f789813b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c185d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c08abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfaccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6eb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cff9908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786cff9518> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf14ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781244f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cff9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf14518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c771438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6586a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1346d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7048> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c18eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c06d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d721b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6ddab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1730f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78ce4494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c06da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6deacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea9e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dda588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0376a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c173b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c18e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781244fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfa3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826ed4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812447dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123eb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf61160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c062eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d40b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf8b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c71ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1ca320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f781240c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78123fca90> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf48438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1278> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c185550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78123ebf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf61828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b92f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cf144a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc10f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d61202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7278be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c64bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7278f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e14f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d729f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c66ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c6ff9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c037630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812486748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0e4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c159da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c658cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b77278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786c134550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e009b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78123eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812418240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6120860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613afd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7826e00ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812447438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6120550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c173390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d613a860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
coverage_call_count 6200
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bc3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d721b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bfb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c114b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c1342e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7287630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dea7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a36d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6093748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7241c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60caef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812486748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6000898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7287ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6066400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6053278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c0a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf78198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60fae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6093470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d601cb00> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72419b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7241198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6024668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d72419b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47498d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47498d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47498d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfa38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e3e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dc1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d468c2b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c6cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6053fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5adf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c079390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b7ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786c134128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a906d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 14
Completed Iteration #21
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a906d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6000128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d6073dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6024320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d601c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826df1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7812476128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c7e94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47649b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47649b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47649b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f787c7e9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4764828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826df1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f78124186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 6500
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d601c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6073cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca278> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47839b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f781240c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2ba90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47836a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47836a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47836a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7826e9ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6dfd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abdb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d4783a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e14dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bcedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c72fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c1d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4749550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7812476c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4764320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 15
Completed Iteration #14
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 3
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 4
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 5
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 6
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 7
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 8
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 9
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47abc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 10
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 11
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b227f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d6066400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e80b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f787c658630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b22160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d72e49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5be30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47832b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d7207978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cf48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d7207978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4783f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47b8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b896d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5aa5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d469ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d468c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5a90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d473fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d613a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc50> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46f36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d60732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b43d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47839e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9128> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab7f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d46af278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b4c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf88ad68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77d46af8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5bce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c06898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5abd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5b89518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ba95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46af7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c2bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472cac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d472c8d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4772ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8563c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf899e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46f3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46aff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8562b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d60faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7826e9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5be3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf87ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d46afcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf899940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d472c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf863d68> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf88a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d473f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d41d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d41d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d47ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d41d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf834470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c14bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4772ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf856320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8992e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf856c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786c159e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8997f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1efd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf863fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4749550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1adb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d46afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf80b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1eff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf834c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77d4c798d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf834b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf8565f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5ad1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fa20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf111278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf863668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf17ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf111908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf111b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf111dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf129358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf129390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf129a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf129668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf111550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1112e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f786cfd47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf129668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1111d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf111e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf129208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf1112b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf111630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d472cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf16fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf14a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf17f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d5b774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf80bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf8566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77d4c4f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1c1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf899080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf87bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf16f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f77cf1ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f77cf111a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f77cf14aa58> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 68.70229007633588
initial coverage: 66.7939
time passed (minutes): 60.1317
iterations: 243
number of new inputs: 320
final coverage: 68.7023
total coverage increase: 1.9084
